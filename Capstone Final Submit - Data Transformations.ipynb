{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "\n",
    "from scripts.sam_value_counts import sam_dataframe_cols_value_count_analysis, sam_dataframe_markup_value_counts\n",
    "from scripts.sam_confusion_matrix import sam_plot_confusion_matrix, sam_confusion_maxtrix\n",
    "from scripts.sam_variance_check import get_low_variance_columns\n",
    "from scripts.tools import check_metric, data_transformations, df_check_stats, game\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "np.set_printoptions(precision=5)\n",
    "np.random.seed(69572)\n",
    "plt.style.use('ggplot')\n",
    "sns.set(color_codes=True)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "from scripts import sam_custom_labeler\n",
    "from collections import defaultdict\n",
    "\n",
    "CUST_CATEGORY_LABELER = sam_custom_labeler.CUST_CATEGORY_LABELER\n",
    "\n",
    "def sam_pickle_save(df_x, df_y, df_test_x, prefix=\"tmp/Iteration1_\"):\n",
    "    print('SAVE PREFIX USED: ', prefix)\n",
    "    pickle.dump(df_x, open(prefix + 'df_x.pkl', 'wb'))\n",
    "    pickle.dump(df_y, open(prefix + 'df_y.pkl', 'wb'))\n",
    "    pickle.dump(df_test_x, open(prefix + 'df_test_x.pkl', 'wb'))\n",
    "    return\n",
    "\n",
    "def sam_pickle_load(prefix='tmp/Iteration1_'):\n",
    "    print('LOAD PREFIX USED: ', prefix)\n",
    "    df_x = pickle.load(open(prefix + 'df_x.pkl', 'rb'))\n",
    "    df_y = pickle.load(open(prefix + 'df_y.pkl', 'rb'))\n",
    "    df_test_x = pickle.load(open(prefix + 'df_test_x.pkl', 'rb'))\n",
    "    return df_x, df_y, df_test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "crazy_list = dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for each in dir():\n",
    "    if each not in crazy_list:\n",
    "        del each"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "source": [
    "# Data Transformation Iteration1\n",
    "\n",
    "Normal Transformations\n",
    "* Date\n",
    "* Bool\n",
    "* Longi, Lati missing values\n",
    "* Longi, Lati precision check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data collection\n",
    "RAW_X = pd.read_csv('data/traning_set_values.csv', index_col='id')\n",
    "RAW_y = pd.read_csv('data/training_set_labels.csv', index_col='id')\n",
    "RAW_TEST_X = pd.read_csv('data/test_set_values.csv', index_col='id')\n",
    "\n",
    "# df_check_stats(RAW_X, RAW_y, RAW_TEST_X)\n",
    "\n",
    "strptime = datetime.datetime.strptime\n",
    "\n",
    "DATE_FORMAT = \"%Y-%m-%d\"\n",
    "REFERENCE_DATE_POINT = strptime('2000-01-01', DATE_FORMAT)\n",
    "\n",
    "if RAW_X.date_recorded.dtype == 'O':\n",
    "\n",
    "    # convert it to datetime format\n",
    "    f = lambda x: strptime(str(x), DATE_FORMAT)\n",
    "    RAW_X.date_recorded = RAW_X.date_recorded.apply(f)\n",
    "    RAW_TEST_X.date_recorded = RAW_TEST_X.date_recorded.apply(f)\n",
    "\n",
    "    # week day\n",
    "    f = lambda x: x.weekday()\n",
    "    RAW_X['date_recorded_weekday'] = RAW_X.date_recorded.apply(f)\n",
    "    RAW_TEST_X['date_recorded_weekday'] = RAW_TEST_X.date_recorded.apply(f)\n",
    "\n",
    "    # date\n",
    "    f = lambda x: x.day\n",
    "    RAW_X['date_recorded_date'] = RAW_X.date_recorded.apply(f)\n",
    "    RAW_TEST_X['date_recorded_date'] = RAW_TEST_X.date_recorded.apply(f)\n",
    "\n",
    "    # month\n",
    "    f = lambda x: x.month\n",
    "    RAW_X['date_recorded_month'] = RAW_X.date_recorded.apply(f)\n",
    "    RAW_TEST_X['date_recorded_month'] = RAW_TEST_X.date_recorded.apply(f)\n",
    "\n",
    "    # year\n",
    "    f = lambda x: x.year\n",
    "    RAW_X['date_recorded_year'] = RAW_X.date_recorded.apply(f)\n",
    "    RAW_TEST_X['date_recorded_year'] = RAW_TEST_X.date_recorded.apply(f)\n",
    "\n",
    "    # total days\n",
    "    f = lambda x: (x - REFERENCE_DATE_POINT).days\n",
    "    RAW_X.date_recorded = RAW_X.date_recorded.apply(f)\n",
    "    RAW_TEST_X.date_recorded = RAW_TEST_X.date_recorded.apply(f)\n",
    "    \n",
    "\n",
    "# Longitude & Latitude -- zero values fix\n",
    "\n",
    "# Filling Missing\n",
    "if not RAW_X.loc[RAW_X.latitude >= -1.0, u'latitude'].empty:\n",
    "    tmp = np.mean(RAW_X[u'latitude'][RAW_X.latitude < -1.0].values)\n",
    "    RAW_X.loc[RAW_X.latitude >= -1.0, u'latitude'] = tmp\n",
    "    RAW_TEST_X.loc[RAW_TEST_X.latitude >= -1.0, u'latitude'] = tmp\n",
    "\n",
    "\n",
    "# Filling Missing\n",
    "if not RAW_X.loc[RAW_X[u'longitude'] <= 1.0, u'longitude'].empty:\n",
    "    tmp = np.mean(RAW_X[u'longitude'][RAW_X[u'longitude'] > 1.0].values)\n",
    "    RAW_X.loc[RAW_X[u'longitude'] <= 1.0, u'longitude'] = tmp\n",
    "    RAW_TEST_X.loc[RAW_TEST_X[u'longitude'] <= 1.0, u'longitude'] = tmp\n",
    "\n",
    "    \n",
    "# Reducing geo location precision to 11 meters\n",
    "LONG_LAT_PRECISION = 0.00001\n",
    "fns_lola =lambda x: (x//LONG_LAT_PRECISION) * LONG_LAT_PRECISION\n",
    "\n",
    "# Reducing Precision of Lat.\n",
    "RAW_X.longitude = RAW_X.longitude.map(fns_lola)\n",
    "RAW_X.latitude = RAW_X.latitude.map(fns_lola)\n",
    "RAW_TEST_X.longitude = RAW_TEST_X.longitude.map(fns_lola)\n",
    "RAW_TEST_X.latitude = RAW_TEST_X.latitude.map(fns_lola)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "#   Note Below transformation are to make sure Label Encoding works fine\n",
    "#\n",
    "#\n",
    "\n",
    "\n",
    "# bool columns\n",
    "tmp = ['public_meeting', 'permit']\n",
    "RAW_X[tmp] = RAW_X[tmp].fillna(False)\n",
    "RAW_TEST_X[tmp] = RAW_TEST_X[tmp].fillna(False)\n",
    "\n",
    "# object columns list\n",
    "obj_cols = RAW_X.dtypes[RAW_X.dtypes == 'O'].index.tolist()\n",
    "\n",
    "# object columns\n",
    "RAW_X[obj_cols] = RAW_X[obj_cols].fillna('Other')\n",
    "RAW_TEST_X[obj_cols] = RAW_TEST_X[obj_cols].fillna('Other')\n",
    "\n",
    "\n",
    "sam_pickle_save(RAW_X, RAW_y, RAW_TEST_X, prefix=\"tmp/Iteration2_dt1_\")\n",
    "df_check_stats(X, y, TEST_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOAD PREFIX USED:  tmp/Iteration2_dt1_\n",
      "Data Frame Shape: (59400, 43) TotColumns: 43 ObjectCols: 0\n",
      "Data Frame Shape: (59400, 1) TotColumns: 1 ObjectCols: 0\n",
      "Data Frame Shape: (14850, 43) TotColumns: 43 ObjectCols: 0\n"
     ]
    }
   ],
   "source": [
    "RAW_X, RAW_y, RAW_TEST_X = sam_pickle_load(prefix=\"tmp/Iteration2_dt1_\")\n",
    "df_check_stats(RAW_X, RAW_y, RAW_TEST_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------\n",
      "AC Score: 0.984399551066 F1 Score: 0.984469065664\n",
      "------------------------------------------------\n",
      "AC Score: 0.800269360269 F1 Score: 0.806787932206\n"
     ]
    }
   ],
   "source": [
    "# Just assining new names to transformed dataframe pointers\n",
    "X, y, TEST_X = data_transformations(RAW_X, RAW_y, RAW_TEST_X)\n",
    "\n",
    "# benchmark\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25,random_state=42, stratify=y)\n",
    "clf = game(X_train, X_test, y_train, y_test, algo='rf', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "del X, y, TEST_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Transformation Iteration1\n",
    "\n",
    "Normal Transformations\n",
    "* Date\n",
    "* Bool\n",
    "* Longi, Lati missing values\n",
    "* Longi, Lati precision check\n",
    "\n",
    "\n",
    "# Data Transformation Iteration2\n",
    "\n",
    "* Custom Labler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for each in dir():\n",
    "    if each not in crazy_list:\n",
    "        del each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOAD PREFIX USED:  tmp/Iteration2_dt1_\n",
      "Data Frame Shape: (59400, 43) TotColumns: 43 ObjectCols: 0\n",
      "Data Frame Shape: (59400, 1) TotColumns: 1 ObjectCols: 0\n",
      "Data Frame Shape: (14850, 43) TotColumns: 43 ObjectCols: 0\n"
     ]
    }
   ],
   "source": [
    "RAW_X, RAW_y, RAW_TEST_X = sam_pickle_load(prefix=\"tmp/Iteration2_dt1_\")\n",
    "df_check_stats(RAW_X, RAW_y, RAW_TEST_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "funder 17 8\n",
      "installer 279 145\n",
      "wpt_name 683 144\n",
      "basin 0 0\n",
      "subvillage 112 37\n",
      "region 0 0\n",
      "lga 0 0\n",
      "ward 0 0\n",
      "recorded_by 0 0\n",
      "scheme_management 0 0\n",
      "scheme_name 212 97\n",
      "extraction_type 0 0\n",
      "extraction_type_group 0 0\n",
      "extraction_type_class 0 0\n",
      "management 0 0\n",
      "management_group 0 0\n",
      "payment 0 0\n",
      "payment_type 0 0\n",
      "water_quality 0 0\n",
      "quality_group 0 0\n",
      "quantity 0 0\n",
      "quantity_group 0 0\n",
      "source 0 0\n",
      "source_type 0 0\n",
      "source_class 0 0\n",
      "waterpoint_type 0 0\n",
      "waterpoint_type_group 0 0\n"
     ]
    }
   ],
   "source": [
    "def text_transformation(name):\n",
    "    \"\"\"Cleanup basic text issue in name(input).\n",
    "    \n",
    "    Removes text capitalisation, case, space and other non text ascii charecters\n",
    "        except space.\n",
    "    \"\"\"\n",
    "    if name:\n",
    "        name = str(name).lower().strip()\n",
    "        name = ''.join([i if 96 < ord(i) < 128 else ' ' for i in name])\n",
    "        if 'and' in name:\n",
    "            name = name.replace('and', ' ')\n",
    "\n",
    "        # clear double space\n",
    "        while '  ' in name:\n",
    "            name = name.replace('  ', ' ')\n",
    "        return name.strip()\n",
    "    return ''\n",
    "\n",
    "for col in obj_cols:\n",
    "    a, b, c = (col, len(RAW_X[col].value_counts()), len(RAW_TEST_X[col].value_counts()))\n",
    "    RAW_X[col] = RAW_X[col].apply(text_transformation)\n",
    "    RAW_TEST_X[col] = RAW_TEST_X[col].apply(text_transformation)\n",
    "    d, e = len(RAW_X[col].value_counts()), len(RAW_TEST_X[col].value_counts())\n",
    "    print(a, b - d, c - e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------\n",
      "AC Score: 0.984264870932 F1 Score: 0.984335586239\n",
      "------------------------------------------------\n",
      "AC Score: 0.802087542088 F1 Score: 0.808550466484\n"
     ]
    }
   ],
   "source": [
    "# Just assining new names to transformed dataframe pointers\n",
    "X, y, TEST_X = data_transformations(RAW_X, RAW_y, RAW_TEST_X)\n",
    "\n",
    "# benchmark\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25,random_state=42, stratify=y)\n",
    "clf = game(X_train, X_test, y_train, y_test, algo='rf', )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Labler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------- funder\n",
      "97 percentage of DATA coverage mean, 593 (in number) groups\n",
      "1881 594\n",
      "97 percentage of DATA coverage mean, 593 (in number) groups\n",
      "973 535\n",
      "-------------------------------------------------------- ward\n",
      "80 percentage of DATA coverage mean, 998 (in number) groups\n",
      "2092 999\n",
      "80 percentage of DATA coverage mean, 998 (in number) groups\n",
      "1959 993\n",
      "-------------------------------------------------------- scheme_name\n",
      "85 percentage of DATA coverage mean, 524 (in number) groups\n",
      "2485 525\n",
      "85 percentage of DATA coverage mean, 524 (in number) groups\n",
      "1693 518\n",
      "-------------------------------------------------------- installer\n",
      "97 percentage of DATA coverage mean, 600 (in number) groups\n",
      "1867 601\n",
      "97 percentage of DATA coverage mean, 600 (in number) groups\n",
      "947 521\n",
      "-------------------------------------------------------- subvillage\n",
      "80 percentage of DATA coverage mean, 8568 (in number) groups\n",
      "19176 8569\n",
      "80 percentage of DATA coverage mean, 8568 (in number) groups\n",
      "8407 4314\n",
      "-------------------------------------------------------- wpt_name\n",
      "80 percentage of DATA coverage mean, 24838 (in number) groups\n",
      "36717 24839\n",
      "80 percentage of DATA coverage mean, 24838 (in number) groups\n",
      "10696 2161\n",
      "(59400, 43) (14850, 43) True\n"
     ]
    }
   ],
   "source": [
    "##################################\n",
    "######### IMPLEMENT ##############\n",
    "#################################\n",
    "\n",
    "custom_labler = defaultdict(CUST_CATEGORY_LABELER)\n",
    "tmp = { 'funder': 97,\n",
    "  'installer': 97,\n",
    "  'wpt_name': 80,\n",
    "  'subvillage': 80,\n",
    "  'ward': 80,\n",
    "  'scheme_name': 85\n",
    "  }\n",
    "\n",
    "for col, limit  in tmp.items():\n",
    "    print('--------------------------------------------------------', col)\n",
    "    labler = custom_labler[col]\n",
    "    labler.DATA_COVERAGE_LIMIT = limit\n",
    "    labler.fit(RAW_X[col])\n",
    "    tmp = labler.fit_transform(RAW_X[col])\n",
    "    print(len(RAW_X[col].value_counts()), len(tmp.value_counts()))\n",
    "    RAW_X[col] = tmp\n",
    "    tmp = labler.etransform(RAW_TEST_X[col])\n",
    "    print(len(RAW_TEST_X[col].value_counts()), len(tmp.value_counts()))\n",
    "\n",
    "print(RAW_X.shape, RAW_TEST_X.shape, all(RAW_X.columns == RAW_TEST_X.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVE PREFIX USED:  tmp/Iteration2_dt2_\n",
      "Data Frame Shape: (59400, 43) TotColumns: 43 ObjectCols: 0\n",
      "Numpy Array Size: 59400\n",
      "Data Frame Shape: (14850, 43) TotColumns: 43 ObjectCols: 0\n"
     ]
    }
   ],
   "source": [
    "sam_pickle_save(RAW_X, RAW_y, RAW_TEST_X, prefix=\"tmp/Iteration2_dt2_\")\n",
    "df_check_stats(X, y, TEST_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------\n",
      "AC Score: 0.985274971942 F1 Score: 0.985335201609\n",
      "------------------------------------------------\n",
      "AC Score: 0.797104377104 F1 Score: 0.803445444177\n"
     ]
    }
   ],
   "source": [
    "# Just assining new names to transformed dataframe pointers\n",
    "X, y, TEST_X = data_transformations(RAW_X, RAW_y, RAW_TEST_X)\n",
    "\n",
    "# benchmark\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25,random_state=42, stratify=y)\n",
    "clf = game(X_train, X_test, y_train, y_test, algo='rf', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVE PREFIX USED:  tmp/Iteration2_final_\n",
      "Data Frame Shape: (59400, 43) TotColumns: 43 ObjectCols: 0\n",
      "Numpy Array Size: 59400\n",
      "Data Frame Shape: (14850, 43) TotColumns: 43 ObjectCols: 0\n"
     ]
    }
   ],
   "source": [
    "sam_pickle_save(X, y, TEST_X, prefix=\"tmp/Iteration2_final_\")\n",
    "df_check_stats(X, y, TEST_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOAD PREFIX USED:  tmp/Iteration2_final_\n",
      "Data Frame Shape: (59400, 43) TotColumns: 43 ObjectCols: 0\n",
      "Numpy Array Size: 59400\n",
      "Data Frame Shape: (14850, 43) TotColumns: 43 ObjectCols: 0\n"
     ]
    }
   ],
   "source": [
    "X, y, TEST_X = sam_pickle_load(prefix=\"tmp/Iteration2_final_\")\n",
    "df_check_stats(X, y, TEST_X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
