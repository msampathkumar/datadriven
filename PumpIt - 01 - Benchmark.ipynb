{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Introduction:**\n",
    "Using the data gathered from Taarifa and the Tanzanian Ministry of Water, can we predict which pumps are functional, which need some repairs, and which don't work at all? Predicting one of these three classes based and a smart understanding of which waterpoints will fail, can improve the maintenance operations and ensure that clean, potable water is available to communities across Tanzania.\n",
    "\n",
    "This is also an intermediate-level competition by [DataDriven][1]! All code & support scripts are in [Github Repo][2]\n",
    "\n",
    "[1]: https://www.drivendata.org/competitions/7/ \"Link to Competetion Page\"\n",
    "[2]: https://github.com/msampathkumar/datadriven_pumpit \"User Code\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scripts.tools import data_transformations, df_check_stats, game, sam_pickle_save, sam_pickle_load\n",
    "\n",
    "np.set_printoptions(precision=5)\n",
    "np.random.seed(69572)\n",
    "plt.style.use('ggplot')\n",
    "sns.set(color_codes=True)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Frame Shape: (59400, 39) TotColumns: 39 ObjectCols: 0\n",
      "Data Frame Shape: (59400, 1) TotColumns: 1 ObjectCols: 0\n",
      "Data Frame Shape: (14850, 39) TotColumns: 39 ObjectCols: 0\n",
      "SAVE PREFIX USED:  tmp/Iteration0_\n",
      "Data Frame Shape: (59400, 39) TotColumns: 39 ObjectCols: 0\n",
      "Numpy Array Size: 59400\n",
      "Data Frame Shape: (14850, 39) TotColumns: 39 ObjectCols: 0\n"
     ]
    }
   ],
   "source": [
    "# data collection\n",
    "RAW_X = pd.read_csv('data/traning_set_values.csv', index_col='id')\n",
    "RAW_y = pd.read_csv('data/training_set_labels.csv', index_col='id')\n",
    "RAW_TEST_X = pd.read_csv('data/test_set_values.csv', index_col='id')\n",
    "\n",
    "df_check_stats(RAW_X, RAW_y, RAW_TEST_X)\n",
    "\n",
    "# bool columns\n",
    "tmp = ['public_meeting', 'permit']\n",
    "RAW_X[tmp] = RAW_X[tmp].fillna(True)\n",
    "RAW_TEST_X[tmp] = RAW_TEST_X[tmp].fillna(True)\n",
    "\n",
    "# object columns list\n",
    "obj_cols = RAW_X.dtypes[RAW_X.dtypes == 'O'].index.tolist()\n",
    "\n",
    "# object columns\n",
    "RAW_X[obj_cols] = RAW_X[obj_cols].fillna('Other')\n",
    "RAW_TEST_X[obj_cols] = RAW_TEST_X[obj_cols].fillna('Other')\n",
    "\n",
    "# Just assining new names to transformed dataframe pointers\n",
    "X, y, TEST_X = data_transformations(RAW_X, RAW_y, RAW_TEST_X)\n",
    "\n",
    "sam_pickle_save(X, y, TEST_X, prefix=\"tmp/Iteration0_\")\n",
    "df_check_stats(X, y, TEST_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------\n",
      "AC Score: 0.984848484848 F1 Score: 0.984906895824\n",
      "------------------------------------------------\n",
      "AC Score: 0.799865319865 F1 Score: 0.806462319165\n"
     ]
    }
   ],
   "source": [
    "# benchmark\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25,random_state=42, stratify=y)\n",
    "clf = game(X_train, X_test, y_train, y_test, algo='rf', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------\n",
      "AC Score: 0.755757575758 F1 Score: 0.77760116502\n",
      "------------------------------------------------\n",
      "AC Score: 0.754074074074 F1 Score: 0.776074770727\n"
     ]
    }
   ],
   "source": [
    "# benchmark\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25,random_state=42, stratify=y)\n",
    "clf = game(X_train, X_test, y_train, y_test, algo='gb', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------\n",
      "AC Score: 0.72430976431 F1 Score: 0.733751767199\n",
      "------------------------------------------------\n",
      "AC Score: 0.594276094276 F1 Score: 0.607978244208\n"
     ]
    }
   ],
   "source": [
    "# benchmark\n",
    "knn_clf = game(X_train, X_test, y_train, y_test, algo='knn')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
