{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# PUMP IT UP\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Introduction:**\n",
    "Using the data gathered from Taarifa and the Tanzanian Ministry of Water, can we predict which pumps are functional, which need some repairs, and which don't work at all? Predicting one of these three classes based and a smart understanding of which waterpoints will fail, can improve the maintenance operations and ensure that clean, potable water is available to communities across Tanzania.\n",
    "\n",
    "This is also an intermediate-level competition by [DataDriven][1]! All code & support scripts are in [Github Repo][2]\n",
    "\n",
    "[1]: https://www.drivendata.org/competitions/7/ \"Link to Competetion Page\"\n",
    "[2]: https://github.com/msampathkumar/datadriven_pumpit \"User Code\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "# %load_ext writeandexecute\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "sns.set(color_codes=True)\n",
    "\n",
    "# seed\n",
    "np.random.seed(69572)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import sys\n",
    "# sys.path = sys.path + ['/Users/sampathkumarm/Desktop/devbox/Sam-DS/Kaggle/datadriven']\n",
    "\n",
    "from scripts.sam_value_counts import sam_dataframe_cols_value_count_analysis, sam_dataframe_markup_value_counts\n",
    "from scripts.sam_confusion_matrix import sam_plot_confusion_matrix, sam_confusion_maxtrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from IPython.core.getipython import get_ipython\n",
    "from IPython.core.magic import (Magics, magics_class,  cell_magic)\n",
    "\n",
    "try:\n",
    "    from StringIO import StringIO\n",
    "except ImportError:\n",
    "    from io import StringIO\n",
    "\n",
    "from markdown import markdown\n",
    "from IPython.core.display import HTML\n",
    "from IPython.display import display\n",
    "\n",
    "@magics_class\n",
    "class MarkdownMagics(Magics):\n",
    " \n",
    "    @cell_magic\n",
    "    def asmarkdown(self, line, cell):\n",
    "        buffer = StringIO()\n",
    "        stdout = sys.stdout\n",
    "        sys.stdout = buffer\n",
    "        try:\n",
    "            exec(cell, locals(), self.shell.user_ns)\n",
    "        except:\n",
    "            sys.stdout = stdout\n",
    "            raise\n",
    "        sys.stdout = stdout\n",
    "        return HTML(\"<p>{}</p>\".format(markdown(buffer.getvalue(), extensions=['markdown.extensions.extra'])))\n",
    "        return buffer.getvalue() + 'test'\n",
    "    \n",
    "    def timer_message(self, start_time):\n",
    "#         print self\n",
    "        time_diff = (now() - start_time).total_seconds()\n",
    "        if time_diff < 0.001:\n",
    "            time_diff = 0\n",
    "            print('\\n<pre>In', time_diff, 'Secs</pre>')\n",
    "        else:\n",
    "            print('\\n<pre>In', time_diff, 'Secs</pre>')\n",
    "\n",
    "    @cell_magic\n",
    "    def timer(self, line, cell):\n",
    "        import datetime\n",
    "        now = datetime.datetime.now\n",
    "        start_time = now()\n",
    "        buffer = StringIO()\n",
    "        stdout = sys.stdout\n",
    "        sys.stdout = buffer\n",
    "        try:\n",
    "            exec(cell, locals(), self.shell.user_ns)\n",
    "            self.timer_message(start_time)\n",
    "        except:\n",
    "            sys.stdout = stdout\n",
    "            raise\n",
    "        sys.stdout = stdout\n",
    "        return HTML(\"<p>{}</p>\".format(markdown(buffer.getvalue(), extensions=['markdown.extensions.extra'])))\n",
    "        return buffer.getvalue() + 'test'\n",
    " \n",
    "get_ipython().register_magics(MarkdownMagics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "RAW_X = pd.read_csv('data/traning_set_values.csv', index_col='id')\n",
    "RAW_y = pd.read_csv('data/training_set_labels.csv', index_col='id')\n",
    "RAW_TEST_X = pd.read_csv('data/test_set_values.csv', index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Shape of RAW_X', RAW_X.shape)\n",
    "print('Shape of RAW_y', RAW_y.shape)\n",
    "print('Shape of RAW_TEST_X', RAW_TEST_X.shape)\n",
    "\n",
    "# ('Shape of RAW_X', (59400, 39))\n",
    "# ('Shape of RAW_y', (59400, 1))\n",
    "# ('Shape of RAW_TEST_X', (14850, 39))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i, col in enumerate(RAW_X.columns):\n",
    "    print('|%d|%s|%d|' % (i, col, len(RAW_X[col].value_counts())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# integer colums\n",
    "cols_ints = '''amount_tsh\n",
    "gps_height\n",
    "longitude\n",
    "latitude\n",
    "num_private\n",
    "region_code\n",
    "district_code\n",
    "population\n",
    "construction_year'''.splitlines()\n",
    "\n",
    "# bool\n",
    "cols_bool = 'public_meeting permit'.split()\n",
    "\n",
    "# date\n",
    "cols_date = ['date_recorded']\n",
    "\n",
    "print('INT COlS: ', len(cols_ints))\n",
    "print('BOOL COLS:', len(cols_bool))\n",
    "print('Date COLS:', len(cols_date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(RAW_X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_object_dtypes(df,others=True):\n",
    "    dtype = object\n",
    "    if others:\n",
    "        return df.dtypes[df.dtypes == dtype]\n",
    "    else:\n",
    "        return df.dtypes[df.dtypes != dtype]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show_object_dtypes(RAW_TEST_X, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show_object_dtypes(RAW_TEST_X, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cols_values_counts_dataframe\n",
    "\n",
    "As we can see in above *describe* output, we seem to have lots of categorical values so let start exploring them a bit.\n",
    "\n",
    "Lets start taking into believe everything is a Categorical Columns and check their data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "columns = RAW_X.columns\n",
    "values_counts_bag = [len(RAW_X[column].value_counts()) for column in columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "_ = sns.distplot(values_counts_bag, hist=True, kde=False,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Example of how np-log transforms data**\n",
    "\n",
    "    >>> np.log([0.001, 0.01, 0.1, 1, 10, 100, 1000])\n",
    "\n",
    "    array([-6.90775528, -4.60517019, -2.30258509,  0.        ,  2.30258509,\n",
    "            4.60517019,  6.90775528])\n",
    "\n",
    "As you can see in np-log example, we can learn that when a list of values vary significantly(exponentially) then their logarithms moves linearly. As we(I) feel comfortable in studying linear plot and linear information, we did a np.log to values counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols_values_counts_dataframe = pd.DataFrame(np.log(values_counts_bag), index=columns, columns=['Value Counts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Values Counts:', values_counts_bag)\n",
    "\n",
    "print('\\nLog of Values Counts:', cols_values_counts_dataframe.T.values)\n",
    "\n",
    "_ = sns.distplot(cols_values_counts_dataframe.T.values, hist=True, kde=False,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cols_values_counts_dataframe.plot(kind='barh', figsize=(12, 12))\n",
    "_ = plt.plot((2, 2), (0, 38))\n",
    "_ = plt.plot((4, 4), (0, 38), '-g')\n",
    "_ = plt.plot((6, 6), (0, 38), '-r')\n",
    "print('We seem to have some special categories where value counts are high.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sam_dataframe_cols_value_count_analysis(RAW_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Checking rest of the columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cols_value_count_limit_fraction = 0.01\n",
    "cols_value_count_limit_log_value = np.log(RAW_X.shape[0] * cols_value_count_limit_fraction)\n",
    "\n",
    "\n",
    "print('Total Number of Records:', RAW_X.shape[0], '- Log val is:', np.log(RAW_X.shape[0]))\n",
    "print('%s percent of Number of Records:' % (cols_value_count_limit_fraction * 100),\\\n",
    "      RAW_X.shape[0] * cols_value_count_limit_fraction,\\\n",
    "      ' - Log val is:',  cols_value_count_limit_log_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cols_categorical_check\n",
    "\n",
    "Here in this project, `cols_categorical_check` refers to list of columns for which caution check is considered. Reason for this check is, we would need more data to explain other columns & target cols with respect to it.\n",
    "\n",
    "Lets consider these columns with more 5% of values as non categorical values and since our problem statement is choosing which category, we will try to minimise the category and see how our performance changes(improves or not)\n",
    "\n",
    "To begin we will consider that those categories with more than `cols_value_count_limit_fraction` percentage as the upper limit allowed. Any column with other data will pruged to become some to other information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show_object_dtypes(RAW_X, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show_object_dtypes(RAW_X, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cols_non_categorical = show_object_dtypes(RAW_X, True).index.tolist()\n",
    "\n",
    "cols_date_numerics = show_object_dtypes(RAW_X, True).index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cols_categorical_check = []\n",
    "\n",
    "for col, vc in cols_values_counts_dataframe.iterrows():\n",
    "    if col in cols_non_categorical:\n",
    "        if float(vc) > cols_value_count_limit_log_value:\n",
    "            cols_categorical_check.append(col)\n",
    "\n",
    "print('Columns we need to moderate are:', cols_categorical_check)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All `cols_date_numerics`, are date & other numeric data which can be made into buckets or reducing precision. Thus we can bound number of categories in data as the more variety of data we have, we need more information specific to each category which all might end with **curse of dimensionality**.\n",
    "\n",
    "During pre-processing states we shall do following\n",
    "TODO\n",
    "* limiting check experiments on our **`cols_date_numerics`** & **`cols_categorical_check`** to be under **`cols_value_count_limit_fraction`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Log limit for categories:', cols_value_count_limit_log_value)\n",
    "print('Actual limit for categories:', cols_value_count_limit_fraction * RAW_X.shape[0])\n",
    "\n",
    "RAW_X[cols_categorical_check].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "RAW_X[cols_categorical_check].head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_ = sns.distplot(RAW_X.gps_height, hist=True, kde=False, rug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_ = sns.distplot(RAW_X.population, hist=True, kde=False, rug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_ = sns.jointplot(x='longitude', y='latitude', data=RAW_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%asmarkdown\n",
    "# To generate a Markup Table\n",
    "tmp = sam_dataframe_markup_value_counts(dataframe=RAW_X, max_print_value_counts=10, show_plots=False, figsize=(9, 2))\n",
    "\n",
    "for each in tmp:\n",
    "    print(each)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observations & TODO\n",
    "\n",
    "* Most of the data seems categorical\n",
    "\n",
    "* Need to check **cols_date_numerics**(TODO1)\n",
    "    * we shall convert date -> day, month, year, weekday, total_no_of_day_from_reference_point. These splits for two reasons.\n",
    "        * Reason1: It might be possible that in some location all specific set of complaints are registered on a start/mid/at end of the month. It might also be possible that they are registered on every Monday or so.\n",
    "        * Reason2: Taking as much information as possible.\n",
    "* Need to check **cols_categorical_check**(TODO2) \n",
    "    * longitutude & latitude seem to hold (0,0) instead of NULL which is acting as outlier for now\n",
    "\n",
    "* Following pairs looks closesly related - cleanup (TODO3)\n",
    "    * quantity & quantity_group\n",
    "    * quality_group & water_quality\n",
    "    * extraction_type, extraction_type_class & extraction_type_group\n",
    "\n",
    "* Other - cleanup (TODO4)\n",
    "    * recorded_by, seems to hold only a single value\n",
    "    * population & amount_tsh, values are for some given as zero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generic Transformations\n",
    "** Num/Bool Tranformations **\n",
    "\n",
    "* date_recorded to Int\n",
    "* public_meeting to Int\n",
    "* permit to Int\n",
    "* longitude to Float(less precision)\n",
    "* latitude to Float(less precision)\n",
    "\n",
    "Precision Description of Longititude and Latitude is available here at below [link](http://gis.stackexchange.com/questions/8650/measuring-accuracy-of-latitude-and-longitude)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Reloading the data\n",
    "\n",
    "RAW_X = pd.read_csv('traning_set_values.csv', index_col='id')\n",
    "RAW_y = pd.read_csv('training_set_labels.csv', index_col='id')\n",
    "RAW_TEST_X = pd.read_csv('test_set_values.csv', index_col='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Int Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "strptime = datetime.datetime.strptime\n",
    "\n",
    "DATE_FORMAT = \"%Y-%m-%d\"\n",
    "REFERENCE_DATE_POINT = strptime('2000-01-01', DATE_FORMAT)\n",
    "\n",
    "if RAW_X.date_recorded.dtype == 'O':\n",
    "\n",
    "    # convert it to datetime format\n",
    "    f = lambda x: strptime(str(x), DATE_FORMAT)\n",
    "    RAW_X.date_recorded = RAW_X.date_recorded.apply(f)\n",
    "    RAW_TEST_X.date_recorded = RAW_TEST_X.date_recorded.apply(f)\n",
    "\n",
    "    # week day\n",
    "    f = lambda x: x.weekday()\n",
    "    RAW_X['date_recorded_weekday'] = RAW_X.date_recorded.apply(f)\n",
    "    RAW_TEST_X['date_recorded_weekday'] = RAW_TEST_X.date_recorded.apply(f)\n",
    "\n",
    "    # date\n",
    "    f = lambda x: x.day\n",
    "    RAW_X['date_recorded_date'] = RAW_X.date_recorded.apply(f)\n",
    "    RAW_TEST_X['date_recorded_date'] = RAW_TEST_X.date_recorded.apply(f)\n",
    "\n",
    "    # month\n",
    "    f = lambda x: x.month\n",
    "    RAW_X['date_recorded_month'] = RAW_X.date_recorded.apply(f)\n",
    "    RAW_TEST_X['date_recorded_month'] = RAW_TEST_X.date_recorded.apply(f)\n",
    "\n",
    "    # year\n",
    "    f = lambda x: x.year\n",
    "    RAW_X['date_recorded_year'] = RAW_X.date_recorded.apply(f)\n",
    "    RAW_TEST_X['date_recorded_year'] = RAW_TEST_X.date_recorded.apply(f)\n",
    "\n",
    "    # total days\n",
    "    f = lambda x: (x - REFERENCE_DATE_POINT).days\n",
    "    RAW_X.date_recorded = RAW_X.date_recorded.apply(f)\n",
    "    RAW_TEST_X.date_recorded = RAW_TEST_X.date_recorded.apply(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Longitude & Latitude -- zero values fix\n",
    "\n",
    "# Filling Missing/OUTLIAR Values\n",
    "_ = np.mean(RAW_X[u'latitude'][RAW_X.latitude < -1.0].values)\n",
    "\n",
    "if not RAW_X.loc[RAW_X.latitude >= -1.0, u'latitude'].empty:\n",
    "    RAW_X.loc[RAW_X.latitude >= -1.0, u'latitude'] = _\n",
    "    RAW_TEST_X.loc[RAW_TEST_X.latitude >= -1.0, u'latitude'] = _\n",
    "\n",
    "\n",
    "# Filling Missing/OUTLIAR Values\n",
    "_ = np.mean(RAW_X[u'longitude'][RAW_X[u'longitude'] > 1.0].values)\n",
    "\n",
    "if not RAW_X.loc[RAW_X[u'longitude'] <= 1.0, u'longitude'].empty:\n",
    "    RAW_X.loc[RAW_X[u'longitude'] <= 1.0, u'longitude'] = _\n",
    "    RAW_TEST_X.loc[RAW_TEST_X[u'longitude'] <= 1.0, u'longitude'] = _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    if x is True:\n",
    "        return 1\n",
    "    elif x is False:\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "\n",
    "\n",
    "if (RAW_X.public_meeting.dtype != 'bool') and (RAW_X.permit.dtype != 'bool'):\n",
    "\n",
    "    # public_meeting\n",
    "    RAW_X.public_meeting = RAW_X.public_meeting.apply(f)\n",
    "    RAW_TEST_X.public_meeting = RAW_TEST_X.public_meeting.apply(f)\n",
    "\n",
    "    # permit\n",
    "    RAW_X.permit = RAW_X.permit.apply(f)\n",
    "    RAW_TEST_X.permit = RAW_TEST_X.permit.apply(f)\n",
    "\n",
    "print('Dtype of public_meetings & permit:',RAW_X.public_meeting.dtype, RAW_X.permit.dtype)\n",
    "print('')\n",
    "# checking\n",
    "if list(RAW_TEST_X.dtypes[RAW_TEST_X.dtypes != RAW_X.dtypes]):\n",
    "    raise Exception('RAW_X.dtypes and RAW_TEST_X.dtypes are not in Sync')\n",
    "else:\n",
    "    print('All in Good Shape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show_object_dtypes(RAW_X, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show_object_dtypes(RAW_X, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reducing geo location precision to 11 meters\n",
    "LONG_LAT_PRECISION = 0.001\n",
    "\n",
    "# Reducing Precision of Lat.\n",
    "if RAW_X.longitude.mean() < 50:\n",
    "    RAW_X.longitude = RAW_X.longitude // LONG_LAT_PRECISION\n",
    "    RAW_X.latitude = RAW_X.latitude // LONG_LAT_PRECISION\n",
    "    RAW_TEST_X.longitude = RAW_TEST_X.longitude // LONG_LAT_PRECISION\n",
    "    RAW_TEST_X.latitude = RAW_TEST_X.latitude // LONG_LAT_PRECISION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_ = sns.jointplot(x='longitude', y='latitude', data=RAW_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Data Tranformations\n",
    "\n",
    "For **cols_categorical_check**, we are going to basic clean action like, lower and upper case issue. Clearning of non ascii values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def text_transformation(name):\n",
    "    if name:\n",
    "        name = name.lower().strip()\n",
    "        name = ''.join([i if 96 < ord(i) < 128 else ' ' for i in name])\n",
    "        if 'and' in name:\n",
    "            name = name.replace('and', ' ')\n",
    "        if '/' in name:\n",
    "            name = name.replace('/', ' ')\n",
    "        while '  ' in name:\n",
    "            name = name.replace('  ', ' ')\n",
    "        return name.strip()\n",
    "    return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%asmarkdown\n",
    "\n",
    "print('''\n",
    "|Column|Prev.|Current|\n",
    "|------|-----|-------|''')\n",
    "for col in cols_categorical_check:\n",
    "    aa = len(RAW_X[col].unique())\n",
    "    RAW_X[col] = RAW_X[col].fillna('').apply(text_transformation)\n",
    "    RAW_TEST_X[col] = RAW_TEST_X[col].fillna('').apply(text_transformation)\n",
    "    bb = len(RAW_X[col].unique())\n",
    "    if aa != bb:\n",
    "        print('|%s|%i|%i|' % (col, aa, bb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# saving transformed data\n",
    "pickle.dump(RAW_X, Open('tmp\\clean_X.pkl', 'w'))\n",
    "pickle.dump(RAW_TEST_X, open('tmp\\clean_TEST_X.pkl', 'w'))\n",
    "# pickle.dump(y, open('tmp\\y.pkl', 'w'))\n",
    "\n",
    "TEST_X, X = RAW_TEST_X, RAW_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Labeler\n",
    "\n",
    "Loading Custom Labeler is for the the purpose of reducing categories varieties by ignoring groups with lower frequencies and covering 80%(default) of the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from __future__ import print_function\n",
    "from ipywidgets import interact, interactive, fixed\n",
    "import ipywidgets as widgets\n",
    "\n",
    "import sam_custom_labeler\n",
    "\n",
    "CUST_CATEGORY_LABELER = sam_custom_labeler.CUST_CATEGORY_LABELER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "help(CUST_CATEGORY_LABELER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labler = CUST_CATEGORY_LABELER()\n",
    "\n",
    "def select_col(col):\n",
    "    global labler\n",
    "    labler = CUST_CATEGORY_LABELER()\n",
    "    labler.fit(RAW_TEST_X[col])\n",
    "    print('Selected', col)\n",
    "\n",
    "ii = interact(select_col, col=['funder', 'installer', 'wpt_name', 'subvillage', 'ward', 'scheme_name'])\n",
    "\n",
    "# To check data coverage\n",
    "def f1(data=80):\n",
    "    labler.check_data_coverage(data_coverage=data)\n",
    "\n",
    "ii1 = interact(f1, data=(70, 100, .5))\n",
    "\n",
    "# To check groups coverage\n",
    "def f2(groups=80):\n",
    "    labler.check_group_coverage(groups)\n",
    "    \n",
    "ii2 = interact(f2, groups=(50, 100., .5))\n",
    "\n",
    "_ = '''\n",
    "Please select one of these slider to chose among the\n",
    " data coverage or groups coverage\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* funder:\n",
    "    * 100.0 percentage of DATA coverage mean, 1881 (in number) groups\n",
    "    * 97.0 percentage of DATA coverage mean, 592 (in number) groups ##\n",
    "    * 90.5 percentage of DATA coverage mean, 237 (in number) groups\n",
    "* installer:\n",
    "    * 100.0 percentage of DATA coverage mean, 1867 (in number) groups\n",
    "    * 97.0 percentage of DATA coverage mean, 599 (in number) groups ##\n",
    "\n",
    "* wpt_name:\n",
    "    * 80.0 percentage of DATA coverage mean, 24838 (in number) groups ##\n",
    "\n",
    "* subvillage:\n",
    "    * 80.5 percentage of DATA coverage mean, 8715 (in number) groups ##\n",
    "    * 83.0 percentage of DATA coverage mean, 9458 (in number) groups\n",
    "* ward:\n",
    "    * 80.0 percentage of DATA coverage mean, 998 (in number) groups ##\n",
    "    * 91.5 percentage of DATA coverage mean, 1397 (in number) groups\n",
    "    * 100.0 percentage of DATA coverage mean, 2093 (in number) groups\n",
    "* scheme_name:\n",
    "    * 100.0 percentage of DATA coverage mean, 2486 (in number) groups\n",
    "    * 91.5 percentage of DATA coverage mean, 870 (in number) groups\n",
    "    * 80.5 percentage of DATA coverage mean, 363 (in number) groups\n",
    "    * 85.0 percentage of DATA coverage mean, 524 (in number) groups ##    \n",
    "** NOTE **:\n",
    "    Marked with double hashes are the selected values for coverage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##################################\n",
    "######### TESTING ################\n",
    "#################################\n",
    "\n",
    "labler = CUST_CATEGORY_LABELER()\n",
    "labler.fit(X.installer)\n",
    "\n",
    "# default data coverage is 80\n",
    "tmp = labler.transform()\n",
    "\n",
    "print('data coveraged', labler.DATA_COVERAGE_LIMIT)\n",
    "print('grous coveraged', len(tmp.value_counts()))\n",
    "\n",
    "print('---------------------')\n",
    "labler.DATA_COVERAGE_LIMIT = 90\n",
    "tmp = labler.transform()\n",
    "\n",
    "print('data coveraged', labler.DATA_COVERAGE_LIMIT)\n",
    "print('grous coveraged', len(tmp.value_counts()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##################################\n",
    "######### IMPLEMENT ##############\n",
    "#################################\n",
    "\n",
    "if 'custom_labler' not in dir():\n",
    "    custom_labler = defaultdict(CUST_CATEGORY_LABELER)\n",
    "    tmp = { 'funder': 97,\n",
    "      'installer': 97,\n",
    "      'wpt_name': 80,\n",
    "      'subvillage': 80,\n",
    "      'ward': 80,\n",
    "      'scheme_name': 85\n",
    "      }\n",
    "\n",
    "    for col, limit  in tmp.iteritems():\n",
    "        labler = custom_labler[col]\n",
    "        labler.DATA_COVERAGE_LIMIT = limit\n",
    "        labler.fit(X[col])\n",
    "        print('')\n",
    "        print('-' * 15, col.upper())\n",
    "\n",
    "    #     custom_labler[col].check_data_coverage(limit)\n",
    "        RAW_X[col] = labler.transform()\n",
    "else:\n",
    "    print('\"custom_labler\" seems is already defined, please check')\n",
    "    \n",
    "print(RAW_X.shape, RAW_TEST_X.shape, all(RAW_X.columns == RAW_TEST_X.columns))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "source": [
    "drop_cols = ['wpt_name',]\n",
    "\n",
    "RAW_X.drop(drop_cols, axis=1, inplace=True)\n",
    "RAW_TEST_X.drop(drop_cols, axis=1, inplace=True)\n",
    "print('Removed Cols:', drop_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Encoder\n",
    "\n",
    "Label Encoder with DefaultDict for quick data transformation\n",
    "http://stackoverflow.com/questions/24458645/label-encoding-across-multiple-columns-in-scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(RAW_X.shape, RAW_TEST_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "d = defaultdict(preprocessing.LabelEncoder)\n",
    "\n",
    "# Labels Fit\n",
    "sam = pd.concat([RAW_X, RAW_TEST_X]).apply(lambda x: d[x.name].fit(x))\n",
    "\n",
    "# Labels Transform - Training Data\n",
    "X = RAW_X.apply(lambda x: d[x.name].transform(x))\n",
    "TEST_X = RAW_TEST_X.apply(lambda x: d[x.name].transform(x))\n",
    "\n",
    "le = preprocessing.LabelEncoder().fit(RAW_y[u'status_group'])\n",
    "y = le.transform(RAW_y[u'status_group'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show_object_dtypes(RAW_X, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show_object_dtypes(X, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pickle\n",
    "\n",
    "** Pickle Save **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# saving transformed data\n",
    "pickle.dump(X, open('tmp\\processed_X.pkl', 'w'))\n",
    "pickle.dump(TEST_X, open('tmp\\processed_TEST_X.pkl', 'w'))\n",
    "pickle.dump(y, open('tmp\\processed_y.pkl', 'w'))\n",
    "\n",
    "# saving label transformers\n",
    "pickle.dump(d, open('tmp\\d.pkl', 'w'))\n",
    "pickle.dump(le, open('tmp\\le.pkl', 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variance Threshold\n",
    "\n",
    "To remove all features that are either one or zero (on or off) in more than 80% of the samples.\n",
    "\n",
    "http://scikit-learn.org/stable/modules/feature_selection.html#removing-features-with-low-variance\n",
    "\n",
    "http://stackoverflow.com/questions/29298973/removing-features-with-low-variance-scikit-learn/34850639#34850639"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = pickle.load(open('tmp\\processed_X.pkl'))\n",
    "TEST_X = pickle.load(open('tmp\\processed_TEST_X.pkl'))\n",
    "y = pickle.load(open('tmp\\processed_y.pkl'))\n",
    "\n",
    "# # Load this when you are about to do text transformation and submission\n",
    "# d = pickle.load(open('tmp\\d.pkl'))\n",
    "# le = pickle.load(open('tmp\\le.pkl'))\n",
    "\n",
    "print(X.shape, y.shape, y[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scripts.sam_variance_check import get_low_variance_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X, removed_features, ranking_variance_thresholds = get_low_variance_columns(dframe=X,\n",
    "                                                                            threshold=(0.85 * (1 - 0.85)),\n",
    "                                                                            autoremove=True)\n",
    "\n",
    "print('\\nLow Variance Columns', removed_features)\n",
    "print('Shape of X is', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if removed_features:\n",
    "    TEST_X.drop(removed_features, axis=1, inplace=True)\n",
    "    print('cleanup completed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Shape of X is', X.shape)\n",
    "print('Shape of TEST_X is', TEST_X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select K Best\n",
    "\n",
    "* For regression: f_regression, mutual_info_regression\n",
    "* For classification: chi2, f_classif, mutual_info_classif\n",
    "\n",
    "\n",
    "Random Forest Classifier score: RandomForestClassifier(n_estimators=150, criterion='entropy', class_weight=\"balanced_subsample\", n_jobs=-1)\n",
    "* chi2 0.81225589225589223\n",
    "*  f_classic 0.81138047138047142\n",
    "* mutual_info_classif 0.81037037037037041"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2, f_classif, mutual_info_classif"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "source": [
    "kbest_cols = 30\n",
    "\n",
    "fit = SelectKBest(score_func=chi2, k=kbest_cols).fit(X, y)\n",
    "cols_names = X.columns\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "ranking_selectkbest = dict(zip(cols_names, fit.scores_))\n",
    "kbest_selected_cols =  [_ for _ in cols_names[:kbest_cols]]\n",
    "\n",
    "# % pprint\n",
    "ranking_selectkbest\n",
    "\n",
    "# print('Removed Columns:\\n\\t', ','.join([ _ for _ in X.columns if _ not in kbest_selected_cols ]))\n",
    "# print('\\nSelected Columns:\\n\\t', ','.join(kbest_selected_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def game(X, y):\n",
    "#     print(X.shape, y.shape[0])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\n",
    "    \n",
    "    clf_rf = RandomForestClassifier(n_jobs=-1, random_state=192)\n",
    "    clf_rf = clf_rf.fit(X_train, y_train)\n",
    "    \n",
    "    train_score = clf_rf.score(X_train, y_train)\n",
    "    test_score = clf_rf.score(X_test, y_test)\n",
    "#     print('Train Score', train_score)\n",
    "#     print('Test  Score', test_score)\n",
    "    return train_score, test_score"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "bag = []\n",
    "kbest_cols = 40\n",
    "\n",
    "# for k in range(1, 40, 4):\n",
    "# for k in range(23, 33, 2):\n",
    "for k in range(26, 29):\n",
    "    kbest_cols = k\n",
    "    \n",
    "    fit = SelectKBest(score_func=chi2, k=kbest_cols).fit(X, y)\n",
    "    cols_names = X.columns\n",
    "    kbest_selected_cols =  [_ for _ in cols_names[:kbest_cols]]\n",
    "\n",
    "    kbest_X = pd.DataFrame(fit.transform(X))\n",
    "    kbest_TEST_X = pd.DataFrame(fit.transform(TEST_X))\n",
    "    # kbest_X.columns = kbest_selected_cols\n",
    "    # kbest_TEST_X.columns = kbest_selected_cols\n",
    "\n",
    "    # print('Before KBest', X.shape, TEST_X.shape, len(y))\n",
    "    # print('After KBest', kbest_X.shape, kbest_TEST_X.shape, len(y))\n",
    "\n",
    "    train_score, test_score = game(kbest_X, y)\n",
    "    bag.append({'cols': kbest_cols,\n",
    "                'train': train_score,\n",
    "                'test': test_score})\n",
    "                \n",
    "print(', '.join(kbest_selected_cols).upper())\n",
    "\n",
    "bag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** kbest conclusion **:\n",
    "\n",
    "Best selected columns\n",
    "```\n",
    "AMOUNT_TSH, DATE_RECORDED, FUNDER, GPS_HEIGHT, INSTALLER, LONGITUDE, LATITUDE, NUM_PRIVATE, BASIN, SUBVILLAGE, REGION, REGION_CODE, DISTRICT_CODE, LGA, WARD, POPULATION, PUBLIC_MEETING, SCHEME_MANAGEMENT, SCHEME_NAME, PERMIT, CONSTRUCTION_YEAR, EXTRACTION_TYPE, EXTRACTION_TYPE_GROUP, EXTRACTION_TYPE_CLASS, MANAGEMENT, MANAGEMENT_GROUP, PAYMENT, PAYMENT_TYPE\n",
    "```\n",
    "\n",
    "``` Python\n",
    "# results of previous runs\n",
    "[{'cols': 1, 'test': 0.52659932659932662, 'train': 0.57483726150392822},\n",
    " {'cols': 5, 'test': 0.68962962962962959, 'train': 0.94240179573512906},\n",
    " {'cols': 9, 'test': 0.7211447811447812, 'train': 0.97638608305274976},\n",
    " {'cols': 13, 'test': 0.75380471380471381, 'train': 0.97955106621773291},\n",
    " {'cols': 17, 'test': 0.76134680134680133, 'train': 0.98071829405162736},\n",
    " {'cols': 21, 'test': 0.76511784511784509, 'train': 0.98076318742985413},\n",
    " {'cols': 25, 'test': 0.80033670033670035, 'train': 0.98316498316498313},\n",
    " {'cols': 29, 'test': 0.80053872053872055, 'train': 0.98379349046015707},\n",
    " {'cols': 33, 'test': 0.80040404040404045, 'train': 0.98390572390572395},\n",
    " {'cols': 37, 'test': 0.79993265993265994, 'train': 0.98341189674523011}]\n",
    "\n",
    "[{'cols': 23, 'test': 0.7976430976430976, 'train': 0.9836812570145903},\n",
    " {'cols': 25, 'test': 0.80033670033670035, 'train': 0.98316498316498313},\n",
    " {'cols': 27, 'test': 0.80101010101010106, 'train': 0.9829405162738496},\n",
    " {'cols': 29, 'test': 0.80053872053872055, 'train': 0.98379349046015707},\n",
    " {'cols': 31, 'test': 0.80000000000000004, 'train': 0.98381593714927051}]\n",
    "\n",
    "[{'cols': 26, 'test': 0.80309764309764309, 'train': 0.98359147025813698},\n",
    " {'cols': 27, 'test': 0.80101010101010106, 'train': 0.9829405162738496},\n",
    " {'cols': 28, 'test': 0.80222222222222217, 'train': 0.98334455667789}]\n",
    "```\n",
    "\n",
    "\n",
    "As per Okham Razor's rules, we are going to select the simplest and well performing. Luckily, we have got kbest_selected_cols at **26** which is comparitively top performer among other K-selections and also lower than actualy number of columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kbest_cols = 26\n",
    "\n",
    "fit = SelectKBest(score_func=chi2, k=kbest_cols).fit(X, y)\n",
    "cols_names = X.columns\n",
    "kbest_selected_cols =  [_ for _ in cols_names[:kbest_cols]]\n",
    "\n",
    "kbest_X = pd.DataFrame(fit.transform(X))\n",
    "kbest_TEST_X = pd.DataFrame(fit.transform(TEST_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(kbest_X, open('tmp\\kbest_X.pkl', 'w'))\n",
    "pickle.dump(kbest_TEST_X, open('tmp\\kbest_TEST_X.pkl', 'w'))\n",
    "pickle.dump(y, open('tmp\\kbest_y.pkl', 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if True:\n",
    "    # this will load kbest\n",
    "    print('Loading KBest Processed Data')\n",
    "    X = pickle.load(open('tmp\\kbest_X.pkl'))\n",
    "    TEST_X = pickle.load(open('tmp\\kbest_TEST_X.pkl'))\n",
    "    y = pickle.load(open('tmp\\kbest_y.pkl'))\n",
    "else:\n",
    "    # this will load processed data\n",
    "    print('Loading normal Processed Data')\n",
    "    X = pickle.load(open('tmp\\processed_X.pkl'))\n",
    "    TEST_X = pickle.load(open('tmp\\processed_TEST_X.pkl'))\n",
    "\n",
    "# # y = pickle.load(open('tmp\\processed_y.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** PCA **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# feature extraction\n",
    "pca = PCA(n_components=4)\n",
    "fit = pca.fit(X)\n",
    "\n",
    "plt.figure(figsize=(12, 3))\n",
    "\n",
    "_ = plt.scatter (range(len(fit.explained_variance_ratio_)), fit.explained_variance_ratio_.cumsum())\n",
    "\n",
    "_ = plt.xlabel('cumsum of explained variance')\n",
    "\n",
    "print(fit.explained_variance_ratio_.cumsum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = pca.transform(X)\n",
    "TEST_X = pca.transform(TEST_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X.shape, TEST_X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Saving Processed Data **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(X, open('tmp\\pca_X.pkl', 'w'))\n",
    "pickle.dump(TEST_X, open('tmp\\pca_TEST_X.pkl', 'w'))\n",
    "# pickle.dump(y, open('tmp\\pca_y.pkl', 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised Learning\n",
    "\n",
    "* Unsupervised Learning Exploration(Gaussian Process, Neural Nets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Loading Pre-Processed Data **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "load = 1\n",
    "\n",
    "if load == 1:\n",
    "    print('Loading PCA Processed Data')\n",
    "    X = pickle.load(open('tmp\\pca_X.pkl'))\n",
    "    TEST_X = pickle.load(open('tmp\\pca_TEST_X.pkl'))\n",
    "\n",
    "elif load == 2:\n",
    "    # this will load kbest\n",
    "    print('Loading KBest Processed Data')\n",
    "    X = pickle.load(open('tmp\\kbest_X.pkl'))\n",
    "    TEST_X = pickle.load(open('tmp\\kbest_TEST_X.pkl'))\n",
    "elif load == 3:\n",
    "    # this will load processed data\n",
    "    print('Loading normal Processed Data')\n",
    "    X = pickle.load(open('tmp\\processed_X.pkl'))\n",
    "    TEST_X = pickle.load(open('tmp\\processed_TEST_X.pkl'))\n",
    "\n",
    "# # y = pickle.load(open('tmp\\processed_y.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(X.shape, y.shape, TEST_X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture as GMM\n",
    "from sklearn.metrics import silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# For future analysis\n",
    "GMM_Centers = []\n",
    "\n",
    "__check_for  = 1000\n",
    "\n",
    "for i in range(2, 7):\n",
    "    # TODO: Apply your clustering algorithm of choice to the reduced data \n",
    "    clusterer = GMM(n_components=i, random_state=42)\n",
    "    clusterer.fit(X)\n",
    "\n",
    "    # TODO: Predict the cluster for each data point\n",
    "    preds = clusterer.predict(X)\n",
    "\n",
    "    # TODO: Find the cluster centers\n",
    "    GMM_Centers.append(clusterer.means_)\n",
    "\n",
    "    # score = silhouette_score(X, preds)\n",
    "    score = silhouette_score(X[:__check_for], preds[:__check_for])\n",
    "\n",
    "    print(i, score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# For future analysis\n",
    "KMM_Centers = []\n",
    "\n",
    "# Testing each category\n",
    "for i in range(2, 7):\n",
    "\n",
    "    clusterer = KMeans(init='k-means++', n_clusters=i, n_init=10)\n",
    "    clusterer.fit(X)\n",
    "\n",
    "    preds = clusterer.predict(X)\n",
    "\n",
    "    centers = clusterer.cluster_centers_\n",
    "    \n",
    "    KMM_Centers.append(centers)\n",
    "\n",
    "#     score = silhouette_score(X, preds)\n",
    "    score = silhouette_score(X[:__check_for], preds[:__check_for])\n",
    "    print(i, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i = 2\n",
    "\n",
    "clusterer = KMeans(init='k-means++', n_clusters=i, n_init=10)\n",
    "clusterer.fit(X)\n",
    "preds = clusterer.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "score = silhouette_score(X[:__check_for], preds[:__check_for])\n",
    "print(i, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(X.shape, TEST_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = pd.DataFrame(X)\n",
    "X['new'] = clusterer.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TEST_X = pd.DataFrame(TEST_X)\n",
    "TEST_X['new'] = clusterer.predict(TEST_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(X.shape, TEST_X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning\n",
    "\n",
    "* Supervised Learning(GBT Trees, Nearest Neighbours, RF, One-vs-One)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test-Train Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "load = 3\n",
    "\n",
    "if load == 1:\n",
    "    print('Loading PCA Processed Data')\n",
    "    X = pickle.load(open('tmp\\pca_X.pkl'))\n",
    "    TEST_X = pickle.load(open('tmp\\pca_TEST_X.pkl'))\n",
    "\n",
    "elif load == 2:\n",
    "    # this will load kbest\n",
    "    print('Loading KBest Processed Data')\n",
    "    X = pickle.load(open('tmp\\kbest_X.pkl'))\n",
    "    TEST_X = pickle.load(open('tmp\\kbest_TEST_X.pkl'))\n",
    "elif load == 3:\n",
    "    # this will load processed data\n",
    "    print('Loading normal Processed Data')\n",
    "    X = pickle.load(open('tmp\\processed_X.pkl'))\n",
    "    TEST_X = pickle.load(open('tmp\\processed_TEST_X.pkl'))\n",
    "\n",
    "y = pickle.load(open('tmp\\processed_y.pkl'))\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\n",
    "\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GBT Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "GradientBoostingClassifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf_gbt = GradientBoostingClassifier(random_state=192)\n",
    "\n",
    "clf_gbt = clf_gbt.fit(X_train, y_train)\n",
    "\n",
    "print('score:', clf_gbt.score(X_test, y_test))\n",
    "\n",
    "# ('score:', 0.75252525252525249) k_best score\n",
    "\n",
    "# ('score:', 0.75400673400673401) preprocessed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nearest Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# modelling\n",
    "clf_knn = KNeighborsClassifier()\n",
    "clf_knn.fit(X_test, y_test)\n",
    "\n",
    "# score\n",
    "clf_knn.score(X_train, y_train)\n",
    "\n",
    "# 0.55842873176206509 k_best\n",
    "# 0.55840628507295176 preprocessed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf_rf = RandomForestClassifier(random_state=192)\n",
    "clf_rf = clf_rf.fit(X_train, y_train)\n",
    "\n",
    "print('Score:' + str(clf_rf.score(X_test, y_test)))\n",
    "\n",
    "# 0.79542087542087547 # (n_jobs=-1, random_state=192)\n",
    "# 0.800942760943 k_best\n",
    "# 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(list(zip(X.columns, clf_rf.feature_importances_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.title('Random Forest - Features Importance - Histogram')\n",
    "plt.ylabel('No.of Features')\n",
    "plt.xlabel('Feature Importance')\n",
    "\n",
    "_ = sns.distplot(clf_rf.feature_importances_ * 100, bins=20, hist=True, kde=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.title('Random Forest - Features (relative*) Importance - Histogram')\n",
    "plt.ylabel('No.of Features')\n",
    "plt.xlabel('Feature Importance - Bin size is 5')\n",
    "\n",
    "tmp = 100 * (clf_rf.feature_importances_  - min(clf_rf.feature_importances_)) / max(clf_rf.feature_importances_)\n",
    "\n",
    "_ = sns.distplot(tmp, bins=20, hist=True, kde=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bag = []\n",
    "kbest_selected_cols = []\n",
    "for col, score in zip(X.columns, tmp):\n",
    "    if score < 5:\n",
    "        bag.append(col)\n",
    "    else:\n",
    "        kbest_selected_cols.append(col)\n",
    "\n",
    "print('Removed Cols:', bag)\n",
    "print('Rest of Cols', kbest_selected_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# n_estimators=150, criterion='entropy', class_weight=\"balanced_subsample\", \n",
    "\n",
    "clf_rf = RandomForestClassifier(random_state=192, n_jobs=-1)\n",
    "# class_weight=\"balanced_subsample\"/\"balanced\"\n",
    "# criterion=\"gini\"/\"entropy\"\n",
    "\n",
    "clf_rf = clf_rf.fit(X[kbest_selected_cols], y_train)\n",
    "# pred = clf_rf.predict_proba(X_test)\n",
    "clf_rf.score(X_test[kbest_selected_cols], y_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "clf_svm = svm.SVC(kernel='linear')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "clf_svm?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "limit = 500\n",
    "clf_svm = clf_svm.fit(X_train[:limit], y_train[:limit])\n",
    "print('')\n",
    "print('Score:' + str(clf_svm.score(X_test, y_test)))\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsOneClassifier, OneVsRestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** One Vs One **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_multiclass_rf = OneVsOneClassifier(RandomForestClassifier(n_estimators=200,\n",
    "                                                        criterion='entropy',\n",
    "#                                                         class_weight=\"balanced_subsample\",\n",
    "                                                        n_jobs=-1))\n",
    "\n",
    "# 0.81265993265993264"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf_multiclass_rf = clf_multiclass_rf.fit(X_train, y_train)\n",
    "\n",
    "print('Classifier:', clf_multiclass_rf)\n",
    "\n",
    "print('Score:', clf_multiclass_rf.score(X_train, y_train))\n",
    "print('Score:', clf_multiclass_rf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** One vs Rest **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf_multiclass_rf = OneVsRestClassifier(RandomForestClassifier(random_state=192))\n",
    "\n",
    "clf_multiclass_rf = clf_multiclass_rf.fit(X_train, y_train)\n",
    "\n",
    "print('Classifier:', clf_multiclass_rf)\n",
    "print('Train Score: ', clf_multiclass_rf.score(X_train, y_train))\n",
    "print('Test Score:', clf_multiclass_rf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf_rf.random_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter tuning\n",
    "\n",
    "\n",
    "From above analysis we can see that Random Forest CLF performed better than most other and so here we shall optimise it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# max_features\n",
    "np.sqrt(len(X_train.columns)), np.log(len(X_train.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.log2(len(X_train.columns)), np.sqrt (len(X_train.columns)), len(X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'balanced_subsample balanced'.split(), 'gini entropy'.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'n_estimators': [10, 50, 100, 150, 200],\n",
    "    'class_weight': ['balanced_subsample', 'balanced'],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_features': ['log2', 'auto', 25],\n",
    "    'random_state': [192]\n",
    "}\n",
    "\n",
    "# clf_rf = RandomForestClassifier(n_estimators=150, criterion='entropy', class_weight=\"balanced_subsample\", n_jobs=-1, random_state=192)\n",
    "# 0.81346801346801345\n",
    "\n",
    "GS_CV = RandomizedSearchCV(RandomForestClassifier(), parameters)\n",
    "\n",
    "GS_CV.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(GS_CV.best_params_, GS_CV.best_score_)\n",
    "# {'n_estimators': 200, 'max_features': 'log2', 'random_state': 192, 'criterion': 'entropy',\n",
    "#  'class_weight': 'balanced_subsample'} 0.806717171717"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv_results = pd.DataFrame(GS_CV.cv_results_, columns=[u'mean_fit_time', u'mean_score_time', u'mean_test_score',\n",
    "       u'mean_train_score', u'param_class_weight', u'param_criterion',\n",
    "       u'param_max_features', u'param_n_estimators', u'params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv_results.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set(color_codes=True)\n",
    "\n",
    "np.random.seed(sum(map(ord, \"regression\")))\n",
    "tips = sns.load_dataset(\"tips\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ax=plt.figure(figsize=(8,8))\n",
    "_ = sns.lmplot(x=\"mean_test_score\", y=\"mean_train_score\", hue=\"param_max_features\", data=cv_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* Checking \"clf_rf\" RF performance"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "sam_confusion_maxtrix(y_test, clf_rf.predict(X_test), ['func', 'non f', 'repair'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBOOST"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "gbm = xgb.XGBClassifier(max_depth=3, n_estimators=100, learning_rate=0.05).fit(X_train, y_train)\n",
    "\n",
    "gbm_predictions = gbm.predict(X_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "print(sum(gbm_predictions == y_test)/ (1.0 * len(y_test)) # 0.7279461279461279)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sam_confusion_maxtrix(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Selection**\n",
    "\n",
    "+ Check for which model is performing best and using it.\n",
    "+ Check to apply the one-vs-many//one-vs-one wrapper.\n",
    "+ Check for 'test_train_split' for which X,y to be used for training"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "clf_rf = RandomForestClassifier(n_estimators=150, criterion='entropy', class_weight=\"balanced_subsample\", n_jobs=-1)\n",
    "\n",
    "clf_rf = clf_rf.fit(X, y)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# saving the index\n",
    "test_ids = RAW_TEST_X.index\n",
    "\n",
    "# predicint the values\n",
    "predictions = clf.predict(TEST_X)\n",
    "print(predictions.shape)\n",
    "\n",
    "# Converting int to its respective Labels\n",
    "predictions_labels = le.inverse_transform(predictions)\n",
    "\n",
    "# setting up column name & save file\n",
    "sub = pd.DataFrame(predictions_labels, columns=['status_group'])\n",
    "sub.head()\n",
    "sub.insert(loc=0, column='id', value=test_ids)\n",
    "sub.reset_index()\n",
    "sub.to_csv('submit.csv', index=False)\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = map(lambda x: x * x, xrange(11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "462px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "widgets": {
   "state": {
    "034ac6993cda42e0a3b7dacf79b00d2f": {
     "views": [
      {
       "cell_index": 56
      }
     ]
    },
    "c731c422cc3b43088c7b596ce39cf111": {
     "views": [
      {
       "cell_index": 56
      }
     ]
    },
    "cabc57e5eef349e0bdb49ef3bdf9c4e7": {
     "views": [
      {
       "cell_index": 56
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
