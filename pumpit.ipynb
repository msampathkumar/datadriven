{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# PUMP IT UP\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Introduction:**\n",
    "Using the data gathered from Taarifa and the Tanzanian Ministry of Water, can we predict which pumps are functional, which need some repairs, and which don't work at all? Predicting one of these three classes based and a smart understanding of which waterpoints will fail, can improve the maintenance operations and ensure that clean, potable water is available to communities across Tanzania.\n",
    "\n",
    "This is also an intermediate-level competition by [DataDriven][1]! All code & support scripts are in [Github Repo][2]\n",
    "\n",
    "[1]: https://www.drivendata.org/competitions/7/ \"Link to Competetion Page\"\n",
    "[2]: https://github.com/msampathkumar/datadriven_pumpit \"User Code\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "# %load_ext writeandexecute\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "sns.set(color_codes=True)\n",
    "\n",
    "# seed\n",
    "np.random.seed(69572)\n",
    "\n",
    "# import sys\n",
    "# sys.path = sys.path + ['/Users/sampathkumarm/Desktop/devbox/Sam-DS/Kaggle/datadriven']\n",
    "\n",
    "import scripts\n",
    "\n",
    "import imp\n",
    "imp.reload(scripts)\n",
    "\n",
    "from scripts.sam_value_counts import sam_dataframe_cols_value_count_analysis, sam_dataframe_markup_value_counts\n",
    "from scripts.sam_confusion_matrix import sam_plot_confusion_matrix, sam_confusion_maxtrix\n",
    "\n",
    "import sys\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from IPython.core.getipython import get_ipython\n",
    "from IPython.core.magic import (Magics, magics_class,  cell_magic)\n",
    "\n",
    "try:\n",
    "    from StringIO import StringIO\n",
    "except ImportError:\n",
    "    from io import StringIO\n",
    "\n",
    "from markdown import markdown\n",
    "from IPython.core.display import HTML\n",
    "from IPython.display import display\n",
    "\n",
    "@magics_class\n",
    "class MarkdownMagics(Magics):\n",
    " \n",
    "    @cell_magic\n",
    "    def asmarkdown(self, line, cell):\n",
    "        buffer = StringIO()\n",
    "        stdout = sys.stdout\n",
    "        sys.stdout = buffer\n",
    "        try:\n",
    "            exec(cell, locals(), self.shell.user_ns)\n",
    "        except:\n",
    "            sys.stdout = stdout\n",
    "            raise\n",
    "        sys.stdout = stdout\n",
    "        return HTML(\"<p>{}</p>\".format(markdown(buffer.getvalue(), extensions=['markdown.extensions.extra'])))\n",
    "        return buffer.getvalue() + 'test'\n",
    "    \n",
    "    def timer_message(self, start_time):\n",
    "#         print self\n",
    "        time_diff = (now() - start_time).total_seconds()\n",
    "        if time_diff < 0.001:\n",
    "            time_diff = 0\n",
    "            print('\\n<pre>In', time_diff, 'Secs</pre>')\n",
    "        else:\n",
    "            print('\\n<pre>In', time_diff, 'Secs</pre>')\n",
    "\n",
    "    @cell_magic\n",
    "    def timer(self, line, cell):\n",
    "        import datetime\n",
    "        now = datetime.datetime.now\n",
    "        start_time = now()\n",
    "        buffer = StringIO()\n",
    "        stdout = sys.stdout\n",
    "        sys.stdout = buffer\n",
    "        try:\n",
    "            exec(cell, locals(), self.shell.user_ns)\n",
    "            self.timer_message(start_time)\n",
    "        except:\n",
    "            sys.stdout = stdout\n",
    "            raise\n",
    "        sys.stdout = stdout\n",
    "        return HTML(\"<p>{}</p>\".format(markdown(buffer.getvalue(), extensions=['markdown.extensions.extra'])))\n",
    "        return buffer.getvalue() + 'test'\n",
    " \n",
    "get_ipython().register_magics(MarkdownMagics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "RAW_X = pd.read_csv('data/traning_set_values.csv', index_col='id')\n",
    "RAW_y = pd.read_csv('data/training_set_labels.csv', index_col='id')\n",
    "RAW_TEST_X = pd.read_csv('data/test_set_values.csv', index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# proportion of labels  available\n",
    "RAW_y.status_group.value_counts() / RAW_y.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Frame Shape: (59400, 23) TotColumns: 0 ObjectCols: 23\n",
      "Data Frame Shape: (14850, 23) TotColumns: 0 ObjectCols: 23\n",
      "Data Frame Shape: (44550, 23) TotColumns: 0 ObjectCols: 23\n"
     ]
    }
   ],
   "source": [
    "def check_shape(*dfs):\n",
    "    for df in dfs:\n",
    "        print('Share of Data Frame is', df.shape)\n",
    "\n",
    "def df_check_stats(*dfs):\n",
    "    \"\"\"To print DataFrames Shape & Cols details.\n",
    "\n",
    "    Input: X, y, TEST_X,..\n",
    "    \"\"\"\n",
    "    stmt = \"Data Frame Shape: %1.15s TotColumns: %1.15s ObjectCols: %1.15s\"\n",
    "    for df in dfs:\n",
    "        df_shape = str(df.shape)\n",
    "        obj_cols, all_cols = len(df.dtypes[df.dtypes == '0']), len(df.dtypes)\n",
    "        print(stmt % (df_shape, obj_cols, all_cols))\n",
    "    return\n",
    "\n",
    "df_check_stats(X, X_test, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Shape of RAW_X', RAW_X.shape)\n",
    "print('Shape of RAW_y', RAW_y.shape)\n",
    "print('Shape of RAW_TEST_X', RAW_TEST_X.shape)\n",
    "\n",
    "# ('Shape of RAW_X', (59400, 39))\n",
    "# ('Shape of RAW_y', (59400, 1))\n",
    "# ('Shape of RAW_TEST_X', (14850, 39))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i, col in enumerate(RAW_X.columns):\n",
    "    print('|%d|%s|%d|' % (i, col, len(RAW_X[col].value_counts())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# integer colums\n",
    "cols_ints = '''amount_tsh\n",
    "gps_height\n",
    "longitude\n",
    "latitude\n",
    "num_private\n",
    "region_code\n",
    "district_code\n",
    "population\n",
    "construction_year'''.splitlines()\n",
    "\n",
    "# bool\n",
    "cols_bool = 'public_meeting permit'.split()\n",
    "\n",
    "# date\n",
    "cols_date = ['date_recorded']\n",
    "\n",
    "print('INT COlS: ', len(cols_ints))\n",
    "print('BOOL COLS:', len(cols_bool))\n",
    "print('Date COLS:', len(cols_date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Share of Data Frame: (59400, 23) All Columns: 0 Object Cols: 23\n",
      "Share of Data Frame: (59400, 23) All Columns: 0 Object Cols: 23\n",
      "Share of Data Frame: (59400, 23) All Columns: 0 Object Cols: 23\n"
     ]
    }
   ],
   "source": [
    "def df_check_stats(*dfs):\n",
    "    for df in dfs:\n",
    "        df_shape = str(df.shape)\n",
    "        obj_cols, all_cols = len(df.dtypes[X.dtypes == '0']), len(df.dtypes)\n",
    "        print(\"Share of Data Frame: %1.15s All Columns: %1.15s Object Cols: %1.15s\" % (df_shape, obj_cols, all_cols))\n",
    "\n",
    "df_check_stats(X, X, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_object_dtypes(df,others=True):\n",
    "    dtype = object\n",
    "    if others:\n",
    "        return df.dtypes[df.dtypes == dtype]\n",
    "    else:\n",
    "        return df.dtypes[df.dtypes != dtype]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show_object_dtypes(RAW_TEST_X, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show_object_dtypes(RAW_TEST_X, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cols_values_counts_dataframe\n",
    "\n",
    "As we can see in above *describe* output, we seem to have lots of categorical values so let start exploring them a bit.\n",
    "\n",
    "Lets start taking into believe everything is a Categorical Columns and check their data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "columns = RAW_X.columns\n",
    "values_counts_bag = [len(RAW_X[column].value_counts()) for column in columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "_ = sns.distplot(values_counts_bag, hist=True, kde=False,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Example of how np-log transforms data**\n",
    "\n",
    "    >>> np.log([0.001, 0.01, 0.1, 1, 10, 100, 1000])\n",
    "\n",
    "    array([-6.90775528, -4.60517019, -2.30258509,  0.        ,  2.30258509,\n",
    "            4.60517019,  6.90775528])\n",
    "\n",
    "As you can see in np-log example, we can learn that when a list of values vary significantly(exponentially) then their logarithms moves linearly. As we(I) feel comfortable in studying linear plot and linear information, we did a np.log to values counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols_values_counts_dataframe = pd.DataFrame(np.log(values_counts_bag), index=columns, columns=['Value Counts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Values Counts:', values_counts_bag)\n",
    "\n",
    "print('\\nLog of Values Counts:', cols_values_counts_dataframe.T.values)\n",
    "\n",
    "_ = sns.distplot(cols_values_counts_dataframe.T.values, hist=True, kde=False,)\n",
    "\n",
    "plt.title('Historgram of  Object Feature`s (log2 of) Unique Values counts')\n",
    "plt.xlabel('Features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cols_values_counts_dataframe.plot(kind='barh', figsize=(12, 12))\n",
    "_ = plt.plot((2, 2), (0, 38))\n",
    "_ = plt.plot((4, 4), (0, 38), '-g')\n",
    "_ = plt.plot((6, 6), (0, 38), '-r')\n",
    "_ = plt.plot((8, 8), (0, 38), '-y')\n",
    "print('We seem to have some special categories where value counts are high.')\n",
    "\n",
    "plt.title('Features Values Counts for comparision')\n",
    "plt.xlabel ('Log of Unique Values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sam_dataframe_cols_value_count_analysis(RAW_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Checking rest of the columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cols_value_count_limit_fraction = 0.01\n",
    "cols_value_count_limit_log_value = np.log(RAW_X.shape[0] * cols_value_count_limit_fraction)\n",
    "\n",
    "\n",
    "print('Total Number of Records:', RAW_X.shape[0], '- Log val is:', np.log(RAW_X.shape[0]))\n",
    "print('%s percent of Number of Records:' % (cols_value_count_limit_fraction * 100),\\\n",
    "      RAW_X.shape[0] * cols_value_count_limit_fraction,\\\n",
    "      ' - Log val is:',  cols_value_count_limit_log_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cols_categorical_check\n",
    "\n",
    "Here in this project, `cols_categorical_check` refers to list of columns for which caution check is considered. Reason for this check is, we would need more data to explain other columns & target cols with respect to it.\n",
    "\n",
    "Lets consider these columns with more 5% of values as non categorical values and since our problem statement is choosing which category, we will try to minimise the category and see how our performance changes(improves or not)\n",
    "\n",
    "To begin we will consider that those categories with more than `cols_value_count_limit_fraction` percentage as the upper limit allowed. Any column with other data will pruged to become some to other information"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "show_object_dtypes(RAW_X, True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "show_object_dtypes(RAW_X, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cols_non_categorical = show_object_dtypes(RAW_X, True).index.tolist()\n",
    "\n",
    "cols_date_numerics = show_object_dtypes(RAW_X, True).index.tolist()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "list(cols_date_numerics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cols_categorical_check = []\n",
    "\n",
    "for col, vc in cols_values_counts_dataframe.iterrows():\n",
    "    if col in cols_non_categorical:\n",
    "        if float(vc) > cols_value_count_limit_log_value:\n",
    "            cols_categorical_check.append(col)\n",
    "\n",
    "print('Columns we need to moderate are:', cols_categorical_check)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All `cols_date_numerics`, are date & other numeric data which can be made into buckets or reducing precision. Thus we can bound number of categories in data as the more variety of data we have, we need more information specific to each category which all might end with **curse of dimensionality**.\n",
    "\n",
    "During pre-processing states we shall do following\n",
    "TODO\n",
    "* limiting check experiments on our **`cols_date_numerics`** & **`cols_categorical_check`** to be under **`cols_value_count_limit_fraction`**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "print('Log limit for categories:', cols_value_count_limit_log_value)\n",
    "print('Actual limit for categories:', cols_value_count_limit_fraction * RAW_X.shape[0])\n",
    "\n",
    "RAW_X[cols_categorical_check].head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "source": [
    "RAW_X[cols_categorical_check].head(15)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "_ = sns.distplot(RAW_X.gps_height, hist=True, kde=False, rug=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "_ = sns.distplot(RAW_X.population, hist=True, kde=False, rug=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "_ = sns.jointplot(x='longitude', y='latitude', data=RAW_X)\n",
    "plt.xlabel('longitude')\n",
    "plt.ylabel('latitude')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "source": [
    "%%asmarkdown\n",
    "\n",
    "# To generate a Markup Table\n",
    "tmp = sam_dataframe_markup_value_counts(dataframe=RAW_X, max_print_value_counts=10, show_plots=False, figsize=(9, 2))\n",
    "\n",
    "for each in tmp:\n",
    "    print(each)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observations & TODO\n",
    "\n",
    "* Most of the data seems categorical\n",
    "\n",
    "* Need to check **cols_date_numerics**(TODO1)\n",
    "    * we shall convert date -> day, month, year, weekday, total_no_of_day_from_reference_point. These splits for two reasons.\n",
    "        * Reason1: It might be possible that in some location all specific set of complaints are registered on a start/mid/at end of the month. It might also be possible that they are registered on every Monday or so.\n",
    "        * Reason2: Taking as much information as possible.\n",
    "* Need to check **cols_categorical_check**(TODO2) \n",
    "    * longitutude & latitude seem to hold (0,0) instead of NULL which is acting as outlier for now\n",
    "\n",
    "* Following pairs looks closesly related - cleanup (TODO3)\n",
    "    * quantity & quantity_group\n",
    "    * quality_group & water_quality\n",
    "    * extraction_type, extraction_type_class & extraction_type_group\n",
    "\n",
    "* Other - cleanup (TODO4)\n",
    "    * recorded_by, seems to hold only a single value\n",
    "    * population & amount_tsh, values are for some given as zero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generic Transformations\n",
    "** Num/Bool Tranformations **\n",
    "\n",
    "* date_recorded to Int\n",
    "* public_meeting to Int\n",
    "* permit to Int\n",
    "* longitude to Float(less precision)\n",
    "* latitude to Float(less precision)\n",
    "\n",
    "Precision Description of Longititude and Latitude is available here at below [link](http://gis.stackexchange.com/questions/8650/measuring-accuracy-of-latitude-and-longitude)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Reloading the data\n",
    "\n",
    "RAW_X = pd.read_csv('data/traning_set_values.csv', index_col='id')\n",
    "RAW_y = pd.read_csv('data/training_set_labels.csv', index_col='id')\n",
    "RAW_TEST_X = pd.read_csv('data/test_set_values.csv', index_col='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Int Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "strptime = datetime.datetime.strptime\n",
    "\n",
    "DATE_FORMAT = \"%Y-%m-%d\"\n",
    "REFERENCE_DATE_POINT = strptime('2000-01-01', DATE_FORMAT)\n",
    "\n",
    "if RAW_X.date_recorded.dtype == 'O':\n",
    "\n",
    "    # convert it to datetime format\n",
    "    f = lambda x: strptime(str(x), DATE_FORMAT)\n",
    "    RAW_X.date_recorded = RAW_X.date_recorded.apply(f)\n",
    "    RAW_TEST_X.date_recorded = RAW_TEST_X.date_recorded.apply(f)\n",
    "\n",
    "    # week day\n",
    "    f = lambda x: x.weekday()\n",
    "    RAW_X['date_recorded_weekday'] = RAW_X.date_recorded.apply(f)\n",
    "    RAW_TEST_X['date_recorded_weekday'] = RAW_TEST_X.date_recorded.apply(f)\n",
    "\n",
    "    # date\n",
    "    f = lambda x: x.day\n",
    "    RAW_X['date_recorded_date'] = RAW_X.date_recorded.apply(f)\n",
    "    RAW_TEST_X['date_recorded_date'] = RAW_TEST_X.date_recorded.apply(f)\n",
    "\n",
    "    # month\n",
    "    f = lambda x: x.month\n",
    "    RAW_X['date_recorded_month'] = RAW_X.date_recorded.apply(f)\n",
    "    RAW_TEST_X['date_recorded_month'] = RAW_TEST_X.date_recorded.apply(f)\n",
    "\n",
    "    # year\n",
    "    f = lambda x: x.year\n",
    "    RAW_X['date_recorded_year'] = RAW_X.date_recorded.apply(f)\n",
    "    RAW_TEST_X['date_recorded_year'] = RAW_TEST_X.date_recorded.apply(f)\n",
    "\n",
    "    # total days\n",
    "    f = lambda x: (x - REFERENCE_DATE_POINT).days\n",
    "    RAW_X.date_recorded = RAW_X.date_recorded.apply(f)\n",
    "    RAW_TEST_X.date_recorded = RAW_TEST_X.date_recorded.apply(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Longitude & Latitude -- zero values fix\n",
    "\n",
    "# Filling Missing/OUTLIAR Values\n",
    "_ = np.mean(RAW_X[u'latitude'][RAW_X.latitude < -1.0].values)\n",
    "\n",
    "if not RAW_X.loc[RAW_X.latitude >= -1.0, u'latitude'].empty:\n",
    "    RAW_X.loc[RAW_X.latitude >= -1.0, u'latitude'] = _\n",
    "    RAW_TEST_X.loc[RAW_TEST_X.latitude >= -1.0, u'latitude'] = _\n",
    "\n",
    "\n",
    "# Filling Missing/OUTLIAR Values\n",
    "_ = np.mean(RAW_X[u'longitude'][RAW_X[u'longitude'] > 1.0].values)\n",
    "\n",
    "if not RAW_X.loc[RAW_X[u'longitude'] <= 1.0, u'longitude'].empty:\n",
    "    RAW_X.loc[RAW_X[u'longitude'] <= 1.0, u'longitude'] = _\n",
    "    RAW_TEST_X.loc[RAW_TEST_X[u'longitude'] <= 1.0, u'longitude'] = _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    if x is True:\n",
    "        return 1\n",
    "    elif x is False:\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "\n",
    "\n",
    "if (RAW_X.public_meeting.dtype != 'bool') and (RAW_X.permit.dtype != 'bool'):\n",
    "\n",
    "    # public_meeting\n",
    "    RAW_X.public_meeting = RAW_X.public_meeting.apply(f)\n",
    "    RAW_TEST_X.public_meeting = RAW_TEST_X.public_meeting.apply(f)\n",
    "\n",
    "    # permit\n",
    "    RAW_X.permit = RAW_X.permit.apply(f)\n",
    "    RAW_TEST_X.permit = RAW_TEST_X.permit.apply(f)\n",
    "\n",
    "print('Dtype of public_meetings & permit:',RAW_X.public_meeting.dtype, RAW_X.permit.dtype)\n",
    "print('')\n",
    "# checking\n",
    "if list(RAW_TEST_X.dtypes[RAW_TEST_X.dtypes != RAW_X.dtypes]):\n",
    "    raise Exception('RAW_X.dtypes and RAW_TEST_X.dtypes are not in Sync')\n",
    "else:\n",
    "    print('All in Good Shape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show_object_dtypes(RAW_X, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show_object_dtypes(RAW_X, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reducing geo location precision to 11 meters\n",
    "LONG_LAT_PRECISION = 0.001\n",
    "\n",
    "# Reducing Precision of Lat.\n",
    "if RAW_X.longitude.mean() < 50:\n",
    "    RAW_X.longitude = RAW_X.longitude // LONG_LAT_PRECISION\n",
    "    RAW_X.latitude = RAW_X.latitude // LONG_LAT_PRECISION\n",
    "    RAW_TEST_X.longitude = RAW_TEST_X.longitude // LONG_LAT_PRECISION\n",
    "    RAW_TEST_X.latitude = RAW_TEST_X.latitude // LONG_LAT_PRECISION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "_ = sns.jointplot(x='longitude', y='latitude', data=RAW_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Data Tranformations\n",
    "\n",
    "For **cols_categorical_check**, we are going to basic clean action like, lower and upper case issue. Clearning of non ascii values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def text_transformation(name):\n",
    "    \"\"\"Cleanup basic text issue in name(input).\n",
    "    \n",
    "    Removes text capitalisation, case, space and other non text ascii charecters\n",
    "        except space.\n",
    "    \"\"\"\n",
    "    if name:\n",
    "        name = name.lower().strip()\n",
    "        name = ''.join([i if 96 < ord(i) < 128 else ' ' for i in name])\n",
    "        if 'and' in name:\n",
    "            name = name.replace('and', ' ')\n",
    "\n",
    "        # clear double space\n",
    "        while '  ' in name:\n",
    "            name = name.replace('  ', ' ')\n",
    "        return name.strip()\n",
    "    return ''"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "source": [
    "%%asmarkdown\n",
    "\n",
    "print('''\n",
    "|Column|Prev.|Current|\n",
    "|------|-----|-------|''')\n",
    "for col in cols_categorical_check:\n",
    "    aa = len(RAW_X[col].unique())\n",
    "    RAW_X[col] = RAW_X[col].fillna('').apply(text_transformation)\n",
    "    RAW_TEST_X[col] = RAW_TEST_X[col].fillna('').apply(text_transformation)\n",
    "    bb = len(RAW_X[col].unique())\n",
    "    if aa != bb:\n",
    "        print('|%s|%i|%i|' % (col, aa, bb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# saving transformed data\n",
    "pickle.dump(obj=RAW_X, file=open('tmp\\clean_X.pkl', 'wb'))\n",
    "pickle.dump(RAW_TEST_X, open('tmp\\clean_TEST_X.pkl', 'wb'))\n",
    "# pickle.dump(y, open('tmp\\y.pkl', 'wb'))\n",
    "\n",
    "TEST_X, X = RAW_TEST_X, RAW_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Labeler\n",
    "\n",
    "Loading Custom Labeler is for the the purpose of reducing categories varieties by ignoring groups with lower frequencies and covering 80%(default) of the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from __future__ import print_function\n",
    "from ipywidgets import interact, interactive, fixed\n",
    "import ipywidgets as widgets\n",
    "\n",
    "from scripts import sam_custom_labeler\n",
    "\n",
    "CUST_CATEGORY_LABELER = sam_custom_labeler.CUST_CATEGORY_LABELER"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "help(CUST_CATEGORY_LABELER)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#\n",
    "# Run this to iteratively genertae following data\n",
    "# \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "labler = CUST_CATEGORY_LABELER()\n",
    "\n",
    "def select_col(col):\n",
    "    global labler\n",
    "    labler = CUST_CATEGORY_LABELER()\n",
    "    labler.fit(RAW_TEST_X[col])\n",
    "    print('Selected', col)\n",
    "\n",
    "ii = interact(select_col, col=['funder', 'installer', 'wpt_name', 'subvillage', 'ward', 'scheme_name'])\n",
    "\n",
    "# To check data coverage\n",
    "def f1(data=80):\n",
    "    labler.check_data_coverage(data_coverage=data)\n",
    "\n",
    "ii1 = interact(f1, data=(70, 100, .5))\n",
    "\n",
    "# To check groups coverage\n",
    "def f2(groups=80):\n",
    "    labler.check_group_coverage(groups)\n",
    "    \n",
    "ii2 = interact(f2, groups=(50, 100., .5))\n",
    "\n",
    "_ = '''\n",
    "Please select one of these slider to chose among the\n",
    " data coverage or groups coverage\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* funder:\n",
    "    * 100.0 percentage of DATA coverage mean, 1881 (in number) groups\n",
    "    * 97.0 percentage of DATA coverage mean, 592 (in number) groups ##\n",
    "    * 90.5 percentage of DATA coverage mean, 237 (in number) groups\n",
    "* installer:\n",
    "    * 100.0 percentage of DATA coverage mean, 1867 (in number) groups\n",
    "    * 97.0 percentage of DATA coverage mean, 599 (in number) groups ##\n",
    "\n",
    "* wpt_name:\n",
    "    * 80.0 percentage of DATA coverage mean, 24838 (in number) groups ##\n",
    "\n",
    "* subvillage:\n",
    "    * 80.5 percentage of DATA coverage mean, 8715 (in number) groups ##\n",
    "    * 83.0 percentage of DATA coverage mean, 9458 (in number) groups\n",
    "* ward:\n",
    "    * 80.0 percentage of DATA coverage mean, 998 (in number) groups ##\n",
    "    * 91.5 percentage of DATA coverage mean, 1397 (in number) groups\n",
    "    * 100.0 percentage of DATA coverage mean, 2093 (in number) groups\n",
    "* scheme_name:\n",
    "    * 100.0 percentage of DATA coverage mean, 2486 (in number) groups\n",
    "    * 91.5 percentage of DATA coverage mean, 870 (in number) groups\n",
    "    * 80.5 percentage of DATA coverage mean, 363 (in number) groups\n",
    "    * 85.0 percentage of DATA coverage mean, 524 (in number) groups ##    \n",
    "** NOTE **:\n",
    "    Marked with double hashes are the selected values for coverage\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##################################\n",
    "######### TESTING ################\n",
    "#################################\n",
    "\n",
    "labler = CUST_CATEGORY_LABELER()\n",
    "labler.fit(X.installer)\n",
    "\n",
    "# default data coverage is 80\n",
    "tmp = labler.transform()\n",
    "\n",
    "print('data coveraged', labler.DATA_COVERAGE_LIMIT)\n",
    "print('grous coveraged', len(tmp.value_counts()))\n",
    "\n",
    "print('---------------------')\n",
    "labler.DATA_COVERAGE_LIMIT = 90\n",
    "tmp = labler.transform()\n",
    "\n",
    "print('data coveraged', labler.DATA_COVERAGE_LIMIT)\n",
    "print('grous coveraged', len(tmp.value_counts()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##################################\n",
    "######### IMPLEMENT ##############\n",
    "#################################\n",
    "\n",
    "if 'custom_labler' not in dir():\n",
    "    custom_labler = defaultdict(CUST_CATEGORY_LABELER)\n",
    "    tmp = { 'funder': 97,\n",
    "      'installer': 97,\n",
    "      'wpt_name': 80,\n",
    "      'subvillage': 80,\n",
    "      'ward': 80,\n",
    "      'scheme_name': 85\n",
    "      }\n",
    "\n",
    "    for col, limit  in tmp.items():\n",
    "        labler = custom_labler[col]\n",
    "        labler.DATA_COVERAGE_LIMIT = limit\n",
    "        labler.fit(X[col])\n",
    "        print('')\n",
    "        print('-' * 15, col.upper())\n",
    "\n",
    "    #     custom_labler[col].check_data_coverage(limit)\n",
    "        RAW_X[col] = labler.transform()\n",
    "else:\n",
    "    print('\"custom_labler\" seems is already defined, please check')\n",
    "    \n",
    "print(RAW_X.shape, RAW_TEST_X.shape, all(RAW_X.columns == RAW_TEST_X.columns))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "source": [
    "drop_cols = ['wpt_name',]\n",
    "\n",
    "RAW_X.drop(drop_cols, axis=1, inplace=True)\n",
    "RAW_TEST_X.drop(drop_cols, axis=1, inplace=True)\n",
    "print('Removed Cols:', drop_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Encoder\n",
    "\n",
    "Label Encoder with DefaultDict for quick data transformation\n",
    "http://stackoverflow.com/questions/24458645/label-encoding-across-multiple-columns-in-scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(RAW_X.shape, RAW_TEST_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "RAW_X.dtypes[RAW_X.dtypes == 'O'].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RAW_X.fillna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "d = defaultdict(preprocessing.LabelEncoder)\n",
    "\n",
    "tmp = RAW_X.dtypes[RAW_X.dtypes == 'O'].index.tolist()\n",
    "\n",
    "RAW_X[tmp] = RAW_X[tmp].fillna('Other')\n",
    "RAW_TEST_X[tmp] = RAW_TEST_X[tmp].fillna('Other')\n",
    "\n",
    "# Labels Fit\n",
    "sam = pd.concat([RAW_X, RAW_TEST_X]).apply(lambda x: d[x.name].fit(x))\n",
    "\n",
    "# Labels Transform - Training Data\n",
    "X = RAW_X.apply(lambda x: d[x.name].transform(x))\n",
    "TEST_X = RAW_TEST_X.apply(lambda x: d[x.name].transform(x))\n",
    "\n",
    "le = preprocessing.LabelEncoder().fit(RAW_y[u'status_group'])\n",
    "y = le.transform(RAW_y[u'status_group'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show_object_dtypes(RAW_X, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show_object_dtypes(X, True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "sam_dataframe_cols_value_count_analysis(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pickle\n",
    "\n",
    "** Pickle Save **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# saving transformed data\n",
    "pickle.dump(X, open('tmp\\processed_X.pkl', 'wb'))\n",
    "pickle.dump(TEST_X, open('tmp\\processed_TEST_X.pkl', 'wb'))\n",
    "pickle.dump(y, open('tmp\\processed_y.pkl', 'wb'))\n",
    "\n",
    "# saving label transformers\n",
    "pickle.dump(d, open('tmp\\d.pkl', 'wb'))\n",
    "pickle.dump(le, open('tmp\\le.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = pickle.load(open('tmp\\processed_X.pkl', 'rb'))\n",
    "TEST_X = pickle.load(open('tmp\\processed_TEST_X.pkl', 'rb'))\n",
    "y = pickle.load(open('tmp\\processed_y.pkl', 'rb'))\n",
    "\n",
    "# # Load this when you are about to do text transformation and submission\n",
    "# d = pickle.load(open('tmp\\d.pkl'))\n",
    "# le = pickle.load(open('tmp\\le.pkl'))\n",
    "\n",
    "print(X.shape, y.shape, y[:5])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "### Correlation Threshold\n",
    "\n",
    "To remove all feature with correlaiton more than 80%"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "if list(X.dtypes[X.dtypes == 'O']):\n",
    "    print('Please check there are still some OBJECT COLUMNS PRESENT')\n",
    "else:\n",
    "    ss = X.corr().fillna(0)\n",
    "\n",
    "    # postive or negitive - both good\n",
    "    ss = ss.applymap(lambda x: x if x and x > 0 else -1 * x)\n",
    "    \n",
    "    # wish to know only strong corr\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    sns.heatmap(ss)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# wish to know only strong corr\n",
    "plt.figure(figsize=(18, 18))\n",
    "sns.heatmap(ss.applymap(lambda x: x if x > 0.90 else 0))\n",
    "\n",
    "len(X[_col_].value_counts()), len(X[_row_].value_counts())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "source": [
    "np.set_printoptions(precision=2)\n",
    "\n",
    "bag = []\n",
    "\n",
    "for _col_ in ss.index:\n",
    "    for _row_ in ss.columns:\n",
    "        if _col_ not in bag:\n",
    "            if (ss[_col_][_row_] > 0.8 and (ss[_col_][_row_] < 1.0)):\n",
    "                try:\n",
    "                    print((_col_, len(X[_col_].value_counts()),\n",
    "                           _row_, len(X[_row_].value_counts()),\n",
    "                           ss[_col_][_row_]))\n",
    "                except KeyError:\n",
    "                    # few extra cols are added\n",
    "                    pass\n",
    "#         bag.append(_row_)\n",
    "#         bag.append(_col_)\n",
    "\n",
    "del _col_, _row_, bag"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "source": [
    "%%asmarkdown\n",
    "\n",
    "print ('''\n",
    "|Column Name|VCount|Column Name|VCount|Corr|\n",
    "|-----------|------|-----------|------|----|''')\n",
    "\n",
    "tmp = '''\n",
    "('date_recorded', 356, 'date_recorded_year', 5, 0.95920911743658788)\n",
    "('extraction_type', 18, 'extraction_type_group', 13, 0.94952351098756882)\n",
    "('extraction_type_group', 13, 'extraction_type', 18, 0.94952351098756882)\n",
    "('source', 10, 'source_type', 7, 0.94381787586073784)\n",
    "('source_type', 7, 'source', 10, 0.94381787586073784)\n",
    "('waterpoint_type', 7, 'waterpoint_type_group', 6, 0.98215380609123037)\n",
    "('waterpoint_type_group', 6, 'waterpoint_type', 7, 0.98215380609123037)\n",
    "('date_recorded_year', 5, 'date_recorded', 356, 0.95920911743658788)\n",
    "'''\n",
    "\n",
    "while ' ' in tmp:\n",
    "    tmp = tmp.replace(' ', '')\n",
    "\n",
    "tmp = tmp.strip().replace('\\'', '')\n",
    "print(tmp.replace(\",\", '|').replace('(', '|').replace(')', '|'))\n",
    "\n",
    "del tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variance Threshold\n",
    "\n",
    "To remove all features that are either one or zero (on or off) in more than 80% of the samples.\n",
    "\n",
    "http://scikit-learn.org/stable/modules/feature_selection.html#removing-features-with-low-variance\n",
    "\n",
    "http://stackoverflow.com/questions/29298973/removing-features-with-low-variance-scikit-learn/34850639#34850639"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X.dtypes[X.dtypes != np.int64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scripts.sam_variance_check import get_low_variance_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X, removed_features, ranking_variance_thresholds = get_low_variance_columns(dframe=X,\n",
    "                                                                            threshold=(0.85 * (1 - 0.85)),\n",
    "                                                                            autoremove=True)\n",
    "\n",
    "print('\\nLow Variance Columns', removed_features)\n",
    "\n",
    "if removed_features:\n",
    "    TEST_X.drop(removed_features, axis=1, inplace=True)\n",
    "    print('cleanup completed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Shape of X is', X.shape)\n",
    "print('Shape of TEST_X is', TEST_X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select K Best\n",
    "\n",
    "* For regression: f_regression, mutual_info_regression\n",
    "* For classification: chi2, f_classif, mutual_info_classif\n",
    "\n",
    "\n",
    "Random Forest Classifier score: RandomForestClassifier(n_estimators=150, criterion='entropy', class_weight=\"balanced_subsample\", n_jobs=-1)\n",
    "* chi2 0.81225589225589223\n",
    "*  f_classic 0.81138047138047142\n",
    "* mutual_info_classif 0.81037037037037041"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2, f_classif, mutual_info_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X.copy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ranking_selectkbest = dict(zip(cols_names, fit.scores_))\n",
    "kbest_selected_cols =  [_ for _ in cols_names[:kbest_cols]]\n",
    "% pprint\n",
    "ranking_selectkbest\n",
    "print('Removed Columns:\\n\\t', ','.join([ _ for _ in X.columns if _ not in kbest_selected_cols ]))\n",
    "print('\\nSelected Columns:\\n\\t', ','.join(kbest_selected_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(X.columns) , str(fns.__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kbest_cols = len(X.columns) -5\n",
    "\n",
    "print(('Shape of X:', X.shape))\n",
    "for fns in [chi2, f_classif, mutual_info_classif]:\n",
    "    print((str(fns.__name__),game(SelectKBest(score_func=fns, k=kbest_cols).fit(X, y).transform(X), y, model='rf')))\n",
    "\n",
    "for fns in [chi2, f_classif, mutual_info_classif]:\n",
    "    print((str(fns.__name__),game(SelectKBest(score_func=fns, k=kbest_cols).fit(X, y).transform(X), y, model='gbt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('''\n",
    "('Shape of X:', (59400, 42))\n",
    "\n",
    "('chi2', (0.98478114478114476, 0.79548821548821547))\n",
    "('f_classif', (0.98381593714927051, 0.79569023569023567))\n",
    "('mutual_info_classif', (0.98505050505050507, 0.79919191919191923))\n",
    "\n",
    "('chi2', (0.75800224466891131, 0.75535353535353533))\n",
    "('f_classif', (0.75755331088664424, 0.75575757575757574))\n",
    "('mutual_info_classif', (0.75795735129068464, 0.75515151515151513))\n",
    "'''.replace(', (', ', ').replace('))', ')').replace('(', '|').replace(')', '|').replace(', ', '|'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bag  = [\n",
    "# {'cols': 1, 'test': 0.5511111111111111, 'train': 0.5545679012345679},\n",
    "#  {'cols': 9, 'test': 0.650976430976431, 'train': 0.658294051627385},\n",
    " {'cols': 17, 'test': 0.7022895622895623, 'train': 0.7092480359147025},\n",
    " {'cols': 25, 'test': 0.7517171717171717, 'train': 0.7534455667789001},\n",
    " {'cols': 25, 'test': 0.75171717171717167, 'train': 0.75344556677890007},\n",
    " {'cols': 28, 'test': 0.7531986531986532, 'train': 0.75537598204264866},\n",
    " {'cols': 31, 'test': 0.75346801346801351, 'train': 0.7551290684624018},\n",
    " {'cols': 33, 'test': 0.7545454545454545, 'train': 0.7562738496071829},\n",
    " {'cols': 34, 'test': 0.75535353535353533, 'train': 0.75658810325476988},\n",
    " {'cols': 35, 'test': 0.75542087542087544, 'train': 0.75665544332210999},\n",
    " {'cols': 36, 'test': 0.75427609427609432, 'train': 0.75586980920314251},\n",
    " {'cols': 37, 'test': 0.75535353535353533, 'train': 0.75800224466891131},\n",
    " {'cols': 38, 'test': 0.75582491582491584, 'train': 0.75797979797979798},\n",
    " {'cols': 39, 'test': 0.75589225589225584, 'train': 0.75797979797979798}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "for kbest_cols in range(18, 25):\n",
    "# for kbest_cols in range(23, 33, 2):\n",
    "# for kbest_cols in range(26, 29):\n",
    "    fit = SelectKBest(score_func=chi2, k=kbest_cols).fit(X, y)\n",
    "    cols_names = X.columns\n",
    "    kbest_selected_cols =  [_ for _ in cols_names[:kbest_cols]]\n",
    "\n",
    "    kbest_X = pd.DataFrame(fit.transform(X.copy()))\n",
    "    kbest_TEST_X = pd.DataFrame(fit.transform(TEST_X.copy()))\n",
    "#     kbest_X.columns = kbest_selected_cols\n",
    "#     kbest_TEST_X.columns = kbest_selected_cols\n",
    "\n",
    "    # print('Before KBest', X.shape, TEST_X.shape, len(y))\n",
    "    # print('After KBest', kbest_X.shape, kbest_TEST_X.shape, len(y))\n",
    "\n",
    "    train_score, test_score = game(kbest_X, y, model='gbt')\n",
    "    bag.append({'cols': kbest_cols, 'train': train_score, 'test': test_score})\n",
    "\n",
    "# print(', '.join(kbest_selected_cols).upper())\n",
    "\n",
    "bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sorted(bag, key=lambda x : x['cols'])\n",
    "bag  = [\n",
    "# {'cols': 1, 'test': 0.5511111111111111, 'train': 0.5545679012345679},\n",
    "#  {'cols': 9, 'test': 0.650976430976431, 'train': 0.658294051627385},\n",
    " {'cols': 17, 'test': 0.7022895622895623, 'train': 0.7092480359147025},\n",
    " {'cols': 25, 'test': 0.7517171717171717, 'train': 0.7534455667789001},\n",
    " {'cols': 28, 'test': 0.7531986531986532, 'train': 0.75537598204264866},\n",
    " {'cols': 31, 'test': 0.75346801346801351, 'train': 0.7551290684624018},\n",
    " {'cols': 33, 'test': 0.7545454545454545, 'train': 0.7562738496071829},\n",
    " {'cols': 34, 'test': 0.75535353535353533, 'train': 0.75658810325476988},\n",
    " {'cols': 35, 'test': 0.75542087542087544, 'train': 0.75665544332210999},\n",
    " {'cols': 36, 'test': 0.75427609427609432, 'train': 0.75586980920314251},\n",
    " {'cols': 37, 'test': 0.75535353535353533, 'train': 0.75800224466891131},\n",
    " {'cols': 38, 'test': 0.75582491582491584, 'train': 0.75797979797979798},\n",
    " {'cols': 39, 'test': 0.75589225589225584, 'train': 0.75797979797979798},\n",
    " {'cols': 18, 'test': 0.70430976430976433, 'train': 0.70985409652076314},\n",
    " {'cols': 19, 'test': 0.70430976430976433, 'train': 0.70985409652076314},\n",
    " {'cols': 20, 'test': 0.70484848484848484, 'train': 0.70904601571268233},\n",
    " {'cols': 21, 'test': 0.70397306397306403, 'train': 0.71160493827160498},\n",
    " {'cols': 22, 'test': 0.70801346801346798, 'train': 0.71331088664421993},\n",
    " {'cols': 23, 'test': 0.75077441077441076, 'train': 0.75173961840628511},\n",
    " {'cols': 24, 'test': 0.75077441077441076, 'train': 0.75173961840628511}]\n",
    "\n",
    "bag = pd.DataFrame(bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.legend?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.pointplot(x='cols', y='test', data=bag, color='green')\n",
    "sns.pointplot(x='cols', y='train', data=bag, color='red', markers=\"x\", linestyles='--')\n",
    "plt.title('GBT KBest Columns Selection')\n",
    "plt.legend(['test(green)',' train(red)'], )\n",
    "plt.ylabel('GBT Score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** kbest conclusion **:\n",
    "\n",
    "Best selected columns\n",
    "```\n",
    "AMOUNT_TSH, DATE_RECORDED, FUNDER, GPS_HEIGHT, INSTALLER, LONGITUDE, LATITUDE, NUM_PRIVATE, BASIN, SUBVILLAGE, REGION, REGION_CODE, DISTRICT_CODE, LGA, WARD, POPULATION, PUBLIC_MEETING, SCHEME_MANAGEMENT, SCHEME_NAME, PERMIT, CONSTRUCTION_YEAR, EXTRACTION_TYPE, EXTRACTION_TYPE_GROUP, EXTRACTION_TYPE_CLASS, MANAGEMENT, MANAGEMENT_GROUP, PAYMENT, PAYMENT_TYPE\n",
    "```\n",
    "\n",
    "``` Python\n",
    "# results of previous runs\n",
    "[{'cols': 1, 'test': 0.52659932659932662, 'train': 0.57483726150392822},\n",
    " {'cols': 5, 'test': 0.68962962962962959, 'train': 0.94240179573512906},\n",
    " {'cols': 9, 'test': 0.7211447811447812, 'train': 0.97638608305274976},\n",
    " {'cols': 13, 'test': 0.75380471380471381, 'train': 0.97955106621773291},\n",
    " {'cols': 17, 'test': 0.76134680134680133, 'train': 0.98071829405162736},\n",
    " {'cols': 21, 'test': 0.76511784511784509, 'train': 0.98076318742985413},\n",
    " {'cols': 25, 'test': 0.80033670033670035, 'train': 0.98316498316498313},\n",
    " {'cols': 29, 'test': 0.80053872053872055, 'train': 0.98379349046015707},\n",
    " {'cols': 33, 'test': 0.80040404040404045, 'train': 0.98390572390572395},\n",
    " {'cols': 37, 'test': 0.79993265993265994, 'train': 0.98341189674523011}]\n",
    "\n",
    "[{'cols': 23, 'test': 0.7976430976430976, 'train': 0.9836812570145903},\n",
    " {'cols': 25, 'test': 0.80033670033670035, 'train': 0.98316498316498313},\n",
    " {'cols': 27, 'test': 0.80101010101010106, 'train': 0.9829405162738496},\n",
    " {'cols': 29, 'test': 0.80053872053872055, 'train': 0.98379349046015707},\n",
    " {'cols': 31, 'test': 0.80000000000000004, 'train': 0.98381593714927051}]\n",
    "\n",
    "[{'cols': 26, 'test': 0.80309764309764309, 'train': 0.98359147025813698},\n",
    " {'cols': 27, 'test': 0.80101010101010106, 'train': 0.9829405162738496},\n",
    " {'cols': 28, 'test': 0.80222222222222217, 'train': 0.98334455667789}]\n",
    "```\n",
    "\n",
    "\n",
    "As per Okham Razor's rules, we are going to select the simplest and well performing. Luckily, we have got kbest_selected_cols at **26** which is comparitively top performer among other K-selections and also lower than actualy number of columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kbest_cols = 26\n",
    "\n",
    "fit = SelectKBest(score_func=chi2, k=kbest_cols).fit(X, y)\n",
    "cols_names = X.columns\n",
    "kbest_selected_cols =  [_ for _ in cols_names[:kbest_cols]]\n",
    "\n",
    "kbest_X = pd.DataFrame(fit.transform(X))\n",
    "kbest_TEST_X = pd.DataFrame(fit.transform(TEST_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kbest_X.shape, kbest_TEST_X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(kbest_X, open('tmp\\kbest_X.pkl', 'wb'))\n",
    "pickle.dump(kbest_TEST_X, open('tmp\\kbest_TEST_X.pkl', 'wb'))\n",
    "pickle.dump(y, open('tmp\\kbest_y.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(kbest_X, open('tmp\\kbest_X.pkl', 'wb'))\n",
    "pickle.dump(kbest_TEST_X, open('tmp\\kbest_TEST_X.pkl', 'wb'))\n",
    "pickle.dump(y, open('tmp\\kbest_y.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "load = 2\n",
    "\n",
    "if load == 2:\n",
    "    # this will load kbest\n",
    "    print('Loading KBest Processed Data')\n",
    "    X = pickle.load(open('tmp\\kbest_X.pkl', 'rb'))\n",
    "    TEST_X = pickle.load(open('tmp\\kbest_TEST_X.pkl', 'rb'))\n",
    "    y = pickle.load(open('tmp\\kbest_y.pkl', 'rb'))\n",
    "elif load == 1:\n",
    "    # this will load processed data\n",
    "    print('Loading Normal Processed Data')\n",
    "    X = pickle.load(open('tmp\\processed_X.pkl', 'rb'))\n",
    "    TEST_X = pickle.load(open('tmp\\processed_TEST_X.pkl', 'rb'))\n",
    "\n",
    "# # y = pickle.load(open('tmp\\processed_y.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** PCA **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# feature extraction\n",
    "pca = PCA(n_components=15)\n",
    "fit = pca.fit(X)\n",
    "\n",
    "plt.figure(figsize=(12, 3))\n",
    "\n",
    "_ = plt.scatter(range(len(fit.explained_variance_ratio_)), fit.explained_variance_ratio_.cumsum())\n",
    "\n",
    "_ = plt.xlabel('cumilative sum of explained variance')\n",
    "_ = plt.ylabel('score')\n",
    "\n",
    "\n",
    "print(fit.explained_variance_ratio_.cumsum())\n",
    "print()\n",
    "print(('Score', game(pca.transform(X), y, 'gbt')))\n",
    "\n",
    "\n",
    "# (0.97580246913580249, 0.60511784511784517) # KBest dataset\n",
    "# (0.97564534231200895, 0.60552188552188557) # Normal Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ss = pd.DataFrame(fit.components_)\n",
    "ss = ss.applymap(lambda x: x if x > 0 else -1 * x)\n",
    "display(ss.describe().T)\n",
    "\n",
    "ss.plot(kind='bar', figsize=(125, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# feature extraction\n",
    "lda = LinearDiscriminantAnalysis(n_components=16)\n",
    "fit = lda.fit(X, y)\n",
    "\n",
    "plt.figure(figsize=(12, 3))\n",
    "\n",
    "_ = plt.scatter (range(len(fit.explained_variance_ratio_)), fit.explained_variance_ratio_.cumsum())\n",
    "\n",
    "_ = plt.xlabel('cumilative sum of explained variance')\n",
    "_ = plt.ylabel('score')\n",
    "\n",
    "\n",
    "print(fit.explained_variance_ratio_.cumsum())\n",
    "\n",
    "print(('\\nScore', game(lda.transform(X), y)))\n",
    "\n",
    "\n",
    "# (0.97580246913580249, 0.60511784511784517) # KBest dataset\n",
    "# (0.97564534231200895, 0.60552188552188557) # Normal Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ss = pd.DataFrame(fit.coef_)\n",
    "ss = ss.applymap(lambda x: x if x > 0 else -1 * x)\n",
    "display(ss.describe().T)\n",
    "\n",
    "ss.plot(kind='bar', figsize=(125, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = pca.transform(X)\n",
    "TEST_X = pca.transform(TEST_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X.shape, TEST_X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Saving Processed Data **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(X, open('tmp\\pca_X.pkl', 'wb'))\n",
    "pickle.dump(TEST_X, open('tmp\\pca_TEST_X.pkl', 'wb'))\n",
    "# pickle.dump(y, open('tmp\\pca_y.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised Learning\n",
    "\n",
    "* Unsupervised Learning Exploration(Gaussian Process, Neural Nets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Loading Pre-Processed Data **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "load = 3\n",
    "\n",
    "if load == 1:\n",
    "    print('Loading PCA Processed Data')\n",
    "    X = pickle.load(open('tmp\\pca_X.pkl', 'rb'))\n",
    "    TEST_X = pickle.load(open('tmp\\pca_TEST_X.pkl', 'rb'))\n",
    "    print(game(X, y, model='rf'))\n",
    "\n",
    "elif load == 2:\n",
    "    # this will load kbest\n",
    "    print('Loading KBest Processed Data')\n",
    "    X = pickle.load(open('tmp\\kbest_X.pkl', 'rb'))\n",
    "    TEST_X = pickle.load(open('tmp\\kbest_TEST_X.pkl', 'rb'))\n",
    "    print(game(X, y, model='rf'))\n",
    "    \n",
    "elif load == 3:\n",
    "    # this will load processed data\n",
    "    print('Loading normal Processed Data')\n",
    "    X = pickle.load(open('tmp\\processed_X.pkl', 'rb'))\n",
    "    TEST_X = pickle.load(open('tmp\\processed_TEST_X.pkl', 'rb'))\n",
    "    print(game(X, y, model='rf'))\n",
    "\n",
    "# # y = pickle.load(open('tmp\\processed_y.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(X.shape, y.shape, TEST_X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture as GMM\n",
    "from sklearn.metrics import silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# For future analysis\n",
    "GMM_Centers = []\n",
    "\n",
    "__check_for  = 1000\n",
    "\n",
    "print ('clusters | score for top 1000')\n",
    "\n",
    "for i in range(2, 7):\n",
    "    # TODO: Apply your clustering algorithm of choice to the reduced data \n",
    "    clusterer = GMM(n_components=i, random_state=42)\n",
    "    clusterer.fit(X)\n",
    "\n",
    "    # TODO: Predict the cluster for each data point\n",
    "    preds = clusterer.predict(X)\n",
    "\n",
    "    # TODO: Find the cluster centers\n",
    "    GMM_Centers.append(clusterer.means_)\n",
    "\n",
    "    # score = silhouette_score(X, preds)\n",
    "    score = silhouette_score(X[:__check_for], preds[:__check_for])\n",
    "\n",
    "    print(i, score)\n",
    "    \n",
    "# clusters | score for top 1000\n",
    "# 2 0.484879234998\n",
    "# 3 0.377180934294\n",
    "# 4 0.334333476259\n",
    "# 5 0.29213724894\n",
    "# 6 0.27643712696"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# For future analysis\n",
    "KMM_Centers = []\n",
    "\n",
    "# Testing each category\n",
    "for i in range(2, 7):\n",
    "\n",
    "    clusterer = KMeans(init='k-means++', n_clusters=i, n_init=10)\n",
    "    clusterer.fit(X)\n",
    "\n",
    "    preds = clusterer.predict(X)\n",
    "\n",
    "    centers = clusterer.cluster_centers_\n",
    "    \n",
    "    KMM_Centers.append(centers)\n",
    "\n",
    "#     score = silhouette_score(X, preds)\n",
    "    score = silhouette_score(X[:__check_for], preds[:__check_for])\n",
    "    print(i, score)\n",
    "    \n",
    "# clusters | score for top 1000\n",
    "# 2 0.502005229628\n",
    "# 3 0.377168744959\n",
    "# 4 0.325091546516\n",
    "# 5 0.303811069492\n",
    "# 6 0.304265445159"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i = 2\n",
    "\n",
    "clusterer = KMeans(init='k-means++', n_clusters=i, n_init=10)\n",
    "clusterer.fit(X)\n",
    "preds = clusterer.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "score = silhouette_score(X[:__check_for], preds[:__check_for])\n",
    "print(i, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = pd.DataFrame(X)\n",
    "X['new'] = clusterer.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TEST_X = pd.DataFrame(TEST_X)\n",
    "TEST_X['new'] = clusterer.predict(TEST_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(X.shape, TEST_X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning\n",
    "\n",
    "* Supervised Learning(GBT Trees, Nearest Neighbours, RF, One-vs-One)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test-Train Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------\n",
      "Loading KBest Processed Data\n",
      "RandomForestClassifier(random_state=192)\n",
      "----------\n",
      "Tranining Score\n",
      "------------------------------------------------\n",
      "AC Score: 0.984646464646 F1 Score: 0.984711501502\n",
      "Testing Score\n",
      "------------------------------------------------\n",
      "AC Score: 0.796498316498 F1 Score: 0.803530383556\n",
      "------------------------------------------------\n",
      "(59400, 23) (59400,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "load = 2\n",
    "\n",
    "np.set_printoptions(precision=4)\n",
    "print('------------------------------------------------')\n",
    "\n",
    "if load == 1:\n",
    "    print('Loading PCA Processed Data')\n",
    "    X = pickle.load(open('tmp\\pca_X.pkl', 'rb'))\n",
    "    TEST_X = pickle.load(open('tmp\\pca_TEST_X.pkl', 'rb'))\n",
    "    y = pickle.load(open('tmp\\processed_y.pkl', 'rb'))\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\n",
    "    model_rf(X_train, y_train)\n",
    "\n",
    "\n",
    "elif load == 2:\n",
    "    # this will load kbest\n",
    "    print('Loading KBest Processed Data')\n",
    "    X = pickle.load(open('tmp\\kbest_X.pkl', 'rb'))\n",
    "    TEST_X = pickle.load(open('tmp\\kbest_TEST_X.pkl', 'rb'))\n",
    "    y = pickle.load(open('tmp\\processed_y.pkl', 'rb'))\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\n",
    "    model_rf(X_train, y_train)\n",
    "\n",
    "elif load == 3:\n",
    "    # this will load processed data\n",
    "    print('Loading normal Processed Data')\n",
    "    X = pickle.load(open('tmp\\processed_X.pkl', 'rb'))\n",
    "    TEST_X = pickle.load(open('tmp\\processed_TEST_X.pkl', 'rb'))\n",
    "    y = pickle.load(open('tmp\\processed_y.pkl', 'rb'))\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\n",
    "    model_rf(X_train, y_train)\n",
    "\n",
    "print('------------------------------------------------')\n",
    "\n",
    "print(X.shape, y.shape)\n",
    "\n",
    "import sklearn.metrics as sk_metrics\n",
    "\n",
    "def check_metric(y_pred, y_test, show_cm=True):\n",
    "    if show_cm:\n",
    "        print('------------------------------------------------')\n",
    "        print(sk_metrics.classification_report(y_pred, y_test))\n",
    "    print('------------------------------------------------')\n",
    "    print('AC Score:', sk_metrics.accuracy_score(y_pred, y_test),\n",
    "          'F1 Score:', sk_metrics.f1_score(y_pred, y_test, average='weighted'))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GBT Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "clf_gbt = GradientBoostingClassifier(random_state=192)\n",
    "\n",
    "clf_gbt = clf_gbt.fit(X_train, y_train)\n",
    "\n",
    "# metric\n",
    "y_train_pred = clf_gbt.predict(X_train)\n",
    "y_pred = clf_gbt.predict(X_test)\n",
    "print('GradientBoostingClassifier(random_state=192)')\n",
    "print('----------')\n",
    "print('Tranining Score')\n",
    "check_metric(y_train_pred, y_train, show_cm=False)\n",
    "print('Testing Score')\n",
    "check_metric(y_pred, y_test, show_cm=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nearest Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# modelling\n",
    "clf_knn = KNeighborsClassifier()\n",
    "clf_knn.fit(X_test, y_test)\n",
    "\n",
    "# metric\n",
    "y_train_pred = clf_knn.predict(X_train)\n",
    "y_pred = clf_knn.predict(X_test)\n",
    "print('KNeighborsClassifier()')\n",
    "print('----------')\n",
    "print('Tranining Score')\n",
    "check_metric(y_train_pred, y_train, show_cm=False)\n",
    "print('Testing Score')\n",
    "check_metric(y_pred, y_test, show_cm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "\n",
    "def model_rf(X_train, y_train):\n",
    "    \"\"\"\n",
    "    Random Forest\n",
    "    \"\"\"\n",
    "    clf_rf = RandomForestClassifier(random_state=192)\n",
    "    clf_rf = clf_rf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf_rf.predict(X_test)\n",
    "\n",
    "    # metric\n",
    "    y_train_pred = clf_rf.predict(X_train)\n",
    "    y_pred = clf_rf.predict(X_test)\n",
    "    print('RandomForestClassifier(random_state=192)')\n",
    "    print('----------')\n",
    "    print('Tranining Score')\n",
    "    check_metric(y_train_pred, y_train, show_cm=False)\n",
    "    print('Testing Score')\n",
    "    check_metric(y_pred, y_test, show_cm=False)\n",
    "    \n",
    "model_rf(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(list(zip(X.columns, clf_rf.feature_importances_)))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "plt.title('Random Forest - Features Importance - Histogram')\n",
    "plt.ylabel('No.of Features')\n",
    "plt.xlabel('Feature Importance')\n",
    "\n",
    "_ = sns.distplot(clf_rf.feature_importances_ * 100, bins=20, hist=True, kde=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "plt.title('Random Forest - Features (relative*) Importance - Histogram')\n",
    "plt.ylabel('No.of Features')\n",
    "plt.xlabel('Feature Importance - Bin size is 5')\n",
    "\n",
    "tmp = 100 * (clf_rf.feature_importances_  - min(clf_rf.feature_importances_)) / max(clf_rf.feature_importances_)\n",
    "\n",
    "_ = sns.distplot(tmp, bins=20, hist=True, kde=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "source": [
    "bag = []\n",
    "kbest_selected_cols = []\n",
    "for col, score in zip(X.columns, tmp):\n",
    "    if score < 5:\n",
    "        bag.append(col)\n",
    "    else:\n",
    "        kbest_selected_cols.append(col)\n",
    "\n",
    "print('Removed Cols:', bag)\n",
    "print('Rest of Cols', kbest_selected_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X[kbest_selected_cols].size / 40., X[kbest_selected_cols].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# n_estimators=150, criterion='entropy', class_weight=\"balanced_subsample\", \n",
    "\n",
    "clf_rf = RandomForestClassifier(random_state=192, n_jobs=-1)\n",
    "# class_weight=\"balanced_subsample\"/\"balanced\"\n",
    "# criterion=\"gini\"/\"entropy\"\n",
    "\n",
    "clf_rf = clf_rf.fit(X_train[kbest_selected_cols], y_train)\n",
    "# pred = clf_rf.predict_proba(X_test)\n",
    "clf_rf.score(X_test[kbest_selected_cols], y_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Random Forest with KBEST"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "# n_estimators=150, criterion='entropy', class_weight=\"balanced_subsample\", \n",
    "\n",
    "clf_rf = RandomForestClassifier(random_state=192, n_jobs=-1)\n",
    "# class_weight=\"balanced_subsample\"/\"balanced\"\n",
    "# criterion=\"gini\"/\"entropy\"\n",
    "\n",
    "clf_rf = clf_rf.fit(X_train[kbest_selected_cols], y_train)\n",
    "# pred = clf_rf.predict_proba(X_test)\n",
    "clf_rf.score(X_test[kbest_selected_cols], y_test)\n",
    "\n",
    "### SVM"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from sklearn import svm\n",
    "\n",
    "clf_svm = svm.SVC(kernel='linear')\n",
    "\n",
    "limit = 500\n",
    "clf_svm = clf_svm.fit(X_train[:limit], y_train[:limit])\n",
    "print('')\n",
    "print('Score:' + str(clf_svm.score(X_test, y_test)))\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model selection Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# metric\n",
    "for clf in [clf_gbt,\n",
    "#             clf_knn,\n",
    "            clf_rf]:\n",
    "    y_train_pred = clf.predict(X_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf)\n",
    "#     print('----------')\n",
    "#     print('Training Score')\n",
    "#     check_metric(y_train_pred, y_train)\n",
    "    print('----------')\n",
    "    print('Testing Score')\n",
    "    check_metric(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsOneClassifier, OneVsRestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** One Vs One **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: OneVsOneClassifier(estimator=RandomForestClassifier(bootstrap=True, class_weight='balanced_subsample',\n",
      "            criterion='entropy', max_depth=None, max_features='auto',\n",
      "            max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=150, n_jobs=-1,\n",
      "            oob_score=False, random_state=192, verbose=0, warm_start=False),\n",
      "          n_jobs=1)\n",
      "Score: 0.999797979798\n",
      "------------------------------------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.80      0.85      9052\n",
      "          1       0.32      0.61      0.42       576\n",
      "          2       0.77      0.84      0.81      5222\n",
      "\n",
      "avg / total       0.83      0.81      0.82     14850\n",
      "\n",
      "------------------------------------------------\n",
      "AC Score: 0.808821548822 F1 Score: 0.81669894899\n"
     ]
    }
   ],
   "source": [
    "clf_multiclass_rf = OneVsOneClassifier(RandomForestClassifier(\n",
    "    n_estimators=200,criterion='entropy', class_weight=\"balanced_subsample\",\n",
    "    random_state=192, n_jobs=-1\n",
    "))\n",
    "\n",
    "\n",
    "clf_multiclass_rf = OneVsOneClassifier(RandomForestClassifier(n_estimators=150,\n",
    "                       criterion='entropy',\n",
    "                       class_weight=\"balanced_subsample\",\n",
    "                       n_jobs=-1, random_state=192\n",
    "))\n",
    "\n",
    "clf_multiclass_rf = clf_multiclass_rf.fit(X_train, y_train)\n",
    "\n",
    "print('Classifier:', clf_multiclass_rf)\n",
    "\n",
    "print('Score:', clf_multiclass_rf.score(X_train, y_train))\n",
    "# print('Score:', clf_multiclass_rf.score(X_test, y_test))\n",
    "\n",
    "y_pred = clf_multiclass_rf.predict(X_test)\n",
    "check_metric(y_pred, y_test)\n",
    "# Score: 0.999775533109\n",
    "# Score: 0.813602693603"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# RandomForestClassifier(n_estimators=150, criterion='entropy', class_weight=\"balanced_subsample\", n_jobs=-1, random_state=192)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** One vs Rest **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf_multiclass_rf = OneVsRestClassifier(RandomForestClassifier(\n",
    "    n_estimators=200,criterion='entropy', class_weight=\"balanced_subsample\",\n",
    "    random_state=192, n_jobs=-1\n",
    "))\n",
    "\n",
    "clf_multiclass_rf = clf_multiclass_rf.fit(X_train, y_train)\n",
    "\n",
    "print('Classifier:', clf_multiclass_rf)\n",
    "print('Train Score: ', clf_multiclass_rf.score(X_train, y_train))\n",
    "# print('Test Score:', clf_multiclass_rf.score(X_test, y_test))\n",
    "\n",
    "y_pred = clf_multiclass_rf.predict(X_test)\n",
    "check_metric(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiclass Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "clf_multiclass1_rf = OneVsOneClassifier(RandomForestClassifier(\n",
    "    random_state=192, n_jobs=-1\n",
    "))\n",
    "clf_multiclass2_rf = OneVsRestClassifier(RandomForestClassifier(\n",
    "    random_state=192, n_jobs=-1\n",
    "))\n",
    "\n",
    "# Gradient Boosting\n",
    "clf_multiclass1_gb = OneVsOneClassifier(GradientBoostingClassifier(\n",
    "    random_state=192\n",
    "))\n",
    "clf_multiclass2_gb = OneVsRestClassifier(GradientBoostingClassifier(\n",
    "    random_state=192\n",
    "))\n",
    "\n",
    "\n",
    "clf_multiclass1_rf = clf_multiclass1_rf.fit(X_train, y_train)\n",
    "clf_multiclass2_rf = clf_multiclass2_rf.fit(X_train, y_train)\n",
    "clf_multiclass1_gb = clf_multiclass1_gb.fit(X_train, y_train)\n",
    "clf_multiclass2_gb = clf_multiclass2_gb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for clf in [clf_multiclass1_gb, clf_multiclass2_gb, clf_multiclass1_rf, clf_multiclass2_rf]:\n",
    "    y_train_pred = clf.predict(X_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print('---------------------------------------------------------------------------')\n",
    "    print(clf)\n",
    "    print('---------------------------------------------------------------------------')\n",
    "    print('Training Score')\n",
    "    check_metric(y_train_pred, y_train)\n",
    "    print('---------------------------------------------------------------------------')\n",
    "    print('Testing Score')\n",
    "    check_metric(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter tuning\n",
    "\n",
    "\n",
    "From above analysis we can see that Random Forest CLF performed better than most other and so here we shall optimise it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# max_features\n",
    "np.sqrt(len(X_train.columns)), np.log(len(X_train.columns))\n",
    "\n",
    "np.log2(len(X_train.columns)), np.sqrt (len(X_train.columns)), len(X_train.columns)\n",
    "\n",
    "'balanced_subsample balanced'.split(), 'gini entropy'.split()\n",
    "\n",
    "parameters = {\n",
    "    'n_estimators': [10, 50, 100, 150, 200],\n",
    "    'class_weight': ['balanced_subsample', 'balanced'],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_features': ['log2', 'auto', 25],\n",
    "    'random_state': [192]\n",
    "}\n",
    "\n",
    "# clf_rf = RandomForestClassifier(n_estimators=150, criterion='entropy', class_weight=\"balanced_subsample\", n_jobs=-1, random_state=192)\n",
    "# 0.81346801346801345\n",
    "\n",
    "GS_CV = RandomizedSearchCV(RandomForestClassifier(), parameters)\n",
    "\n",
    "GS_CV.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(GS_CV.best_params_, GS_CV.best_score_)\n",
    "# {'n_estimators': 200, 'max_features': 'log2', 'random_state': 192, 'criterion': 'entropy',\n",
    "#  'class_weight': 'balanced_subsample'} 0.806717171717\n",
    "\n",
    "cv_results = pd.DataFrame(GS_CV.cv_results_, columns=[u'mean_fit_time', u'mean_score_time', u'mean_test_score',\n",
    "       u'mean_train_score', u'param_class_weight', u'param_criterion',\n",
    "       u'param_max_features', u'param_n_estimators', u'params'])\n",
    "\n",
    "cv_results.head(2)\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(color_codes=True)\n",
    "\n",
    "np.random.seed(sum(map(ord, \"regression\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ax=plt.figure(figsize=(8,8))\n",
    "_ = sns.lmplot(x=\"mean_test_score\", y=\"mean_train_score\", hue=\"param_max_features\", data=cv_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* Checking \"clf_rf\" RF performance"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "sam_confusion_maxtrix(y_test, clf_rf.predict(X_test), ['func', 'non f', 'repair'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GBT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GradientBoostingClassifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'n_estimators': range(25, 250, 50),\n",
    "    'random_state': [192],\n",
    "    'min_samples_split': range(2, 8, 2),\n",
    "#     'min_samples_leaf': [.001, .01, .1, .3, .5],\n",
    "#     'max_depth': range(3, 8)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "GS_CV = RandomizedSearchCV(GradientBoostingClassifier(), parameters)\n",
    "\n",
    "GS_CV.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "GS_CV.best_params_, GS_CV.best_score_\n",
    "\n",
    "cv_results = pd.DataFrame(GS_CV.cv_results_, columns=[u'mean_test_score', u'mean_train_score', # two standard\n",
    "                                                      # here params keys\n",
    "                                                      u'param_min_samples_split', u'param_n_estimators', u'params'])\n",
    "\n",
    "sns.pairplot(data=cv_results, x_vars=['mean_test_score', 'mean_train_score'],\n",
    "             y_vars=['param_min_samples_split', 'param_n_estimators'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'n_estimators': [215, 225, 235,], # 225 best\n",
    "    'random_state': [192],\n",
    "    'min_samples_split': [5, 6],\n",
    "    'min_samples_leaf': [.001, .01, .1, .3, .5],\n",
    "#     'max_depth': range(3, 8)\n",
    "}\n",
    "GS_CV = RandomizedSearchCV(RandomForestClassifier(), parameters)\n",
    "\n",
    "GS_CV.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "cv_results = pd.DataFrame(GS_CV.cv_results_, columns=[u'mean_test_score', u'mean_train_score', # two standard\n",
    "                                                      # here params keys\n",
    "                                                      u'param_min_samples_leaf',\n",
    "                                                      u'param_min_samples_split', u'param_n_estimators',\n",
    "                                                      u'params'])\n",
    "\n",
    "_ = sns.pairplot(data=cv_results, x_vars=['mean_test_score', 'mean_train_score'],\n",
    "             y_vars=['param_min_samples_split', 'param_n_estimators', u'param_min_samples_leaf',])\n",
    "\n",
    "\n",
    "print(GS_CV.best_params_, GS_CV.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBOOST"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "gbm = xgb.XGBClassifier(max_depth=3, n_estimators=100, learning_rate=0.05).fit(X_train, y_train)\n",
    "\n",
    "gbm_predictions = gbm.predict(X_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "print(sum(gbm_predictions == y_test)/ (1.0 * len(y_test)) # 0.7279461279461279)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sam_confusion_maxtrix(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Selection**\n",
    "\n",
    "+ Check for which model is performing best and using it.\n",
    "+ Check to apply the one-vs-many//one-vs-one wrapper.\n",
    "+ Check for 'test_train_split' for which X,y to be used for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "GS_CV.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "clf_rf = OneVsOneClassifier(RandomForestClassifier(n_estimators=150,\n",
    "random_state=192,\n",
    "max_features='log2',\n",
    "class_weight='balanced_subsample',\n",
    "criterion='gini'))\n",
    "\n",
    "print (clf_rf)\n",
    "\n",
    "clf_rf = clf_rf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# saving the index\n",
    "test_ids = RAW_TEST_X.index\n",
    "\n",
    "# predicint the values\n",
    "predictions = clf_rf.predict(TEST_X)\n",
    "print(predictions.shape)\n",
    "\n",
    "# Converting int to its respective Labels\n",
    "predictions_labels = le.inverse_transform(predictions)\n",
    "\n",
    "# setting up column name & save file\n",
    "sub = pd.DataFrame(predictions_labels, columns=['status_group'])\n",
    "sub.head()\n",
    "sub.insert(loc=0, column='id', value=test_ids)\n",
    "sub.reset_index()\n",
    "sub.to_csv('submit.csv', index=False)\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores = '''\n",
    "0.7970\n",
    "0.786838161735000\n",
    "0.799663299663\n",
    "0.803097643097\n",
    "0.796498316498000\n",
    "0.699393939394\n",
    "0.709020068049\n",
    "0.779259259259000\n",
    "0.778047138047\n",
    "0.813468013468000\n",
    "0.808821548822\n",
    "'''.strip().splitlines()\n",
    "\n",
    "scores = map(lambda x: float(x) if x else None, scores)\n",
    "\n",
    "stages = '''\n",
    "Benchmark\n",
    "Algorithmn Selection\n",
    "\n",
    "KSelect chi2 Test(40+cols)\n",
    "KSelect Best(26)Cols\n",
    "KBest Processed Data\n",
    "\n",
    "PCA Processed Data Score\n",
    "Normal Processed Data\n",
    "\n",
    "OneVsOneClassifier\n",
    "OneVsRestClassifier\n",
    "\n",
    "Tuning\n",
    "Result\n",
    "'''.strip().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-45-3ec1e44df8ad>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-45-3ec1e44df8ad>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    print(list(scores)\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "print(list(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x11a4af6d8>]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqwAAAHcCAYAAAATCPhsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAPYQAAD2EBqD+naQAAIABJREFUeJzs3Xl03Gd99/33LNKMttG+L5bkTXZkx7acEIiNszhrAadA\ngJA7MRTT8rQPzQ3lboiTYiAHSGg4wGlzt3DgMZC0oSQOSZqSzQlkIybYjmPHjhctlq1dsnZpNKOZ\n+T1/zGIrtmOPtfxm+bzOybE1/s3oO7k00kfXXNf3shiGYSAiIiIiEqOsZhcgIiIiIvJ+FFhFRERE\nJKYpsIqIiIhITFNgFREREZGYpsAqIiIiIjFNgVVEREREYpoCq4iIiIjENAVWEREREYlpCqwiIiIi\nEtOiDqxer5fNmzdzySWXsHbtWrZu3XrWa1944QVuvPFGVq5cya233sqBAwem/PtPf/pTrr76ahoa\nGvj85z9PU1NT9M9ARERERBJa1IH1/vvv58CBAzz00ENs2bKFf/3Xf+X5558/7brGxka+9rWv8aUv\nfYmnnnqKuro6/vqv/xqPxwPAI488wi9+8Qu+8Y1v8Pjjj1NeXs4Xv/jFyL+LiIiIiECUgdXtdvPY\nY49xzz33UFdXx/r169m0aRMPP/zwade+9tprLFy4kI997GNUVlby1a9+lb6+PhobGwF44okn+MIX\nvsC6deuYN28e3/zmNxkYGGD37t0z88xEREREJCFEFVgPHjyI3+9nxYoVkdsaGhrYu3fvadfm5OTQ\n2NjI7t27MQyDbdu2kZWVRVVVFQB33nknH/nIRyLXWywWAEZGRi7oiYiIiIhIYrJHc3Fvby85OTnY\n7Sfvlp+fj8fjYWBggNzc3MjtN954Iy+99BKf/exnsdlsWK1WfvrTn5KVlQXAqlWrpjz2b37zG/x+\nPw0NDdN5PiIiIiKSYKJeEpCamjrltvDHXq93yu2Dg4P09fWxZcsWHn30UW666Sa+/vWv09/ff9rj\nvv3223z/+99n06ZN5OfnR/scRERERCSBRRVYHQ7HacE0/HFaWtqU2x944AEWL17MLbfcwtKlS/n2\nt79NWloajz/++JTr3nrrLTZt2sS6dev4+7//+6iKNwwjqutFREREJP5EtSSguLiYwcFBAoEAVmsw\n6/b19eF0OnG5XFOu3b9/P7fffnvkY4vFQl1dHR0dHZHb/vSnP/GlL32JtWvX8oMf/CDq4i0WC8PD\nbvz+QNT3lfhis1lxudI03klC451cNN7JReOdXMLjPV1RBdYlS5Zgt9vZs2dPZA3qzp07qa+vP+3a\noqKiSEeAsJaWFpYvXw7A4cOH+du//VuuuOIKfvCDH0QCcLT8/gA+n77gk4XGO7lovJOLxju5aLwl\nGlGlRKfTyYYNG9iyZQv79u1j+/btbN26lY0bNwLB2dZwH9Wbb76ZRx99lCeffJJjx47xwAMP0NnZ\nyV/+5V8C8I1vfIOysrLIuta+vr4p9xcRERERgShnWAHuuusuvvWtb7Fx40aysrK44447WL9+PQBr\n1qzhvvvu46abbuLGG2/E7Xbzk5/8hO7ubpYsWcKvfvUrcnNz6evr4+233wbgiiuumPL43/ve97jp\nppum/8xEREREJCFYjDjfuTQwMKa3FJKA3W4lNzdD450kNN7JReOdXDTeySU83tN1YQtHRURERETm\niAKriIiIiMQ0BVYRERERiWkKrCIiIiIS0xRYRURERCSmKbCKiIiISExTYBURERGRmKbAKiIiIiIx\nTYFVRERERGKaAquIiIiIxDQFVhERERGJaQqsIiIiIhLTFFhFREREZllb7yjHukcIBAyzS4lLdrML\nEBEREUlke4708S/b9mIAzlQb88tczC/PZkFFNvPLsklzKI6di/4PiYiIiMySSZ+f/9x+mPC86oTX\nz/6jA+w/OgCABSgvzGRhRTYLyrOZX5FNYbYTi8ViWs2xSIFVREREZJY8/+fj9A1NAPCRD1Xj8wdo\nbB/iaOcwPr+BQXC5QFvvKL9/qx2A7IxUFoRmYBeUZzOvJAu7LblXcSqwioiIiMyCwVEPT/+xFYCF\nFdn85dqayMzppC9Aa/cIjW1DNLYP0dg2yPD4JABDY152He5l1+FeAOw2KzWlWZEAO788G1d6qjlP\nyiQKrCIiIiKzYNvLTXgm/ViAz65fNOVt/hS7NTiLWp4NgGEY9A66Q+E1GGLbe8cwAJ8/wJG2IY60\nDUXuX5yXzoJyFwsrcphfnk1pfjrWBF5GoMAqIiIiMsNaOod5fV8XAJcvL2VeSdb7Xm+xWCjKTaco\nN50P1ZcCMD7ho7kjGF6PtA3R3DGMZ9IPQHf/ON3945HPkeG0Mz80+7qwPJuaUheOVNssPsO5pcAq\nIiIiMoMMw+CRF48Awa4An/hw7QU9TrrTTn1tPvW1+QD4AwHaesZobB+iKRRiTwwH18eOTfjY23SC\nvU0nALBaLFQWZ7LwlLWweS7nDDw7cyiwioiIiMygN9/toTH09v1HPlRNdqZjRh7XZrUyrySLeSVZ\nXN1QAcDAiCcSXhvbhzjWPYI/YBAwDFq7RmjtGmH7rjYA8lyOyDKEBRXZVBZlYrPGx2YuBVYRERGR\nGeKZ9PPoHxoBKMxxcs3qyln9fLlZDlbXFbG6rijy+Y92Dk9ZCzs24QOgf9jDm8M9vPluDwCpKVZq\nS10sqMgJbeZykeFMmdV6L5QCq4iIiMgMefZPx+gf9gDw6asWkmKf2xlMR4qNxVW5LK7KBYLLE7r6\nx092I2gfovPEOADeyQAHjw1y8Nhg5P7lBRnBdbChZQRFuWkx0RNWgVVERERkBvQPT/DMjmAbqyXz\nclm5sMDkioKbuUrzMyjNz2DtxWUAjLonp6yDbekcZtIXAKC9b4z2vjFeebsDgKz0lCnLCKpLskix\nz/1mLgVWERERkRnw2B+a8PoCWCxwy9ULY2Jm8kwy01JYsaCAFQuCgdrnD3C8ZzSyDraxbZDBUS8A\nI+OTvHWkj7eO9AFgt1mYV5IVCrE5LKjIJjtj9nvCKrCKiIiITFNj+xA7DnQDsG5FORVFmSZXdP6C\nBxO4qCl1ce0llRiGwYnhiSnrYI/3jGIY4PMbNLUP09Q+zHMcB4JrdcPhdWF5NmUFGVitMxvWFVhF\nREREpiFgGDyy/TAAaQ47N62tMbmi6bFYLBRkp1GQncZlS0sAcHt8tJyymaupYwi3J9gTtndwgt7B\nLt7YH+wJm+awUVsWDK+LqnJY25Ax7ZoUWEVERESm4Y13umjpHAFgw5qahDw2Nc1hZ2l1Hkur8wAI\nBAw6+sYiG7ka24boGXQD4Pb42d/Sz/6WfgDWNlRN+/MrsIqIiIhcoAmvj8debgKgJC+dq1aVm1zR\n3LBaLVQUZVJRlMkVK4PPeWjMG5x9bR/iSPsgrV0j+PzGjHw+BVYRERGRC/Q/b7QyFNqg9JmrF2C3\nxUcj/tmQnZFKw+JCGhYXAjDp89M94J6Rx07e/6siIiIi09A76Oa5N4Mbj+pr81g+3/w2VrEkxW6j\nutQ1I4+lwCoiIiJyAR79fSM+fwCrxcJnrlpodjkJTYFVREREJEqHjg2w81AvAFetKqesYPo74eXs\nFFhFREREohAIGPzn9iNAsAn/hjhvYxUPFFhFREREovDq3g6O94wCcNPaGjKcKSZXlPgUWEVERETO\n0/iEj8dfaQagvDCDdSvKTK4oOSiwioiIiJynp/94lJHxSQA+c/VCbFZFqbmg/8siIiIi56G7f5wX\ndgbbWK1YUMBFoVOfZPYpsIqIiIich/96qRF/wMBmtfDpqxaYXU5SUWAVEREROYf9Lf3saewD4JpL\nKinOSze5ouSiwCoiIiLyPvyBAL9+MdjGypWewkc/VG1uQUlIgVVERETkffzhrQ7a+8YA+Pi6+aQ5\n7CZXlHwUWEVERETOYtQ9yROvBttYVRVlsmZZqckVJScFVhEREZGzeOq1FsYmfADcsn4hVqvF5IqS\nk+a0RWLIpC9AV/847X2jtPeO0dU/Tk6Gg1WLClhUlaN+fyIic6i9b4yXdrcDsLquiMVVuSZXlLwU\nWEVM4PMH6O4fp71vjPbeMTr6xmjvG6NnwE3AME67/sXdbWSmpbByYQENi4tYWp2L3abwKiIyWwzD\n4L9ePELAMLDbrHzqivlml5TUFFhFZpE/EKBnwE17bzCQtvcFw2l3/zj+wOnB9FTOVBvFeel09Y/j\n8foZdU/y6t5OXt3bSZrDzooF+TQsLqK+Jo/UFNscPSMRkeSwt+kE77T0A3D9ByopyEkzuaLkpsAq\nMgMCAYPeQTdtvWN09I1GgmlX/zg+//sH09QUK2X5GZQXZFBWmEF5QSblBRnkuRxYLBYmfX7eaeln\n16Fe9hzpY9zjw+3x8cb+bt7Y340jxcay+fmsXlzIstp87V4VEZkmnz/Ar19qBCA7M5UbL5tnckWi\nn2wiUQgYBn1DE7T3jkbexu/oHaOzf5xJX+B975tit1Kanx4MpgUZlBcGg2l+thOr5eyL+FPsNlYu\nLGTlwkJ8/gAHWwfYeaiXt470MjI+iWfSz86DPew82IPdZqW+Jo+GxYWsWFhAhjNlpv8XiIgkvJd2\ntdHdPw7AJ9fNx5mquGS2qEfA6/XyzW9+kxdeeAGn08lf/dVf8fnPf/6M177wwgv88Ic/pLOzk6VL\nl3L33XezdOnSyL8//fTT/PjHP6a3t5c1a9Zw7733kpurBc1iPsMwODE8MWV9aXvfGJ0nxvBOvn8w\ntdsslORlUF4YCqYFwb8XZqdNe3ep3Walvjaf+tp8br9uMYePD7LrUC+7DvcwOOrF5w+wp7GPPY19\n2KwWlszLpWFxISsXFeJKT53W5xYRSQbD416efP0oADWlLj5YX2JuQQKAxTDOsMPjfdx7773s2rWL\n++67j7a2Nu68806+973vce211065rrGxkU984hPce++9rFy5kl/84hc899xzvPjiizgcDvbu3cvt\nt9/Ot7/9berq6rj33nvJyMjg3//936N6AgMDY/jOMbMl8c9ut5KbmzHj420YBgMjntM2P3WcGMPj\n9b/vfW1WCyV56ZFQWhYKpkW5aXO+mz9gGDR3DLPrUA+7DvXSNzQx5d8tFlhUkUPD4kIaFheRm+WY\n0/qiNVvjLbFJ451cYn28f/XsQf6wpwOAzbc1sKA82+SK4lt4vKcrqsDqdru57LLL+PnPf87q1asB\n+Ld/+zfeeOMNfvWrX0259he/+AVPP/00jz32GABjY2M0NDSwbds2LrroIu68806sVivf+973AOjq\n6uLKK69k+/btlJeXn/cTiNUveJlZ0/0GZxgGg6Pek4H0lHWmbs/7B1OrxUJxXtp7gmkmxblpMblT\n3zAMjnWPsjMUXrtCb2udan6Zi4bFRTQsLqQwBjcSxPoPNJlZGu/kEsvjfbxnlG9ufRPDgMsuKuav\nP3qR2SXFvZkKrFEtCTh48CB+v58VK1ZEbmtoaOAnP/nJadfm5OTQ2NjI7t27WblyJdu2bSMrK4uq\nqioA9uzZw9/8zd9Eri8pKaG0tJS33347qsAq8l7DY17ae08G0vCf4cbPZ2OxQFFOWmSmtKwgg4qC\nTIrz0kmxx14wPRuLxcK8kizmlWTxiXXzae8bi8y8Hu8ZBaCpY5imjmF+8/tG5hVnhWZeCynNn/43\nFRGReGQYBo9sP4xhBDfDfnKd2ljFkqgCa29vLzk5OdjtJ++Wn5+Px+NhYGBgyvrTG2+8kZdeeonP\nfvaz2Gw2rFYrP/3pT8nKyoo8VlFR0ZTHLygooKurazrPR5LIyLh3yvrSjlDrqFH35DnvW5jjpLwg\nc8qsaWl+ekK2hyovyKC8oIaPXV5D98A4uw/1svNQLy2dwwC0do/Q2j3C4680U1aQQcOiYHitLMrE\n8j6bwUREEsnuw30cPDYIwI0fmEeey2lyRXKqqAKr2+0mNXXqxo3wx16vd8rtg4OD9PX1sWXLFi6+\n+GIeeeQRvv71r/Pb3/6WvLw8JiYmzvhY732cc7HF4FuyMvPaesfYcbCXxmMDtPWM0N47xtDYub9W\nCrKdlBee3JEf/tORmnjB9HyUF2ZSXpjJR9fUcGJogp2Hetj5bg+Hjw9iAB2h2ej//uNRinPTWF1X\nxOq6ImrLXHMaXsOva72+k4PGO7nE4nhP+gI8+vtgG6s8l4O/uLwaexy9sxbLZmqcowqsDofjtEAZ\n/jgtbeo6uAceeIDFixdzyy23APDtb3+bG264gccff5xNmzad9bGczuh+o3G5Ym/9ncycwREPP3vy\nHV5+q+19ryvIdlJV4qKqJIuq4iyqSrKoLM4iXW2dzio3N4MF1fl85rolDAxPsOOdTv64t5O9TX0E\nAgbdA27+541W/ueNVgpy0vjQslI+tLyMuuo8bHN0lrZe38lF451cYmm8H3vpCD2DbgC+8LF6Sopc\nJlck7xVVYC0uLmZwcJBAIIA1tAu6r68Pp9OJyzV1cPfv38/tt98e+dhisVBXV0dHR3DnXVFREX19\nfVPu09fXd9oygXMZHnbj98fWom2ZPsMweGVPB79+8ciUtac5mamhWcJgg/2KwmCz/TP1G/W4vXjc\n0c3YJ7PLlhRx2ZIiRsa9vHW4jz8f7GF/ywl8foO+QTdPvdrMU682k52RSsPiQlbXFVE3b3aOiLXZ\nrLhcaXp9JwmNd3KJtfEeHPHwXy8cAmBhRTb183IYGBgzuarEER7v6YoqsC5ZsgS73c6ePXtYtWoV\nADt37qS+vv60a4uKimhsbJxyW0tLCxdffDEAK1asYNeuXdx0000AdHZ20tXVFfn38+X3B2Jul6FM\nT+eJMX757CEOHx+M3HbFynL+akM9+PxnHG99DcyctFQ7H6ov4UP1Jbg9Pt5u6mPXoV72NZ3A6wsw\nNOblpd3tvLS7nQynnZULg2tel1bnzfjmNL2+k4vGO7nEynj/5qVGJrx+LMAt6xfi9xtAVB0/ZQ5E\nFVidTicbNmxgy5YtfPe736W7u5utW7dy3333AcEZ0qysLBwOBzfffDObN2+mvr6elStX8pvf/IbO\nzk42bNgAwC233MLtt9/OxRdfTH19Pd/97ne58sor1SEgiU36AvxuRyv/88bRyHGmpfnpbLy+jqU1\neeRmOfVb7xxLc9i5bGkJly0twTPp553mE8EjYhv7mPD6GZvw8dq+Tl7b10maw8bF8wtoWFxIfW0+\njgTcwCYiieVo1zCv7+sE4PJlpVSXaClArIr64ICJiQm+9a1v8dxzz5GVlcWmTZu47bbbAKirq+O+\n++6LzJpu27aNn//853R3d7NkyRLuuece6urqIo/1xBNP8OMf/5ihoaHISVfZ2dE16I3FPm4SvUPH\nBvjVc4foPBHsGWq3WfjIh6q54QPzSLFbY7pvXzKa9AU4cLSfXaEjYt/bMiw1xcqy2nwaFhdy8fwC\n0hzRHaqn8U4uGu/kEivjbRgG3/uP3TS2DeFItXHfX19GdmZsH6oSj0w5OCAWmf0FL9Mz6p7k0d83\n8urezshtdVU53Hbd4ik9QWPlG5yczucPcCh0ROzuw70Mv6d7g91m4aLqPBoWF7FiYQGZaefeCKfx\nTi4a7+QSK+P95rvd/PuT+wH4xLpa/uKD1abVkshMOThAZKYYhsGf3u3m19uPMDwe7Jua4bTzqasW\nsGZZqfp/xhG7zcpF1XlcVJ3H/7pmEY3tQ+w81MPuw730D3vw+Q3ebjrB200nsFkt1FXl0LC4iJWL\nCsnOSD33JxARmWGeST+/CbWxKsh2cu0llSZXJOcS14HVFwO7CyV6vYNuHnruEO+09Eduu+yiYj5z\n1UJcCjBxzWq1sKgyh0WVOdxy9UJaOkcip2z1DLrxBwz2Hx1g/9EBHnruEAsrcyIHFahJt4jMlef+\ndIz+YQ8An75qISl2rbmPdXEdWG/b8izXf6CKK1eWR71GTuaezx/ghZ3HefLVFryht4EKc5zcdt1i\n6mvyTa5OZprFYqG2zEVtmYtPXjGf4z2j7DrUy67DvXT0jWEAh48Pcvj4II+8eISaUherQ0fElhVm\nml2+iCSo/uEJfvenViC4BG3VogKTK5LzEddrWD/6D08CwbeSr720ivUNFQquMaq5Y5hfPnswcpa9\n1WLh+g9U8dHLq89rN3msrHmSmdF5YiwYXg/10to9ctq/VxVn8omrFrFyfp7GOwno9Z1czB7vn/73\nfnbs78ZigW9+/lIqi/QL8mzSpivg7n97nb2NJw8fyHDaufaSStavrlRwjRFuj4/HX2nmpV1tka52\ntWUuNl5fF9U3CbO/wcns6R10h2Zee2hqH47cbrVa+Jf/vZa0VL2WE51e38nFzPFuah/iOw/tAuCK\nFWXcfn3dOe4h06XAGrLj7TYef7mZd1sHIreFg+vVDZWkO/XDziy7D/fyHy8cZmAkuE7ImWrjE+vm\nc+XKcqxRHu2pH2jJYWDEw6t7O3ji1RYAvnbLSpbOyzW5Kplten0nF7PGO2AYfOdXu2jpHCbNYed7\nf3MZrnTtm5ht6hIQsrgql/9zy0oOHx/kyddaeLd1gLEJH799tYXn3jzOtZdWsl7BdU4NjHj4jxcO\ns/twb+S2VYsKufWaReRmqcednF1uloMbPjCPp/8YPDyiuWNIgVVEZsQb73TR0hl8F2fD5dUKq3Em\nYVLcosqcSHB96vUWDhwdYNzj44lXW3hewXVOBAIGv3+rnW0vNzHh9QPBAPK/rlnEykWFJlcn8SLF\nbqWqOIvmjmGaO4bPfQcRkXOY8Pp47OUmAIrz0rmqocLkiiRaCZfeFlXm8LXPvE9wDa1xVXCdWcd7\nRvnlswcjAcMCXN1QwV9+uFbriSVqtWUumjuGaekYxjAM9eUVkWn53Y5WhkaDh5p85qoF2G1WkyuS\naCVskggH1yNtgzz1Wgv7w8H1tRae/3M4uFaQ7jz3qTtydp5JP0+9HvxlwB8ILoeuLMpk4/V11Jbp\nTGa5MOGvnaExL/3DHvKz1aNVRC5M36CbZ/90HID6mjyWz1cbxXiUsIE1bGFFDv9wluD6XCi4XqPg\nekHeaTnBQ88dondwAoBUu5UNa2u4ZnWlfnuVaakty478vaVzWIFVRC7Yb/7QhM8fwGqx8OmrF+od\nmziV8IE1LBxcG9uGePL1Fva39OP2+HjylBlXBdfzMzzm5dcvHWHH/u7IbfW1edx27WIKc9JMrEwS\nRUl+OulOO+MTPlo6h1ldV2R2SSIShw4dG2DnwR4ArlxVTnnB9HerizmSJrCGLajI5h8+veKswfWa\n1RVce0mlgusZGIbBa3s7+c3vGxmb8AHgSk/hM+sX8oElxfqtVWaM1WJhQUUOexv7Irt6RUSiEQgY\nPLL9CBBsd7lhTY3JFcl0JF1gDYsE1/YhnnqthXdCwfWp14/yws42Bdf36DwxxkPPHeLgscHIbR++\nuJRPXrGAzDT9P5KZt6gqNxhYu0YIBIyoe/eKSHJ7bV8nx0KnK960tlY/q+Jc0gbWsAXl2Xz1rMH1\nONesruSaSyrJSNLgOukL8MyOVp5+I9gXE6A0P53br1vM4ir1x5TZs7AyBwCP10/niTHKC3V8ooic\nH7fHx+OhNlblBRlcsbLM5IpkupI+sIaFg2tTe3CpwDvN/bg9/qQOroePD/LLZw/SeWIcALvNwl98\nsJobL5tHil2bqmR2LTrlF6KWzhEFVhE5b//9x6MMj08C8JmrF2Kz6mdWvFNgfY/55dl89VNnD67r\nGyq59tLEDq5jE5M8+vsmXnm7I3Lb4socbr9+MaX5WrAucyM/20lOZiqDo15aOodZs7zU7JJEJA50\n94/zwp+DbaxWLCjgopo8kyuSmaDAehaR4NoxxFOvHWVf8wncHj///cejbN8VDK7XXFKZUGtiDMPg\nzXd7eOTFIwyPBRssZzjtfOrKBaxZXqpNVTKnLBYLtWXZ7D7cS7M2XonIefqvlxrxBwxsVgufvmqB\n2eXIDFFgPYf5Zdl85VMXnzG4vrDzOOtXV3JtAgTX3kE3Dz1/iHea+yO3Xba0mM9cvRBXhs5bFnPU\nlrnYfbiXtp5RJn1+Uuw2s0sSkRi2/2g/exr7ALhmdSXFeekmVyQzRYH1PIWDa3PHME+93sLephNM\neP08/cejbI/j4OoPBHjhz2088WozXl8AgIJsJ7dft5j6Wp0GIuYKn3jlDxgc6xll/ikHCoiInMof\nCPDrUBurrPQUPvKhanMLkhmlwBql2jIX//vm9wuuFVx7SVVcBNeWzmF++czBSNsPq8XCdZdW8rE1\nNThSNJMl5qspPXm8b0vHsAKriJzVy3s6aO8bA+DjH64l3amIk0g0mhfo7MG1le0722I6uLo9Pn77\nSjMv7m7DCHaqoqbUxcbrF1NVnGVucSKnyEhLoTg3je4BNy2dI2aXIyIxamxikidebQGgsiiTtcvV\nxirRKLBOUzi4tnQO8+RrU4PrCzvbWN9QwXWXxk5wfetILw8/f5iBEQ8AjlQbn1w3nytXlqsxu8Sk\nmjJXKLBq45WInNmTr7Uw6g62sfrs+oX6eZaAFFhnSE3pyeD61GstvN10Ao/Xz/+80cr2XeYH14ER\nD//5wmF2He6N3LZyYQG3XrOIPJfTlJpEzkdNqYsd+7vp6h9nfGJSp8+JyBQdfWO8tKsdgNWLC3Wo\nTYJSYJ1hNaUu7jhHcL32kkqy0udm530gYPD7t9rZ9nITE14/ALlZDm69ZhGrFhXOSQ0i03HqOtaj\nXSMsrVZPRRE56dcvHSFgGNhtVj51pdpYJSoF1llyanD979ePsqexb86Da1vPKL989iBNHcG3Ui3A\nVasq+Pi6WtIcGnqJD1VFmdisFvwBg5bOYQVWEYnY29QXacd43aWVFOSkmVyRzBallllWU+ri7z+5\nnKNdwzz12nuC6842rm6o4LpLZza4eieDJ3M99+Yx/IHgrqqKwkw23rBYu6wl7qSm2KgozKS1e4Tm\nDq1jFZEgnz/Ar19sBCA7M5W/+OA8kyuS2aTAOkeqS84QXCf9/G5HKy/umrngur+ln189d5DewQkA\nUu1WNqyp4ZpLKrHbdJayxKea0ixau0c42qVOASIS9NLudrr6xwH45Lr5OFMVaRKZRneOnSu4XtVQ\nznWXVuH/B4qWAAAgAElEQVSKMrgOj3v5rxeP8Mb+7shtF9Xkcdt1iynSWyQS52pKXfxhTwcDIx4G\nRjzkZjnMLklETDQ87uXJ14JtrGpKs/hgfYnJFclsU2A1STi4tnaN8NTrLbx1JBhcn9lxjJd2tZ93\ncDUMg9f2dfKblxoZm/ABwRM+brl6IR9YWozFotYeEv9qyk45QKBzmNwsbRgUSWZPvNqC2xP8mXfL\n+kVY9bMu4SmwmmxeSRZf/sT7BNdV5Vz3gTMH167+cX717EEOHhuM3LZ2eSk3X7kgZvq+isyEsvwM\nHCk2PJN+WjqH1eFCJIkd7xnl5T3BNlaXLS1mQbn2ZiQDBdYYcdbg+qdjvLi7jatXVUSCq88f4Hc7\nWnn6j634/AEASvLS2Xj9YvWfk4RktVqYV5LF4eODOkBAJIkZhsGvXzyCYQT3aHzyivlmlyRzRIE1\nxpwpuHonA5Hg+uHlZRxoHaAjdF6y3Wbhxsvm8RcfrCbFrk1VkrhqS12hwDpCwDD0FqBIEnrrSB/v\ntg4AcMNl83TwTRJRYI1RZwuu23e1Ra5ZVJnDxusXU5qfYWKlInOjujQLALfHR3f/uL7uRZLMpC/A\nf710BIA8l4PrP1BlckUylxRYY1w4uB7rHuGp14+y+3Av6Q47n7pqAWuWl2qWSZJG7aknXnWOKLCK\nJJkXdh6PtGz85BXzcaTYTK5I5pICa5yoKs7i//34MvqHJ0hz2HVSlSSd/GwnWekpjIxP0tw5rDY2\nIklkaNTDf//xKAALKrL5wJJicwuSOadFj3Emz+VUWJWkZLFYqAnNsmrjlUhy2fZKMx6vH4Bbrl6o\nlo1JSIFVROJGOLAe6x6NdMgQkcTW2jXC63s7Abh8WUnk+4AkFwVWEYkb4R9UPn+Att5Rk6sRkdlm\nGAb/uf0wBuBItfGJdWpjlawUWEUkbtSEOgUAtHRoWYBIovvzwR6OtA0B8JEPziMnU8cyJysFVhGJ\nG1npqRRkB/sutnSOmFyNiMwm76SfR3/fCEBBtpNrL6k0uSIxkwKriMSV2jJtvBJJBs++eYwTwx4A\nPn3VAlLsamOVzBRYRSSuhNexdvSN4fb4TK5GRGbDwIiH3+1oBaCuKodViwpNrkjMpsAqInElHFgN\n4Fi3lgWIJKLH/tCIdzKAxQKfURsrQYFVROLMvOIswj+7mrUsQCThNLUP8cb+bgA+fHEZVcVZ57iH\nJAMFVhGJK45UG+UFmYA6BYgkmoBh8MiLRwBIc9j4y7W1JlcksUKBVUTiTri9lToFiCSWHfu7aA79\nIvqxy2twZaSaXJHECgVWEYk7NaFOASeGJxga85pcjYjMhAmvj8f+0ARAcV46VzdUmFyRxBIFVhGJ\nO7WnHM2o9lYiieF3O44xOBr8BfTTVy3AblNEkZOi/mrwer1s3ryZSy65hLVr17J169YzXnfbbbdR\nV1d32n9333135Jp/+Zd/Yd26dVx66aV85Stfob+//8KfiYgkjbKCDFLswW9fWscqEv/6htw89+Yx\nAC6qyePi+fkmVySxxh7tHe6//34OHDjAQw89RFtbG3feeSfl5eVce+21U6578MEHmZycjHy8Z88e\nvvKVr3DrrbcC8Otf/5rHH3+cH/zgB+Tk5LBlyxb+6Z/+iQcffHCaT0lEEp3dZmVecRaN7UO0dCmw\nisS7R3/fxKQvgNViURsrOaOoZljdbjePPfYY99xzD3V1daxfv55Nmzbx8MMPn3aty+UiPz+f/Px8\ncnNz+eEPf8gXv/hFli5dCsArr7zCDTfcwOrVq1mwYAGbNm3ijTfemJlnJSIJL9yPtaVjGMMwTK5G\nRC7UoWMD/PlgDwBXriynvCDD5IokFkUVWA8ePIjf72fFihWR2xoaGti7d+/73m/btm0MDQ2xadOm\nyG05OTm8/PLLdHd3MzExwdNPP81FF10UZfkikqzCnQLGJnz0DrpNrkZELkQgcLKNVYbTzoa1NSZX\nJLEqqsDa29tLTk4OdvvJlQT5+fl4PB4GBgbOer+f/exnfO5znyMtLS1y29/93d9htVpZt24dDQ0N\n7N69mwceeOACnoKIJKNwpwBQeyuRePXavk6OdY8CcNPaWjLTUkyuSGJVVGtY3W43qalTe6KFP/Z6\nz9xaZseOHfT09HDzzTdPub2trY309HR+8pOf4HK5uP/++9m8eTM///nPoykJm3YRJoXwOGu8k8P5\njHdZQQYZTjtjEz6Odo9w+fLSuSpPZphe38klPM4eX4DHX2kGoLwgg/WXVGCz6msg0czU6zqqwOpw\nOE4LpuGPT509PdXzzz/P2rVrcblcU27/+te/zp133sm6desA+NGPfsSVV17J3r17Wb58+XnX5HKd\n+fNKYtJ4J5dzjffieXnsPtTDse5RcnO17i3eJdvre3xikjG3j4w0O85UO1Zrcm00evZPxxgO9VH+\n648vpyBfR7DK2UUVWIuLixkcHCQQCGAN/RbU19eH0+k8LZCGvfrqq3z5y1+eclt/fz+dnZ0sXrw4\ncltJSQm5ubl0dHREFViHh934/YFonobEIZvNisuVpvFOEuc73hWFGew+BE1tg/SdGNHsTJxKxtd3\nW88oW37+JpOh52sB0px20h120hzBP9Odob+f8mfk3yO3pQSvddhJTbHGxe56m83KqNfPk68EDwlY\nsbCAmqIMBgbGTK5MZkP49T1dUQXWJUuWYLfb2bNnD6tWrQJg586d1NfXn/H6gYEBjh8/Hrk2LDs7\nm9TUVJqamqipCS6w7u/vZ3BwkIqK6E628PsD+HzJ8Q1ONN7J5lzjXV0cnJHx+gK0do5QVawZmniW\nTK/vl/e0R8IqgAGMT/gYn/Bd8GParBbSHHbSHLZI6D31zylB94y32Uix22bg2Z3b//fUfnx+A5vV\nwqeuXJA04y4XLqrA6nQ62bBhA1u2bOG73/0u3d3dbN26lfvuuw8IzrZmZWXhcDgAOHLkCE6n87QQ\narPZ+PjHP879999PTk4OLpeL73//+6xcufKs4VdE5L3CnQIgeOKVAqvEi71NJwBYUJ7N2uWljHt8\nuD2+k39OBP90e/xTbvcHzt7CzR8wGHVPMuqePOs152K3WaaE2bOGXMfJkHvqzHCaw37OE6r2t/Tz\np/1dAKxfXUFJXvoF1yvJI+qDA+666y6+9a1vsXHjRrKysrjjjjtYv349AGvWrOG+++7jpptuAk4G\n2DPZvHkzP/rRj/ja177GxMQEl19+Of/8z/88jaciIskmO9NBnstB/7CHls4R1q04931EzNY76Kbz\nxDgAH6wvYe3FZed1P8Mw8PoC7wm0vtPCrnvCf/pt4ft4fbxf22Kf32B4fJLh8QsPval262khNrLM\nwWFnT2MfAFnpKXz0Q2pjJefHYsR5x+2BgTG9lZAE7HYrubkZGu8kEc14P/jbfew61EtlUSbf+qtL\n56hCmUnJ9vp+aXcbDz9/GIB//n8+RH62c84+t2EYTHj9p4dZjw/3RPg2/5mDcCj0Tnj9M1LL52+s\nY+3y8wvrEr/Cr+9pP84M1CIiYpraUhe7DvXS3juGZ9KPI2Vu1uCJXKjwcoDywow5DasAFoslMuOZ\nd4GPEQgYTHiDQfZMSxdOm9V9T/Cd8PpZsaiQdSvKCbzPEgeRUymwikhcqw4d0RowDI51j7CwIsfk\nikTOzjvp593W4EE7y2vzTa7mwlitlmB3AmcKZEd//1Nn1BVY5XypB4yIxLXqkizCjXxaOoZNrUXk\nXA4eG2QytOxh+fz4DKwiZlBgFZG4luawU1oQXB/V3KnAKrFtX2g5QJrDzvzyC5ieFElSCqwiEvdq\nSoLdSI52jphcicjZGYbB3ubgDvmLavLO2f5JRE7Sq0VE4l5NWXAda8+ge1o9KEVmU1f/OL2DE0D8\nrl8VMYsCq4jEvZrSk0dDt2hZgMSocHcAgGW1F7pHXyQ5KbCKSNyrLMrEbgtuvdLGK4lV4cA6rySL\n7EyHydWIxBcFVhGJe3ablcqi4DpWzbBKLHJ7fBw+PgjAxeoOIBI1BVYRSQi1oWUBLZ3DxPkBfpKA\nDhwdwB/qObpMgVUkagqsIpIQasqCM6zD45OcGJ4wuRqRqfaFugNkpqVQU+I6x9Ui8l4KrCKSEE7d\neKX2VhJLDMOIrF9dVpuH1Wo5xz1E5L0UWEUkIRTnpZPmsAE6QEBiy/GeUQZHvQAsn19gcjUi8UmB\nVUQSgtVioTr0Vqs6BUgs2dccnF21WIIHBohI9BRYRSRhhJcFHO0eIRDQxiuJDW+HlgPML88mMy3F\n5GpE4pMCq4gkjHBg9Xj9dJ4YM7kaERh1T9LUPgTodCuR6VBgFZGEUVt2cuOV1rFKLNjf0k+4y9py\ntbMSuWAKrCKSMHKzHGRnpgLqFCCxIdwdICczlcqiTJOrEYlfCqwiklDCBwhohlXMFggYkQ1Xy+fn\nY7GonZXIhVJgFZGEEl7H2tYzyqTPb3I1ksxauoYZdU8CsKxW7axEpkOBVUQSSjiw+gMGx3pGTa5G\nktm+0HIAm9XC0upck6sRiW8KrCKSUKpLsyJ/Vz9WMVN4/eqiyhzSHHaTqxGJbwqsIpJQMpwpFOel\nA9CidaxikqExL0e7ghv/1B1AZPoUWEUk4dSEZllb1ClATBJeDgAKrCIzQYFVRBJOeB1rV/844xOT\nJlcjyWhvqDtAQbaTktCMv4hcOAVWEUk44dZWAC1dmmWVueXzB9jf0g+onZXITFFgFZGEU1Wcic0a\nDAnaeCVzral9CLfHB8Dy+WpnJTITFFhFJOGk2G1UFAZPFdLGK5lr4e4AKXYrdVU5JlcjkhgUWEUk\nIdWUBZcFKLDKXAuvX10yL5fUFJvJ1YgkBgVWEUlI4U4Bg6NeBkY8JlcjyeLE0ATtvWMALKtVdwCR\nmaLAKiIJqebUjVeaZZU5sq9Z7axEZoMCq4gkpLL8DByht2MVWGWuhNevluanU5iTZnI1IolDgVVE\nEpLVaqG6JLgsoFmdAmQOTPr8HGg92c5KRGaOAquIJKzwsoCjXSMEDMPkaiTRHTo+iHcyAMByrV8V\nmVEKrCKSsMKdAtweH9394yZXI4kuvBzAkWpjYaXaWYnMJAVWEUlY4U4BoHWsMvv2hQLrRdV52G36\n8Soyk/SKEpGEle9ykpWeAkBLp45oldnT3T9O94Ab0PpVkdmgwCoiCctisUTWsWqGVWZTeDkAqP+q\nyGxQYBWRhFYbCqzHukfw+QMmVyOJKny6VVVRJrlZDpOrEUk8CqwiktCqQ4HV5zdo6x01uRpJRB6v\nn0PHBgBYpuUAIrNCgVVEEtqUjVfqxyqz4N3WAXz+YNu0i+cXmFyNSGJSYBWRhJaVnkphjhOAZq1j\nlVmwt6kPgAynndoy1zmuFpELocAqIgnv5MYrdQqQmWUYRmT9an1tPlarxeSKRBKTAquIJLxwYO3s\nG8Pt8ZlcjSSS9r4x+oc9gE63EplNCqwikvDCgdUAWrs0yyozJ3xYgAW4qDbP3GJEEpgCq4gkvHnF\nWVhC79SqH6vMpHD/1doyF670VJOrEUlcCqwikvAcqTbKCzIBBVaZOeMTkxxpGwLUzkpktimwikhS\nqC0LtrdSYJWZsv/oAAEj2M5Kx7GKzC4FVhFJCuF1rCeGPQyNeU2uRhJBuJ2VKyOVquKsc1wtItMR\ndWD1er1s3ryZSy65hLVr17J169YzXnfbbbdRV1d32n9333135Jpnn32W6667jpUrV/KFL3yBjo6O\nC38mIiLvIxxYQbOsMn0Bw2Bfcz8Ay2rzsFrUzkpkNkUdWO+//34OHDjAQw89xJYtW/jXf/1Xnn/+\n+dOue/DBB3n99dcj/z344IOkpqZy6623ArB7926+9rWvsWnTJn7729+SkpLCV7/61ek/IxGRMygr\nyCDVHvyWpxOvZLpau0YYDs3U63QrkdkXVWB1u9089thj3HPPPdTV1bF+/Xo2bdrEww8/fNq1LpeL\n/Px88vPzyc3N5Yc//CFf/OIXWbp0KQBbt25lw4YN3HzzzVRXV3PPPffQ29vL4ODgzDwzEZFT2G1W\nqkq0jlVmRridldViYWm12lmJzLaoAuvBgwfx+/2sWLEicltDQwN79+593/tt27aNoaEhNm3aFLnt\nzTff5Jprrol8XFFRwYsvvkhOTk40JYmInLeakvCJV8MYoc0yIhcifLrVwops0p12k6sRSXxRBdbe\n3l5ycnKw20++OPPz8/F4PAwMDJz1fj/72c/43Oc+R1paGgAjIyMMDQ3h8/n4whe+wJo1a/jbv/1b\nuru7L/BpiIicW02oU8DYhI/eQbfJ1Ui8Gh73RpaVqDuAyNyI6tdCt9tNaurUxsjhj73eM++63bFj\nBz09Pdx8882R28bHxwH4zne+w1e/+lVqamr40Y9+xJe+9CV++9vfRvUEbDY1OkgG4XHWeCeH2Rrv\nhRUn38Fp7R6lrDBzRh9fLky8vb7fbR0gPD+/cnEhdnt81B0r4m28ZXpmapyjCqwOh+O0YBr+ODx7\n+l7PP/88a9euxeU6uUPXZrMBcPPNN/PRj34UgAceeIDLL7+cPXv2TFlycC4u15k/ryQmjXdymenx\nzslJJys9hZHxSTr63eTmZszo48v0xMvr+93W4F6Lwtw06hcWYVGHgAsSL+MtsSGqwFpcXMzg4CCB\nQACrNZiY+/r6cDqdUwLpqV599VW+/OUvT7ktNzcXu91OTU1N5LacnBxycnLo7OyMKrAOD7vx+wPR\nPA2JQzabFZcrTeOdJGZzvKtLXOxrPsGB5j4GBsZm9LHlwsTT69sfCLDrYHD52rKaPAYHx02uKP7E\n03jL9IXHe7qiCqxLlizBbrezZ88eVq1aBcDOnTupr68/4/UDAwMcP348cm2YzWajvr6egwcPcsMN\nNwDQ39/PwMAA5eXlUT0Bvz+Az6cv+GSh8U4uszHe1SVZ7Gs+QWvXCB6vD5tVb0vGinh4fR9pG2Rs\nwgdAfU1+zNcby+JhvCV2RPWd2ul0smHDBrZs2cK+ffvYvn07W7duZePGjUBwttXj8USuP3LkCE6n\nk4qKitMe6/Of/zwPPfQQzz77LE1NTWzevJmlS5eyfPnyaT4lEZGzCx8g4PUFaO/VDKtEZ2+onZXd\nZmXJvFyTqxFJHlFPLdx1113U19ezceNG7r33Xu644w7Wr18PwJo1a3jmmWci1/b19ZGVdebj6q67\n7jruuusuvv/97/PJT34SCB42ICIym2pKT35PUj9WiVY4sNZV5eBItZlcjUjysBhx3oxwYGBMbykk\nAbvdSm5uhsY7Scz2eP+f//s6J4Y9fPjiUj53w5IZf3yJTry8vgdGPPzDg68DcMv6hVyzutLkiuJT\nvIy3zIzweE+XFm+JSNKpDi0LaO4YMbkSiSf7QocFgPqvisw1BVYRSTq1ocDa0TeGx+s3uRqJF+Hl\nAMW5aRTnpptcjUhyUWAVkaQT3ngVMAxauzXLKufm8wfYf7QfgGWaXRWZcwqsIpJ05pVkEW71ro1X\ncj4OHx+MzMZfPL/A5GpEko8Cq4gknTSHndKC4CYABVY5H+HlAKkpVhZV5pzjahGZaQqsIpKUwu2t\nFFjlfIQ3XC2dl0eKXT86ReaaXnUikpTCG696BycYGfeaXI3Esp5BN50ngkewqjuAiDkUWEUkKYVb\nWwEc7dLGKzm7fU1qZyViNgVWEUlKlUWZ2G3BrVctHVoWIGcXXr9aUZhBnstpcjUiyUmBVUSSkt1m\npao4uI61WetY5Sw8k34OHhsA1M5KxEwKrCKStGpKgssCjnYOE+enVMssOXRsgMnQ8aHLaxVYRcyi\nwCoiSaumLDjDOjw+yYnhCZOrkVgUXg6Q5rAzvzzb5GpEkpcCq4gkrZpTNl61dGrjlUxlGEYksNbX\n5GG36UemiFn06hORpFWcl06awwaoH6ucrvPEOH1DwZl3dQcQMZcCq4gkLavFQnVoHas6Bch77T2l\nnVW91q+KmEqBVUSSWm1ZaONV1wiBgDZeyUnh062qS7LIzkg1uRqR5KbAKiJJLTzD6pn003lizORq\nJFa4PT4OHx8EtBxAJBYosIpIUgvPsIL6scpJB4724w/NuC+fX2ByNSKiwCoiSS03y0FOZvDtXnUK\nkLDw+tWs9BSqS7NMrkZEFFhFJOmF21tp45VAqJ1Vc7idVT5Wi8XkikREgVVEkl44sLb1jjLp85tc\njZjteM8oQ6NeQOtXRWKFAquIJL2a0DpWf8DgWPeoydWI2d4OLQewWKC+Ns/kakQEFFhFRKgpOblG\nURuvZF8osC4ozybDmWJyNSICCqwiIqQ7UyjOSwfgqAJrUht1T9LUMQRoOYBILFFgFREBakM7wZvV\nKSCpvdNyAiN0fsQynW4lEjMUWEVEOLnxqrt/nPGJSZOrEbOElwPkZjmoLMo0uRoRCVNgFRHhZGAF\naOnSLGsyCgQM9jX3A8HZVYvaWYnEDAVWERGgqjgTmzUYUNSPNTm1dA4z6g7Ormv9qkhsUWAVEQFS\n7DYqQm8Bt2jjVVIKn25ls1pYMi/X5GpE5FQKrCIiIZETrxRYk1L4dKtFlTmkOewmVyMip1JgFREJ\nqQl1Chgc9TIw4jG5GplLg6MeWkNrl7UcQCT2KLCKiITUnrLxqlnrWJPKvtDsKiiwisQiBVYRkZDS\n/AwcKTYAjnYpsCaTcDurwhwnJaFDJEQkdiiwioiEWK0WqkPHtGqGNXn4/AH2Hw22s1peW6B2ViIx\nSIFVROQUNWXBZQFHu4YJhI88koTW1D6E2+MHYJmWA4jEJAVWEZFThDsFuD1+uvvHTa5G5sLboeUA\nqXYrdVU5JlcjImeiwCoicopwpwBQe6tkEV6/Wjcvl9TQGmYRiS0KrCIip8h3OXGlpwDQ0qEjWhNd\n35Cb9r4xQN0BRGKZAquIyCksFgvVoWUBzZphTXj7mvsjf19Wq8AqEqsUWEVE3iPcj/V4zwg+f8Dk\namQ2hZcDlOanU5iTZnI1InI2CqwiIu8R7hTg8xsc7xk1uRqZLZM+PwdagzOsF88vMLkaEXk/Cqwi\nIu9Rc8qJV9p4lbgOHRvEOxmcQVc7K5HYpsAqIvIemWkpFOY4AQXWRLY3tBzAmWpjYUW2ydWIyPtR\nYBUROYPwLGtLpzoFJKq9zcHAelF1HnabfhyKxDK9QkVEziC88aqzbwy3x2dyNTLTuvrH6RlwA2pn\nJRIPFFhFRM4g3NrKAFq7NMuaaMLLAQDq1c5KJOYpsIqInMG84iysFgugdayJaF9THwBVxZnkZjlM\nrkZEzkWBVUTkDBypNsoLMwAdIJBoJrw+Dh0fBLQcQCReKLCKiJxFTWkWAEcVWBPKu60D+PwGAMtr\n1X9VJB5EHVi9Xi+bN2/mkksuYe3atWzduvWM1912223U1dWd9t/dd9992rXPPPMMdXV10VcvIjKL\nwp0CTgx7GBr1mFyNzJTw+tUMp53aMtc5rhaRWGCP9g73338/Bw4c4KGHHqKtrY0777yT8vJyrr32\n2inXPfjgg0xOTkY+3rNnD1/5yle49dZbp1w3MjLCd77zHSyhtWIiIrFi6gECI6xYqLWO8c4wjEhg\nXVabj9Wqnz0i8SCqGVa3281jjz3GPffcQ11dHevXr2fTpk08/PDDp13rcrnIz88nPz+f3NxcfvjD\nH/LFL36RpUuXTrnu+9//PvPmzZvesxARmQXlhRmk2oPfJrXxKjG0944xMBKcLdfpViLxI6rAevDg\nQfx+PytWrIjc1tDQwN69e9/3ftu2bWNoaIhNmzZNuf3NN9/kzTff5Etf+lI0ZYiIzAmb1UpVSXAd\nqwJrYggfFmAB6mvyzC1GRM5bVIG1t7eXnJwc7PaTKwny8/PxeDwMDAyc9X4/+9nP+NznPkdaWlrk\nNq/Xyze+8Q2++c1v4nDobTYRiU21kROvhjEMw+RqZLr2NgbbWdWWuchKTzW5GhE5X1GtYXW73aSm\nTn2Bhz/2er1nvM+OHTvo6enh5ptvnnL7gw8+SH19PR/84Ad58803oyljCpuO00sK4XHWeCeHWBrv\n+eXZ8OfjjE346B/xUJyXbnZJCWeuxnvMPUlje3CmfMXCAux287++klEsvb5l9s3UOEcVWB0Ox2nB\nNPzxqbOnp3r++edZu3YtLtfJzQuHDx/m0Ucf5emnnwaY1qyFy3XmzyuJSeOdXGJhvFcuKYEn3gGg\ne8hD3fxCkytKXLM93u+0thMI/bxZs6qS3NyMWf188v5i4fUt8SOqwFpcXMzg4CCBQACrNZiY+/r6\ncDqdUwLpqV599VW+/OUvT7nt+eefZ3h4mKuvvhqAQCCAYRisWrWKb3/723zkIx8575qGh934/YFo\nnobEIZvNisuVpvFOErE03g6rQUZaCmPuSfYd6WF5Ta6p9SSiuRrvP77dDkB2Ziq56XYGBsZm7XPJ\n2cXS61tmX3i8pyuqwLpkyRLsdjt79uxh1apVAOzcuZP6+vozXj8wMMDx48cj14bdfvvtbNiwIfLx\nnj17+Md//EeefPJJ8vOj27Xp9wfw+fQFnyw03sklVsa7piSLd1r6aWofjol6EtVsjnfAMCLrV5fV\n5BPwGwTQmmQzxcrrW+JDVAsLnE4nGzZsYMuWLezbt4/t27ezdetWNm7cCARnWz2ek821jxw5gtPp\npKKiYsrjuFwuKisrI/8VFxcDUFlZSXq61oeJSGwJ92M91j2CTzNCcam1a4Th8WBvcB3HKhJ/ol4J\ne9ddd1FfX8/GjRu59957ueOOO1i/fj0Aa9as4Zlnnolc29fXR1ZW1sxVKyJigprQaUheX4COPr2N\nHI/ChwXYrBaWVqudlUi8sRhx3qdlYGBMbykkAbvdSm5uhsY7ScTaeA+NefnKv7wGwO3XL+aKFeUm\nV5RY5mK87/3lTlo6h6mryuEfP7vq3HeQWRNrr2+ZXeHxni71lBAROYfsjFTyXcF+0Ud1gEDcGR7z\nRsZNp1uJxCcFVhGR8xBex9rcMWJyJRKtfc0nIturltcqsIrEIwVWEZHzEF7H2t43isfrN7kaica+\n0FYvMqAAACAASURBVHGs+S4nZQXqvSoSjxRYRUTOQ01JMLAaBrR2a5Y1XvgDAd5p7geC3QEsFovJ\nFYnIhVBgFRE5D/NKsghHnRatY40bTe3DjHt8gNavisQzBVYRkfOQ5rBH3k5WYI0f4eUAdpuVJVU6\npUwkXimwioicp+rSYF9pBdb48XZjMLDWVeXgSLWZXI2IXCgFVhGR81Qb6hTQOzjByLjX5GrkXPqH\nJ2jrHQV0upVIvFNgFRE5T+FOAQAtndp4FevCywFA61dF4p0Cq4jIeaoozMRuC2690gECsS98HGtx\nXjrFuekmVyMi06HAKiJynuw2K1XFwXWszQqsMW3SF+DA0QFAhwWIJAIFVhGRKIRPvGrpHMYwjHNc\nLWY53DaIZzJ4wMPyBQqsIvFOgVVEJAo1oU4BI+OTnBiaMLkaOZt9oeUAjhQbiypyTK5GRKZLgVVE\nJArhGVaAli5tvIpV4fWrS6tzSbHrR51IvNOrWEQkCsV56aQ57AC0dGgdayzqGRinq38cUHcAkUSh\nwCoiEgWrxRJZFqCNV7EpPLsK2nAlkigUWEVEohReFtDaNUIgoI1XsWZvqP9qRWEmeS6nydWIyExQ\nYBURiVI4sHom/XScGDO5GjmVZ9LPwdZBQKdbiSQSBVYRkShN2Xildawx5WDrAD5/AFBgFUkkCqwi\nIlHKzXKQk5kKqFNArAkvB0hz2Jlf7jrH1SISLxRYRUQuQOQAAc2wxgzDMNjbGAys9TV52Kz6ESeS\nKPRqFhG5ALVlwcDa1jvKpM9vcjUC0HFinBPDwcMctBxAJLEosIqIXIDq0AyrP2BwrHvU5GoETp5u\nBbBM7axEEooCq4jIBagpyYr8Xf1YY8Pepj4geHyuKyPV5GpEZCYpsIqIXIB0ZwoleekAtCiwmm58\nwseRtiFAs6siiUiBVUTkAoVPvGrpVKcAsx042o8/dIjDxQsKTK5GRGaaAquIyAUKdwro7h9nbGLS\n5GqSW7idVVZ6CvNOWa4hIolBgVVE5ALVlJ3s83lUs6ymMQwjsuFqWW0+VovF5IpEZKYpsIqIXKCq\nokxs1mA40sYr8xzrHmVozMv/397dR0VZ5/8ffwEjDCITNwoiKKDdgJKipGlJdmPu12qzbbdON2tW\noltb2XHP7nqTZWaZ5rbWqba1bN1d3e5W2/Z3TFfzu3s2v633ClhGKgiCAoLcCcIMzMzvD5xRFi1H\nGa6BeT7O4ZzmwzXT+/Ijw8trPtf7I9HOCuiuCKwAcJF6mIKUENNLklRIYDWMqztAYECAhiRHGVwN\nAG8gsALAJRh4eh1rwbE6OZ1Og6vxT671q5fHWxRm7mFwNQC8gcAKAJcg6XSngNoGm6pPWg2uxv+c\nPGVTwdHWq9tXsxwA6LYIrABwCVxXWCXaWxnh68NVcl3XHjqIdlZAd0VgBYBLEBcdppDgIElsIGCE\n3NPdASLDQ5TQJ8zgagB4C4EVAC5BYGCAe5tWAmvncjic2ldwpp1VAO2sgG6LwAoAlyjp9LKAwrI6\nObjxqtMUlNapoalFkjSM9atAt0ZgBYBL5FrH2mi1q7zqlMHV+A/XcoCgwAClJkUaXA0AbyKwAsAl\nSj7rxquCYywL6Cyu3a2uGhAhc7DJ4GoAeBOBFQAuUZQlRJaerf0/2aK1c9TUW1VU3vpnPXQgywGA\n7o7ACgCXKCAgwH2VlS1aO4fr6qokDb2cdlZAd0dgBYAOkNyvNbAWHz+pFrvD4Gq6P9fuVjERoYqN\nDDW4GgDeRmAFgA7gusLaYneq+Hi9wdV0by12h74+XCWpdXcr2lkB3R+BFQA6QHKbHa9YFuBNB0tq\n1WSzS5KG0s4K8AsEVgDoAL1CeygmovWj6cN0CvAq1/rVYFOgruofYXA1ADoDgRUAOkhS3Okdr8ro\nFOBNrvWrqYmRCu4RZHA1ADoDgRUAOohrA4HSygY1WlsMrqZ7qqxp1LHKBkksBwD8CYEVADqIq1OA\nU1IhV1m9Yl/BmXZWV9N/FfAbBFYA6CADYsMVePqOdW688o6c0+tX+/UOU+8I2lkB/sLjwGqz2TR3\n7lyNHDlSmZmZWrly5TmPmzx5slJSUtp9PfPMM+5j3nnnHd1yyy3KyMjQI488ovz8/Is/EwAwWEiP\nIMX3CZNEYPUGW7NdeUXVktjdCvA3Hm++vGTJEu3fv1+rVq1SSUmJZs2apfj4eE2YMKHNcW+99Zaa\nm5vdj7OzszVz5kw9+OCDkqQPPvhAf/zjH/Xyyy8rKSlJ7777rqZNm6YNGzYoJCTkEk8LAIyRHGdR\n8fF6AqsXfFtcI1tL66YMrF8F/ItHV1gbGxu1Zs0azZs3TykpKRo/fryysrK0evXqdsdaLBZFR0cr\nOjpakZGRWrZsmaZNm6bBgwdLkj799FNNnTpV48aNU2Jiop5//nlVV1drz549HXNmAGCA5NOdAqrq\nrKqttxpcTfeSe3o5gDk4SJcnXGZwNQA6k0eBNS8vT3a7Xenp6e6xjIwM5ebmfufz1q5dq9raWmVl\nZbnHZs2apTvuuMP92LVTycmT3KgAoOtqu4EA72cdxel0Kje/UpI0JDlKpiBuwQD8iUc/8RUVFYqI\niJDJdGYlQXR0tKxWq6qrq8/7vBUrVujhhx9WaOiZBfIjRoxQbGys+/HHH38su92ujIwMT0oCAJ8S\n3ydMwabWt9YClgV0mLKqU6qoaZLE+lXAH3m0hrWxsVHBwcFtxlyPbTbbOZ+zbds2HT9+XPfcc895\nXzcnJ0evvPKKsrKyFB3t2RtREP/K9guueWa+/UNXnm+TApUUZ9GB4hoVltXJZOp659DZLmS+vy6s\ncv/38Cv78OfahXXln294rqPm2aPAGhIS0i6Yuh6fffX0bJs2bVJmZqYsFss5v793715Nnz5d48aN\n04wZMzwpR5JksdDWxJ8w3/6lq853anJ0a2AtPamIiJ7uJU/4bt813/sLayRJgxIuU/KAqM4qCV7U\nVX++YQyPAmtsbKxqamrkcDgUGNiamCsrK2U2m88bSLds2aKnnnrqnN/bvn27HnvsMWVmZurVV1/1\nsPRWdXWNstsdF/VcdB1BQYGyWEKZbz/R1ec7Prr1F3F9Y7O+LahUbFRPgyvybd833022Fu1zrV9N\nilJ1dUNnl4gO1NV/vuEZ13xfKo8Ca2pqqkwmk7KzszVixAhJ0q5du5SWlnbO46urq1VcXOw+9mwH\nDhzQz3/+c91444169dVX3QHYU3a7Qy0t/IX3F8y3f+mq8z0gNtz93weLaxRtMRtYTddxvvnOPXRC\ndodTkpSWHNUl/06gva768w1jeJQSzWazJk2apPnz52vfvn3avHmzVq5cqSlTpkhqvdpqtZ5p43Lw\n4EGZzWYlJCS0e63nnntO/fr10+zZs1VVVaXKysp2zweArqjPZWb1Cu0hiU4BHcHVzqpXaA8NjDv3\np3kAujePL2vOmTNHaWlpmjJlihYuXKinn35a48ePlySNHTtWGzZscB9bWVmp8PDwdq9RWVmpnJwc\nHTp0SDfeeKMyMzPdX2c/HwC6ooCAACWd7sfKBgKXxul0al9Ba2BNGxilwEDWAwP+KMDpdDqNLuJS\nVFc38JGCHzCZAhUZGcZ8+4nuMN+fbinQ//uyUD1MgXpr5g30Df0O3zXfxcfrNf8POyRJ0384WKOH\n9DWiRHSg7vDzjQvnmu9LxTsoAHhB0umPrptbHDpWyU1CF8u1WUCApDT6rwJ+i8AKAF5w9o5XbCBw\n8VzrVwfGW9zrggH4HwIrAHjBZWHB7u4Ah48RWC9GQ1OzDh2tlcTuVoC/I7ACgJcku2+8olPAxfj6\ncJVcd1kMHdTb2GIAGIrACgBektyvdVnA0cp6WW12g6vpelzLAS7rFawBsb0MrgaAkQisAOAlrp6h\nTqdUVM5VVk84zmpndfXAaLa3BfwcgRUAvGRAbLhcMauAdaweKSw9qZOnmiWxfhUAgRUAvCY0xKR+\nvVv7DxaWEVg94WpnFRQYoCHJUQZXA8BoBFYA8CJXeyuusHrGtRzgioTLFBpiMrgaAEYjsAKAF7lu\nvKqsbVLdKZvB1XQNtQ02d2cFugMAkAisAOBVrtZWUuu6THy/r05fXZWkqwexfhUAgRUAvCqhTy+Z\nglrfag+z49UFcbWziraY1S+6p8HVAPAFBFYA8CJTUKAST/cQJbB+P7vDoa8OV0mShl5OOysArQis\nAOBlSadvvDpcWiena+smnFP+0To1Wlsk0c4KwBkEVgDwMtcGAidPNetEbZPB1fi2nNPtrExBgUpJ\njDS4GgC+gsAKAF7m6hQgSQUsC/hO+06vX01JjFBIjyCDqwHgKwisAOBlMZGh7l6idAo4vxO1TSqp\naJDEcgAAbRFYAcDLAgMC3O2tuMJ6fq7drSRp6OX0XwVwBoEVADqBa8erorKTcji48epccg61Lgfo\nG9VTMRGhBlcDwJcQWAGgE7gCq7XZrmMnGgyuxvc0t9j1taudFZsFAPgvBFYA6ASuwCpJh4+xLOC/\nfZV/QtZmuyR2twLQHoEVADpBZHiIIsNDJLGBwLnsyiuXJIUEB+nKhAiDqwHgawisANBJkvpy49X5\n7P6mNbAOToxUDxO/mgC0xbsCAHSSgaf7sR6taJDt9MffkMqrTumoq50VywEAnAOBFQA6iWsdq93h\n1JHj9QZX4ztyDp1pZ3U1/VcBnAOBFQA6iWtJgMSNV2dztbPqH9NLURazwdUA8EUEVgDoJD3NPdQ3\nqqck6XAZgVWSrDa78oqqJUnpbBYA4DxMRhcAAP4kOc6isqpTfn+F1eF0au+BSq3fVqhmu0MSu1sB\nOD8CKwB0ooH9LNr6dZnKqxvV0NSsMHMPo0vqVC12h7bvL9f6bUUqPXHKPX5VYqQuT7DI6TCwOAA+\ni8AKAJ0oKe7MOtbC0pMakhxlYDWdx9ps15acY9q444hO1Fnd41GWEN02OlGTbrpCjQ1WtThIrADa\nI7ACQCcaENNLQYEBsjucKiit6/aB9VRTs/53z1Ft3lWsk6ea3eNx0T018dpEjR4SK3OISeZgkxob\nrN/xSgD8GYEVADpRD1OQ+sf0UmHZyW69jrW23qpNO4v1r71H1WQ703M2qW+4bh+TqOFX9lFgQICB\nFQLoSgisANDJkuMsrYG1tE5Op1MB3Si4Ha9p1D+2H9H/5ZaqxX7m4/3UxEjdNiZRgxMju9X5Augc\nBFYA6GTJcRb9a+9R1TbYVH3S2i16j5Ycr9f6bUXa8c1xOZxO9/jwK3rr9jFJ7l2+AOBiEFgBoJMl\nnxXeDpfWdenAeqikVp9tLVRO/gn3WGBAgEYPidXE0YmK7x1mXHEAug0CKwB0sriongoJDpLVZtfh\n0pPKuCrG6JI84nQ69dXhKn22tUgHimvc4z1MgbphaD/94Nr+6n1ZqIEVAuhuCKwA0MkCAwOU3Ddc\neUdqdLi069x45XA4tevb41q/rUhHyuvd46EhJt08Il63XtNflrBgAysE0F0RWAHAAMlxFuUdqVFh\nWZ0cTqdP3zHf3OLQ1q/LtGFbkcqrG93jlrBgTRjZXzemx6unmV8nALyHdxgAMEByXOs61karXeVV\npxQX7XtrPZtsLfp39jFt2lms6pNneqT2vsysidcO0PVXxym4R5CBFQLwFwRWADCAK7BKUsGxOp8K\nrPWNzdq8q1j/u7tEDU0t7vH4PmG6bXSiRqXGKCgw0MAKAfgbAisAGCDKEiJLWLDqGmw6XFqn66+O\nM7okVZ+0auOOI/p39jFZm880+x8Ub9Hto5M09PJon166AKD7IrACgAECAlpvvMrJP2H4jVdlVae0\nYVuR/vNVmeyOMz1U05KjdPuYRF3ZP4Jm/wAMRWAFAIMk97MoJ/+Eio/Xq7nFoR6mzv2YvajspD7b\nVqTdecfliqkBkjJSYnT76EQl9g3v1HoA4HwIrABgkIGn17G22J0qqahvs67VW5xOpw4U1+izrUX6\n6nCVezwoMEDXpfXVxNGJ6hvV0+t1AIAnCKwAYJCk/7rxypuB1eF0KvfQCX22rVD5R88sQQjuEagb\n0+M1YWT/Lr3jFoDujcAKAAbpFdpDMRGhOl7TqEIvrWO1Oxza8U1rs/+jFQ3u8TCzSbdkJGj8Nf3V\nK7SHV/7fANBRCKwAYKDkfhYdr2lUQQcH1uYWu/4vt1Qbth9RZW2TezyiV7B+MGqAxqX3kzmYXwEA\nugberQDAQMlxFm3fX66yE6fUaG1RaMilvS03Wlv0r71HtWlnseoabO7xmMhQ3TY6UWOG9O30m7sA\n4FIRWAHAQMlxrXfiOyUVlp1UamLkRb1OXYNNn+8q1j/3HFWj9Uyz/wExvXTbmERdc1WMAgNpTQWg\na/I4sNpsNj3//PP6/PPPZTab9eijj+qRRx5pd9zkyZO1c+fOduM//vGP9dJLL0mS1q1bp9dff10V\nFRUaO3asFi5cqMjIi3uzBoCuaEBsuAIDAuRwOnW4tM7jwFpZ26iN24u1JfeYbC0O9/iV/SN0+5hE\npSVH0UMVQJfncWBdsmSJ9u/fr1WrVqmkpESzZs1SfHy8JkyY0Oa4t956S83Nze7H2dnZmjlzph58\n8EFJUm5urubNm6cXXnhBKSkpWrhwoebMmaPf//73l3hKANB1hPQIUkKfMB05Xq/Dxy58HevRygZt\n2Fak7fvL2zT7HzYoWreNSdQVCRHeKBcADOFRYG1sbNSaNWv03nvvKSUlRSkpKcrKytLq1avbBVaL\n5Ux7FofDoWXLlmnatGkaPHiwJOkvf/mLJk6cqDvvvFOStHTpUt100006evSo4uPjL/W8AKDLSIqz\ntAbWsu8PrAXH6vTZ1kLtPVjpHgsIkK5NjdXE0YnqH9PLi5UCgDE8Cqx5eXmy2+1KT093j2VkZGj5\n8uXf+by1a9eqtrZWWVlZ7rHs7Gz97Gc/cz/u27ev4uLilJOTQ2AF4FcG9rPoi5xjqqqzqqbeqohe\nIW2+73Q6tb+oWuu3Fumbomr3uCkoUGOHxul/rh2gmIjQzi4bADqNR4G1oqJCERERMpnOPC06OlpW\nq1XV1dXnXX+6YsUKPfzwwwoNPfOGWlFRoZiYmDbH9e7dW2VlZZ6UBABd3tkbBhwurdPwK/pIam32\nv/dAhdZvK9Lh0pPuY8zBQbppeLxuHdm/XbgFgO7I4yUBwcHBbcZcj20227meom3btun48eO65557\n2ow3NTWd87XO9zrnExREexZ/4Jpn5ts/+Nt8D+jbS8GmQNlaHCoqr9fwK/to61dlWvefQpWeOOU+\nLrxnD/1g1ADdkpGgsG7U7N/f5tvfMd/+paPm2aPAGhIS0i5Quh6fffX0bJs2bVJmZmabNa3f9Vpm\ns2dbA1osfAzmT5hv/+JP8315/wjtP1ylHd+U6z9flamyptH9vd4RofrRjYM04drEbt3s35/mG8w3\nPOPRO19sbKxqamrkcDgUGNiamCsrK2U2m9sFUpctW7boqaeeajceExOjysrKNmOVlZXtlgl8n7q6\nRtntju8/EF1aUFCgLJZQ5ttP+ON8D4jppf2Hq1R21hXVuOieuuO6JI1J6ytTUKAaG6xqbLAaWKV3\n+ON8+zPm27+45vtSeRRYU1NTZTKZlJ2drREjRkiSdu3apbS0tHMeX11dreLiYvexZ0tPT9fu3bt1\n1113SZJKS0tVVlamYcOGeXQCdrtDLS38hfcXzLd/8af5vrJ/hP6x/YgkKalvuG4fk6jhV/ZRYECA\n5JRf/Dn403yD+YZnPAqsZrNZkyZN0vz587Vo0SKVl5dr5cqVWrx4saTWK6Th4eEKCWm9CeDgwYMy\nm81KSEho91r333+/HnroIQ0bNkxpaWlatGiRbrrpJjoEAPBLwwZF64kfXa1eoSZd2T+CZv8AcBaP\nV8LOmTNHaWlpmjJlihYuXKinn35a48ePlySNHTtWGzZscB/rCrDnkp6erhdeeEFvvfWWHnjgAUVE\nRGjRokUXeRoA0LUFBAQo46o+umpAJGEVAP5LgNPpdH7/Yb6rurqBjxT8gMkUqMjIMObbTzDf/oX5\n9i/Mt39xzfeloqcEAAAAfBqBFQAAAD6NwAoAAACfRmAFAACATyOwAgAAwKcRWAEAAODTCKwAAADw\naQRWAAAA+DQCKwAAAHwagRUAAAA+jcAKAAAAn0ZgBQAAgE8jsAIAAMCnEVgBAADg0wisAAAA8GkE\nVgAAAPg0AisAAAB8GoEVAAAAPo3ACgAAAJ9GYAUAAIBPI7ACAADApxFYAQAA4NMIrAAAAPBpBFYA\nAAD4NAIrAAAAfBqBFQAAAD6NwAoAAACfRmAFAACATyOwAgAAwKcRWAEAAODTCKwAAADwaQRWAAAA\n+DQCKwAAAHwagRUAAAA+jcAKAAAAn0ZgBQAAgE8jsAIAAMCnEVgBAADg0wisAAAA8GkEVgAAAPg0\nAisAAAB8GoEVAAAAPo3ACgAAAJ9GYAUAAIBPI7ACAADApxFYAQAA4NMIrAAAAPBpBFYAAAD4NAIr\nAAAAfJrHgdVms2nu3LkaOXKkMjMztXLlyvMe++233+qBBx7QsGHDdOedd2r79u1tvv/GG29o3Lhx\nGjVqlGbOnKmqqirPzwAAAADdmseBdcmSJdq/f79WrVql+fPn680339SmTZvaHVdfX6+pU6fqiiuu\n0Lp163TrrbfqySefdIfSDz/8UJ988oleffVVvf/++zp+/LieffbZSz8jAAAAdCseBdbGxkatWbNG\n8+bNU0pKisaPH6+srCytXr263bGffPKJwsLCtGDBAvXv319PPfWUkpKS9NVXX0mSvvjiC02cOFHX\nXHONLr/8cmVlZWnr1q0dc1YAAADoNjwKrHl5ebLb7UpPT3ePZWRkKDc3t92xO3fu1M0339xm7K9/\n/atuuOEGSVJERIT+/e9/q7y8XE1NTVq3bp2GDBlyMecAAACAbsyjwFpRUaGIiAiZTCb3WHR0tKxW\nq6qrq9scW1xcrMjISD333HMaO3as7rvvPu3Zs8f9/SeeeEKBgYEaN26cMjIytGfPHv3mN7+5xNMB\nAABAd2P6/kPOaGxsVHBwcJsx12ObzdZm/NSpU1qxYoUeeughrVixQuvWrdPUqVP1j3/8Q7GxsSop\nKVHPnj21fPlyWSwWLVmyRHPnztV7773n0QkEBdHowB+45pn59g/Mt39hvv0L8+1fOmqePQqsISEh\n7YKp63FoaGib8aCgIKWmpurJJ5+UJKWkpOjLL7/U3//+d02fPl2zZ8/WrFmzNG7cOEnSa6+9pptu\nukm5ubkaOnToBddksYR+/0HoNphv/8J8+xfm278w3/CER7E3NjZWNTU1cjgc7rHKykqZzWZZLJY2\nx/bp00cDBw5sM5aUlKTS0lJVVVWptLRUV111lft7ffv2VWRkpI4dO3Yx5wEAAIBuyqPAmpqaKpPJ\npOzsbPfYrl27lJaW1u7Y9PR05eXltRkrKChQQkKCLrvsMgUHBys/P9/9vaqqKtXU1CghIcHTcwAA\nAEA35lFgNZvNmjRpkubPn699+/Zp8+bNWrlypaZMmSKp9Wqr1WqVJN1333369ttv9eabb+rIkSN6\n/fXXVVJSojvvvFNBQUG6++67tWTJEu3atUsHDhzQr3/9aw0fPvyc4RcAAAD+K8DpdDo9eUJTU5MW\nLFigjRs3Kjw8XFlZWZo8ebKk1nWqixcv1l133SVJ2rt3rxYuXKj8/HwNGjRIzzzzjDIyMiS1rn19\n7bXXtH79ejU1Nen666/XvHnzFBkZ2cGnCAAAgK7M48AKAAAAdCZ6SgAAAMCnEVgBAADg0wisAAAA\n8GkEVgAAAPg0AisAAAB8WpcMrDabTXPnztXIkSOVmZmplStXGl0SvKS8vFwzZszQtddeq3Hjxmnx\n4sXttgdG9zR9+nTNmTPH6DLgRTabTQsWLNCoUaM0duxYLVu2zOiS4EVlZWV67LHHlJGRoVtuuUV/\n+tOfjC4JXmKz2fTDH/5QO3fudI+VlJTokUce0fDhw3XHHXfoyy+/9Og1TR1dZGdYsmSJ9u/fr1Wr\nVqmkpESzZs1SfHy8JkyYYHRp6GAzZsxQRESE3n//fdXU1Gju3LkKCgrSr371K6NLgxd99tln+uKL\nL/SjH/3I6FLgRS+++KJ27NihP/zhD6qvr9fMmTMVHx+ve++91+jS4AVPP/20EhIS9Le//U0HDx7U\nL3/5S8XHx2v8+PFGl4YOZLPZ9Itf/EKHDh1qM/7EE08oJSVFa9eu1ebNm/Xkk09qw4YN6tu37wW9\nbpe7wtrY2Kg1a9Zo3rx5SklJ0fjx45WVlaXVq1cbXRo6WEFBgXJzc/Xyyy9r0KBBysjI0IwZM7Ru\n3TqjS4MX1dbWaunSpRo6dKjRpcCLamtr9cknn+jFF19UWlqaRo8erUcffVQ5OTlGlwYvqKurU05O\njh5//HENGDBAt9xyizIzM7Vt2zajS0MHys/P17333quSkpI241u3blVxcbFeeOEFDRw4UNOnT1d6\nerrWrFlzwa/d5QJrXl6e7Ha70tPT3WMZGRnKzc01sCp4Q58+fbRixQpFRUW5x5xOp06ePGlgVfC2\nJUuWaNKkSRo0aJDRpcCLdu/erfDwcF1zzTXusWnTpumll14ysCp4i9lsVmhoqNauXauWlhYVFBRo\nz549Gjx4sNGloQPt2LFDY8aM0UcffaSz96XKzc3VkCFDFBIS4h7LyMhQdnb2Bb92lwusFRUVioiI\nkMl0ZjVDdHS0rFarqqurDawMHS08PFzXX3+9+7HT6dTq1at13XXXGVgVvGnr1q3avXu3nnjiCaNL\ngZcVFxcrPj5en376qSZOnKjx48frd7/7ndh8sXsKDg7Wc889pw8//FDDhg3TbbfdphtuuEF33323\n0aWhA91///2aNWtWm2AqtWa3mJiYNmPR0dEqLy+/4NfucmtYGxsbFRwc3GbM9Zibcbq3V155RXl5\neVq7dq3RpcALbDabnn/+ec2fP7/dzzi6n1OnTqmwsFAff/yxFi9erIqKCj377LPq2bOnHn74eNw0\nagAAA0tJREFUYaPLgxfk5+fr5ptv1tSpU3XgwAEtXLhQ1113ne644w6jS4OXnS+7eZLbulxgDQkJ\naXeCrsehoaFGlIROsHTpUq1atUqvvfYaHxV3U2+88YbS0tK4gu4ngoKC1NDQoN/+9rfumy6OHj2q\nDz74gMDaDW3dulVr1qzRF198oeDgYA0ePFhlZWV6++23Cax+ICQkRLW1tW3GbDabzGbzBb9Glwus\nsbGxqqmpkcPhUGBg64qGyspKmc1mWSwWg6uDNyxcuFAfffSRli5dyt2k3dj69et14sQJDR8+XJLU\n3NwsSdq4caP27NljZGnwgpiYGIWEhLS5Qzg5OVllZWUGVgVv+frrr5WUlNTmKltqaqqWL19uYFXo\nLLGxse26BlRWVqpPnz4X/BpdLrCmpqbKZDIpOztbI0aMkCTt2rVLaWlpBlcGb3jzzTf10Ucfadmy\nZbr11luNLgdetHr1arW0tLgfL126VJJoYdZNDRs2TFarVUVFRUpMTJTU+pFxfHy8wZXBG2JiYlRU\nVKSWlhb3PSgFBQVKSEgwuDJ0hmHDhundd9+VzWZz/6Nl9+7dbW66/D5d7qYrs9msSZMmaf78+dq3\nb582b96slStXasqUKUaXhg6Wn5+vt99+W9OnT9fw4cNVWVnp/kL3ExcXp/79+7u/wsLCFBYWpv79\n+xtdGrwgOTlZ48aN0+zZs5WXl6ctW7bo3Xff1QMPPGB0afCCm2++WSaTSfPmzVNhYaH++c9/avny\n5XrooYeMLg2dYNSoUYqLi9Ps2bN16NAhvfPOO9q3b59+8pOfXPBrBDi74C2ZTU1NWrBggTZu3Kjw\n8HBlZWVp8uTJRpeFDvbOO++02/nG6XQqICBA33zzjUFVobO4drl6+eWXDa4E3lJfX68XX3xRn3/+\nuUJDQ/Xggw/q8ccfN7oseEl+fr4WLVqk3NxcRUVF6ac//Sm/u7ux1NRU/fnPf9bIkSMltXYGmTt3\nrnJzczVgwAA988wzGj169AW/XpcMrAAAAPAfXW5JAAAAAPwLgRUAAAA+jcAKAAAAn0ZgBQAAgE8j\nsAIAAMCnEVgBAADg0wisAAAA8GkEVgAAAPg0AisAAAB8GoEVAAAAPo3ACgAAAJ/2/wE7eX73xoHp\n1QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x115e8a9e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([0.797, 0.786838161735, 0.799663299663, 0.803097643097,\n",
    "          0.796498316498, 0.699393939394, 0.709020068049,\n",
    "          0.779259259259, 0.778047138047, 0.813468013468, 0.808821548822], )\n",
    "\n",
    "# plt.xticks(range(3), 'a b c'.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "462px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "widgets": {
   "state": {
    "034ac6993cda42e0a3b7dacf79b00d2f": {
     "views": [
      {
       "cell_index": 56
      }
     ]
    },
    "c731c422cc3b43088c7b596ce39cf111": {
     "views": [
      {
       "cell_index": 56
      }
     ]
    },
    "cabc57e5eef349e0bdb49ef3bdf9c4e7": {
     "views": [
      {
       "cell_index": 56
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
